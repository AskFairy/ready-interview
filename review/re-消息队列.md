# 消息队列 

#### 消息队列

消息队列，是**分布式系统**中不可缺少的**中间件**。可实现**高性能**，**高可用**，**可伸缩和最终一致性架构**

目前主流的消息队列有

- Kafka：大数据、实时计算，kafka是业内标准。
- RabbitMQ：开源，Erlang实现，Spring Cloud 支持上不错，社区活跃
- RocketMQ ：Java实现，阿里出品。
- ActiveMQ ：不清楚，没经过大规模吞吐量场景的验证，社区不活跃

![image-20200928164858644](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200928164900.png)

#### 角色

- 生产者（Producer）

- 消费者（Consumer

- 消息代理（Message Broker）：负责**存储消息**和**转发消息**两件事情。

  其中，**转发消息**分为推送和拉取两种方式。

  - **拉取**（Pull）
  - **推送**（Push）

#### 应用场景

- 应用解耦
  - 解耦：从主动调用的方式，变成了消息的订阅发布
- 异步处理
  - 串行调用变为异步，提升速度。
  - 前提，返回的结果不依赖于处理的结果。
- 流量削峰
  - 转发到消息队列中，慢慢处理。
  - 生产中，如果对时效没有要求，可以允许短暂的高峰期积压
- 消息通讯
  - 消息通讯
- 日志处理（异步处理）
  - 解决大量**日志传输**的问题（ELK+kafka）

#### 缺点

- 复杂度提高
  - 1）消息怎么不重复消息。
  - 2）消息怎么保证不丢失。
  - 3）需要消息顺序的业务场景，怎么处理。
- 可用性降低
- 一致性问题。**一定要达到数据的最终一致性**

#### 消费语义

1. 消息至多被消费一次（At most once）：消息可能会丢失，但绝不重传。

   - 吞吐量大，容忍消息丢失。
   - Message Broker不对接收到的消息响应确认
   - Message Broker转发不要求持久性，也不关心消费者是否真的收到
   - Message Broker消息被拿走就删除，不关心消费者，消费情况

2. 消息至少被消费一次（At least once）：消息可以重传，但绝不丢失。

   - Message Broker 必须响应对消息的确认，并提供持久性保障
   - 接收到消费者通知后，才删除消息。

3. 消息仅被消费一次（Exactly once）：每一条消息只被传递一次。

   - Message Broker 上存储的消息被 Consumer 仅消费一次。

     - Message Broker不对接收到的消息响应确认

     - Message Broker 提供持久性保障
     - 消息有唯一标识，消费者记录唯一标准，防止重复消费

   - Producer 上产生的消息被 Consumer 仅消费一次。

     - Message Broker对接收到的消息响应确认。 Producer 负责为该消息产生唯一标识，以防止 Consumer 重复消费
     - Message Broker 提供持久性保障，消息队列里有唯一标识
     - 消费者记录唯一标识，防止重复消费

#### 消息队列有几种投递方式？分别有什么优缺点

**push**

- 优点：**即时**
- 缺点：就是受限于消费者的消费能力，可能造成消息的**堆积**

**pull**

- 优点：消费者自己掌控进度，不会堆积
- 缺点：延迟、忙等

**目前的消息队列，基于 push + pull 模式结合的方式**，Broker 仅仅告诉 Consumer 有新的消息，具体的消息拉取，还是 Consumer 自己主动拉取。

##### 消费者实现幂等性？消息不被重复消费？

**消息仅被消费一次**，且**每条消息从 Producer 保证被送达，并且被 Consumer 仅消费一次**。

重复消费：offset，消费者挂了

方式：

1. 业务层自己确认是否是否消费过
2. 事物，Zookeeper 和 Redis 在获取分布式锁

##### 如何保证生产者的发送消息的可靠性？

**RabbitMQ** 

![image-20200928174648240](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200928174649.png)

1. 生产者弄丢了数据

   1. 提供事物（同步），会降低吞吐

      ```java
      // 开启事务
      channel.txSelect
      try {
          // 这里发送消息
      } catch (Exception e) {
          channel.txRollback
      
          // 这里再次重发这条消息
      }
      
      // 提交事务
      channel.txCommit
      ```

   2. 开启 `confirm` 模式：

      - 开启 `confirm` 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 `ack` 消息，告诉你说这个消息 ok 了。
      - 如果 `RabbitMQ` 没能处理这个消息，会**回调你的**一个 `nack` 接口，告诉你这个消息接收失败，你可以重试。
      - 而且你可以结合这个机制**自己在内存里维护每个消息 id 的状态**，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

2. RabbitMQ 弄丢了数据

   1. **开启 RabbitMQ 的持久化**
      - 创建 queue 的时候将其设置为持久化
      - 发送消息的时候将消息的 `deliveryMode` 设置为 2
      - 持久化可以跟生产者那边的 `confirm` 机制配合

3. 消费端弄丢了数据

   - RabbitMQ 提供的 `ack` 机制，简单来说，就是**你必须关闭 RabbitMQ 的自动 ack** ，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 `ack` 一把。
   - 为防止任务执行期间出错，设置NO_ACK=FALSE标志，这样、一旦任务没有应答的话，相应的任务就会被RabbitMQ自动Re-Queue,避免丢失任务（手动ACK超时怎么办？禁用心跳不行，线程池，定时统一处理异常。）

**Kafka**

1. 消费端弄丢了数据
   - **关闭自动提交** offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢，**可能会有重复消费**，自己保证幂等性
2. Kafka 弄丢了数据
   - broker 宕机，然后重新选举 partition 的 leader，没来得及同步，丢失数据，
   - 为了防止leader切换不丢数据
     - 给 topic 设置 `replication.factor` 参数：这个值必须大于 1，要求每个 p**artition 必须有至少 2 个副本**。
     - 在 Kafka 服务端设置 `min.insync.replicas` 参数：这个值必须大于 1，这个是**要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队**，这样才能确保 leader 挂了还有一个 follower 吧。
     - 在 **producer 端**设置 `acks=all` ：这个是要求每条数据，必须是**写入所有 replica 之后，才能认为是写成功了**。
     - 在 **producer 端**设置 `retries=MAX` （很大很大很大的一个值，无限次重试的意思）：这个是**要求一旦写入失败，就无限重试**，卡在这里了。
3. 生产者会不会弄丢数据？
   - 设置了 `acks=all` ,生产者会自动不断的重试，重试无限次。

##### 如何保证消息的顺序性？

场景： mysql `binlog` 日志，到MQ，再出来，顺序得一致。多个消费者，多个线程消费。

解决顺序型，得同步

###### 解决方案

**RabbitMQ**

1. 拆分多个 queue，每个 queue 一个 consumer
2. 一个 queue 但是对应一个 consumer，然后这个 consumer 内部用**内存队列做排队**，然后分发给底层不同的 worker 来处理。

**Kafka**

1. 一个 topic，一个 partition，一个 consumer，内部单线程消费
2. 写 **N 个内存 queue**，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，**每个线程分别消费一个内存 queue** 即可，这样就能保证顺序性。

##### 如何解决消息积压的问题？

1. 先

##### 如何解决消息过期的问题？

大量积压，**批量重导**

##### 消息队列如何实现高可用？

###### RabbitMQ ：

1. 单机：DEMO
2. 普通集群：创建的**创建的 queue，只会放在一个 RabbitMQ 实例上**，每个实例放队列的元数据。集群间可能产生大量的数据传输，没备份，可用性无法保障。就是为了提高吞吐量。
3. 镜像集群模式（高可用性）：基于主从做高可用。你创建的 queue，无论元数据还是 queue 里的消息都会**存在于多个实例上**，也就是镜像
   - 开销大，**不是分布式**，所有数据放到一个节点里，**不能线性扩展**。

###### Kafka 的高可用性

由多个 `broker` 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 `partition`，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。

这就是**天然的分布式消息队列**，就是说一个 topic 的数据，是**分散放在多个机器上的，每个机器就放一部分数据**。

- Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制
- 所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 **leader 打交道**，然后其他 replica 就是 follower。
- **写数据**的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己**主动从 leader 来 pull 数据**
- **消费**的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。
-  broker 宕机：会从 follower 中**重新选举**一个新的 leader 出来