# 中心主题

## 资料

### 从0开始微服务

### 随笔

#### 我们最关心的是 QPS（调用量）、AvgTime（平均耗时）以及 P999（99.9% 的请求性能在多少毫秒以内）这些指标

#### 

#### 服务健康状态监测

##### 

#### 基于现有的 Socket 通信，在服务消费者和服务提供者之间建立网络连接，然后在服务提供者一侧基于 BIO、NIO 和 AIO 三种方式中的任意一种实现服务端请求处理，最后再花费一些精力去解决服务消费者和服务提供者之间的网络可靠性问题。这种方式对于 Socket 网络编程、多线程编程知识都要求比较高，感兴趣的话可以尝试自己实现一个通信框架。但我建议最为稳妥的方式是使用成熟的开源方案，比如 Netty、MINA 等，它们都是经过业界大规模应用后，被充分论证是很可靠的方案。

## 架构演进

### 单体应用 - 微服务架构 - 容器化应用 - DevOps

## 微服务的发展由来

### 它是由单体应用进化到服务化拆分部署，后期随着移动互联网规模的不断扩大，敏捷开发、持续交付、DevOps 理论的发展和实践，以及基于 Docker 容器化技术的成熟，微服务架构开始流行，逐渐成为应用架构的未来演进方向。

## 单体应用的痛

### 部署效率低下

### 团队协作开发成本高

### 系统高可用性差

### 线上发布变慢

## 服务化的思想进一步演化，演变为今天我们所熟知的微服务

### 微服务相比于服务化又有什么不同呢？

#### 服务拆分粒度更细

#### 服务独立部署

#### 服务独立维护

#### 服务治理能力要求高

## 什么时候进行服务化拆分？

### 项目第一阶段的主要目标是快速开发和验证想法，证明产品思路是否可行

### 随着新功能新特性的增加，需要大规模地扩张开发人员，以支撑多个功能的开发

### 一旦单体应用同时进行开发的人员超过 10 人，就会遇到上面的问题，这个时候就该考虑进行服务化拆分了

## 服务化拆分的两种姿势

### 纵向拆分+横向拆分

## 服务化拆分的前置条件

### 服务如何定义

### 服务如何发布和订阅

### 服务如何监控

### 故障如何定位

### 服务如何治理

## 微服务架构

### 服务调用的流程。

#### 首先服务提供者（就是提供服务的一方）按照一定格式的服务描述，向注册中心注册服务，声明自己能够提供哪些服务以及服务的地址是什么，完成服务发布。

#### 接下来服务消费者（就是调用服务的一方）请求注册中心，查询所需要调用服务的地址，然后以约定的通信协议向服务提供者发起请求，得到请求结果后再按照约定的协议解析结果

#### 而且在服务的调用过程中，服务的请求耗时、调用量以及成功率等指标都会被记录下来用作监控，调用经过的链路信息会被记录下来，用于故障定位和问题追踪。在这期间，如果调用失败，可以通过重试等服务治理手段来保证成功率。

### 微服务架构

#### 服务发布和引用（服务描述）

##### 常用的服务描述方式

###### RESTful API

####### 被用作 HTTP 或者 HTTPS 协议的接口定义

###### XML 配置

####### 通过在服务提供者和服务消费者之间维持一份对等的 XML 配置文件，来保证服务消费者按照服务提供者的约定来进行服务调用

###### IDL 文件

####### IDL 就是接口描述语言（interface description language）的缩写，通过一种中立的方式来描述接口，使得在不同的平台上运行的对象和不同语言编写的程序可以相互通信交流

######## 生成不同语言平台的客户端和服务端代码，从而具备跨语言服务调用能力

######## IDL 文件需要对接口返回值进行详细定义

######## idl跟通信协议无关，grpc用的是http2，可以理解是七层，thrift用的是tcp，四层

###### 

#### 注册中心

##### 注册中心的工作流程

###### 服务提供者在启动时，根据服务发布文件中配置的发布信息向注册中心注册自己的服务。定期发送心跳汇报存活状态

###### 服务消费者在启动时，根据消费者配置文件中配置的服务信息向注册中心订阅自己所需要的服务，把 返回的服务节点列表缓存在本地内存中

####### 基于负载均衡算法选择一台服务提供者发起调用。

###### 注册中心返回服务提供者地址列表给服务消费者。

###### 当服务提供者发生变化，比如有节点新增或者销毁，注册中心将变更通知给服务消费者，让它刷新本地内存中缓存的服务节点列表。

##### 实现方式

###### 注册中心 API

###### 集群部署

####### 保证可用性

####### 有的注册中心还采用多 IDC 部署，这就对数据一致性产生了很高的要求

###### 目录存储

####### 存储数据

###### 服务健康状态检测

####### 心跳机制

###### 服务状态变更通知

####### 监听器watcher机制

###### 白名单机制

#### 服务框架

##### 解决RPC（远程服务调用）远程服务调用间的传输

###### 客户端和服务端如何建立网络连接？

####### 客户端和服务端之间基于 TCP 协议建立网络连接最常用的途径有两种

######## HTTP 通信

######### HTTP 通信是基于应用层 HTTP 协议的，而 HTTP 协议又是基于传输层 TCP 协议的。

######### 一次 HTTP 通信过程就是发起一次 HTTP 调用，而一次 HTTP 调用就会建立一个 TCP 连接

########## "三次握手"的过程来建立连接。

########## "四次挥手"的过程来断开连接。

######## Socket 通信

######### Socket 通信是基于 TCP/IP 协议的封装，建立一次 Socket 连接至少需要一对套接字

######### 步骤

########## 服务器监听

########## 客户端请求

########## 服务端连接确认

########## 数据传输

######## 网络不一定总是可靠

######### 经常会遇到网络闪断、连接超时、服务端宕机等各种异常

######### 处理手段

########## 链路存活检测：客户端需要定时地发送心跳检测消息（一般是通过 ping 请求）给服务端，如果服务端连续 n 次心跳检测或者超过规定的时间都没有回复消息，则认为此时链路已经失效，这个时候客户端就需要重新与服务端建立连接

########## 断连重试：通常有多种情况会导致连接断开，比如客户端主动关闭、服务端宕机或者网络故障等。这个时候客户端就需要与服务端重新建立连接，但一般不能立刻完成重连，而是要等待固定的间隔后再发起重连，避免服务端的连接回收不及时，而客户端瞬间重连的请求太多而把服务端的连接数占满。

###### 服务端如何处理请求？

####### 同步阻塞方式（BIO）

######## 客户端每发一次请求，服务端就生成一个线程去处理。当客户端同时发起的请求很多时，服务端需要创建很多的线程去处理每一个请求，如果达到了系统最大的线程数瓶颈，新来的请求就没法处理了。

######## 适用于连接数比较小的业务场景

####### 同步非阻塞方式 (NIO)

######## 通过 I/O 多路复用技术进行处理。就是把多个 I/O 的阻塞复用到同一个 select 的阻塞上，从而使系统在单线程的情况下可以同时处理多个客户端请求

######## 适用于连接数比较多并且请求消耗比较轻的业务场景

####### 异步非阻塞方式（AIO）

######## 客户端只需要发起一个 I/O 操作然后立即返回，等 I/O 操作真正完成以后，客户端会得到 I/O 操作完成的通知，此时客户端只需要对数据进行处理就好了，不需要进行实际的 I/O 读写操作，因为真正的 I/O 读取或者写入操作已经由内核完成了。这种方式的优势是客户端无需等待，不存在阻塞等待问题。

######## 适用于连接数比较多而且请求消耗比较重的业务场景

###### 数据传输采用什么协议？

####### 协议

######## HTTP 协议

######## 私有协议

######### Dubbo 协议

####### 协议需要定义服务消费者和服务提供者之间对传输数据的\"编解码\"工作的契约

######## 契约

######### 消息头和消息体。其中消息头存放的是协议的公共字段以及用户扩展字段，消息体存放的是传输数据的具体内容

###### 数据该如何序列化和反序列化？

####### 序列化方式

######## 文本类如 XML/JSON 等

######## 二进制类如 PB/Thrift 等

####### 采用哪种序列化方式，主要取决于三个方面的因素

######## 支持数据结构类型的丰富度

######## 跨语言支持

######## 性能。主要看两点，一个是序列化后的压缩比，一个是序列化的速度

##### RPC调用框架

###### 通信框架

####### 解决客户端和服务端如何建立连接

####### 管理连接

####### 服务端如何处理请求的问题

###### 通信协议

####### 它主要解决客户端和服务端采用哪种数据传输协议的问题

###### 序列化和反序列化

####### 它主要解决客户端和服务端采用哪种数据编解码的问题。

###### 一个通信框架可以适配多种通信协议，也可以采用多种序列化和反序列化的格式，比如服务化框架 Dubbo 不仅支持 Dubbo 协议，还支持 RMI 协议、HTTP 协议等，而且还支持多种序列化和反序列化格式，比如 JSON、Hession 2.0 以及 Java 序列化等。

#### 服务监控

##### 服务监控要做什么

###### 监控前-需要搞定的问题

####### 监控对象

######## 用户端监控。通常是指业务直接对用户提供的功能的监控

######## 接口监控。通常是指业务提供的功能所依赖的具体 RPC 接口的监控

######## 资源监控。通常是指某个接口依赖的资源的监控

######## 基础监控。通常是指对服务器本身的健康状况的监控。

####### 监控指标

######## 请求量

######### 实时请求量

########## QPS（Queries Per Second）即每秒查询次数来衡量

######### 统计请求量

########## PV（Page View）即一段时间内用户的访问量来衡量

########### 比如一天的 PV 代表了服务一天的请求量，通常用来统计报表。

######## 响应时间

######### 大多数情况下，可以用一段时间内所有调用的平均耗时来反映请求的响应时间。但它只代表了请求的平均快慢情况，有时候我们更关心慢请求的数量

######### 把响应时间划分为多个区间，比如 0～10ms、10ms～50ms、50ms～100ms、100ms～500ms、500ms 以上这五个区间，其中 500ms 以上这个区间内的请求数就代表了慢请求量，

######### 还可以从 P90、P95、P99、P999 角度来监控请求的响应时间，比如 P99 = 500ms，意思是 99% 的请求响应时间在 500ms 以内，它代表了请求的服务质量，即 SLA。

######## 错误率

######### 错误率的监控通常用一段时间内调用失败的次数占调用总次数的比率来衡量，比如对于接口的错误率一般用接口返回错误码为 503 的比率来表示

####### 监控维度

######## 全局维度

######## 分机房维度

######## 单机维度

######## 时间维度

######### 同一个监控对象，在每天的同一时刻各种指标通常也不会一样，这种差异要么是由业务变更导致，要么是运营活动导致

######### 。为了了解监控对象各种指标的变化，通常需要与一天前、一周前、一个月前，甚至三个月前做比较。

######## 核心维度

######### 依据重要性程度对监控对象进行分级，最简单的是分成核心业务和非核心业务。

###### 监控系统原理

####### 数据采集

######## 采集什么

######### 包括调用的响应时间、调用是否成功、调用的发起者和接收者分别是谁

######## 方式

######### 服务主动上报

########## 嵌入数据收集代码

######### 代理收集

########## 通过代理去解析本地日志文件，然后再上报

######## 最好动态控制采样率

####### 数据传输

######## 数据传输方式

######### UDP 传输

######### Kafka 传输

######## 采用的数据格式有两种

######### 进制协议，最常用的就是 PB 对象，它的优点是高压缩比和高性能，可以减少传输带宽并且序列化和反序列化效率特别高

######### 文本协议，最常用的就是 JSON 字符串，它的优点是可读性好，但相比于 PB 对象，传输占用带宽高，并且解析性能也要差一些。

####### 数据处理

######## 聚合

######### 接口维度聚合

######### 机器维度聚合

######## 存储

######### 索引数据库，比如 Elasticsearch，以倒排索引的数据结构存储，需要查询的时候，根据索引来查询。

######### 时序数据库，比如 OpenTSDB，以时序序列数据的方式存储，查询的时候按照时序如 1min、5min 等维度来查询。

####### 数据展示

######## 曲线图。一般是用来监控变化趋势的

######## 饼状图。一般是用来监控占比分布的

######## 格子图。主要做一些细粒度的监控，比如下面这张格子图代表了不同的机器的接口调用请求量和耗时情况，展示结果一目了然。

#### 服务追踪

##### 记录服务调用经过的每一层链路，以便进行问题追踪和故障定位。

##### 微服务追踪的作用

###### 优化系统瓶颈

###### 优化链路调用

###### 生成网络拓扑

###### 透明传输数据

####### 除了服务追踪，业务上经常有一种需求，期望能把一些用户数据，从调用的开始一直往下传递，以便系统中的各个服务都能获取到这个信息

####### A / B测试

######## 就是整两套UI，统计用户效果

##### 服务追踪系统原理

###### 调用链

####### 通过一个全局唯一的 ID 将分布在各个服务节点上的同一次请求串联起来，从而还原原有的调用关系，可以追踪系统问题、分析调用数据并统计各种系统指标。

####### 比较有名的有 Twitter 的Zipkin、阿里的鹰眼、美团的MTrace等。

####### 基本概念

######## 

######## traceId，用于标识某一次具体的请求 ID

######### 串联某一次请求在系统中经过的所有路径

######## spanId，用于标识一次 RPC 调用在分布式请求中的位置

######### 区分系统不同服务之间调用的先后关系

######## annotation，用于业务自定义埋点数据，可以是业务感兴趣的想上传到后端的数据，比如一次请求的用户 UID。

######### 用于业务自定义一些自己感兴趣的数据

##### 服务追踪系统实现

###### 数据采集层，负责数据埋点并上报

####### 

###### 数据处理层，负责数据的存储与计算

####### 实时处理

######## 一般采用 Storm 或者 Spark Streaming 来对链路数据进行实时聚合加工，存储一般使用 OLTP 数据仓库，比如 HBase，使用 traceId 作为 RowKey，能天然地把一整条调用链聚合在一起，提高查询效率。

####### 离线数据处理

######## 针对离线数据处理，一般通过运行 MapReduce 或者 Spark 批处理程序来对链路数据进行离线计算，存储一般使用 Hive。

###### 数据展示层，负责数据的图形化展示

####### 调用链路图

######## 一次服务整体情况

######## 每一层的情况

####### 调用拓扑图

######## 一种全局视野图，在实际项目中，主要用作全局监控，用于发现系统中异常的点，从而快速做出决策

#### 服务治理

##### 服务监控能够发现问题，服务追踪能够定位问题所在，而解决问题就得靠服务治理了。服务治理就是通过一系列的手段来保证在各种意外情况下，服务调用仍然能够正常进行

##### 场景

###### 依赖服务不可用

####### 熔断

###### 单机故障

####### 自动摘除故障节点

###### 单 IDC 故障

####### 自动切换故障 IDC 的流量到其他正常 IDC

##### 常用的服务治理手段

###### 节点管理（服务健康状态）

####### 服务调用失败一般是由两类原因引

######## 服务提供者自身出现问题

######## 网络问题

####### 两类手段

######## 注册中心主动摘除机制

######## 服务消费者摘除机制

######### 防止因为网络问题注册中心会把服务节点全部摘除

######### 将存活探测机制用在服务消费者这一端更合理

###### 节点选择（从服务节点访问优先级角度来考虑）

####### 负载均衡

######## 随机算法

######## 轮询算法

######### 按照固定的权重，对可用服务节点进行轮询

######## 最少活跃调用算法

######### 在服务消费者这一端的内存里动态维护着同每一个服务节点之间的连接数

######## 一致性 Hash 算法

######### 指相同参数的请求总是发到同一服务节点。当某一个服务节点出现故障时，原本发往该节点的请求，基于虚拟节点机制，平摊到其他节点上，不会引起剧烈变动。

####### 服务路由

######## 对于服务消费者而言，在内存中的可用服务节点列表中选择哪个节点不仅由负载均衡算法决定，还由路由规则确定。

######## 路由规则，就是通过一定的规则如条件表达式或者正则表达式来限定服务节点的选择范围。

######## 为什么要制定路由规则呢？

######### 业务存在灰度发布的需求

########## 灰度发布：按定的规则，先让一部分人试用

######### 多机房就近访问的需求

########## 通过 IP 段规则来控制访问，在选择服务节点时，优先选择同一 IP 段的节点。

######## 路由规则该如何配置

######### 静态配置

########## 在服务消费者本地存放服务调用的路由规则

######### 动态配置

########## 路由规则是存在注册中心的，服务消费者定期去请求注册中心来保持同步

###### 服务容错（从调用的健康状态角度来考虑）

####### 于服务调用失败的情况，需要有手段自动恢复，来保证调用成功。

####### 服务消费者容错常用手段

######## FailOver：失败自动切换

######### 就是服务消费者发现调用失败或者超时后，自动从可用的服务节点列表总选择下一个节点重新发起调用，也可以设置重试的次数。这种策略要求服务调用的操作必须是幂等的，也就是说无论调用多少次，只要是同一个调用，返回的结果都是相同的，

######### 一般适合服务调用是读请求的场景。

######## FailBack：失败通知

######### 就是服务消费者调用失败或者超时后，不再重试，而是根据失败的详细信息，来决定后续的执行策略。比如对于非幂等的调用场景，如果调用失败后，不能简单地重试，而是应该查询服务端的状态，看调用到底是否实际生效，如果已经生效了就不能再重试了；如果没有生效可以再发起一次调用。

######## FailCache：失败缓存

######### 就是服务消费者调用失败或者超时后，不立即发起重试，而是隔一段时间后再次尝试发起调用。比如后端服务可能一段时间内都有问题，如果立即发起重试，可能会加剧问题，反而不利于后端服务的恢复。如果隔一段时间待后端节点恢复后，再次发起调用效果会更好。

######## FailFast：快速失败。

######### 就是服务消费者调用一次失败后，不再重试。实际在业务执行时，一般非核心业务的调用，会采用快速失败策略，调用失败后一般就记录下失败日志就返回了。

######## 一般情况下对于幂等的调用，可以选择 FailOver 或者 FailCache，非幂等的调用可以选择 FailBack 或者 FailFast。
