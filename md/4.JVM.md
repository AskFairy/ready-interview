# JVM

## 概念

### [JAVA中类、实例与Class对象](https://blog.csdn.net/djzhao/article/details/79107071)

**类：**类是面向对象编程语言的`一个重要概念`，它是`对一项事物的抽象概括，可以包含该事物的一些属性定义，以及操作属性的方法`。

类只是信息描述的，写明了有哪些内部属性及接口，你可以理解为是程序员定义了一套规则。

面向对象编程中，我们都是以类来编码。

**Class：**在包 java.lang 下继承Object特殊的**Class类**，它内部可以记录类的成员、接口等信息，也就是在Java里，Class是一个用来`表示类的类`，让JVM`看懂的一套模板`。（Class是一个实实在在的类，可以为它创建实例，也就是本文后面提到的Class对象，也叫做Class实例：就是类加载器加载到内存中的模板。）。

java提供了下面几种获取到类的Class对象的方法：

- （1）利用对象实例调用getClass()方法获取该对象的Class实例；

- （2）运用类名.class 的方式来获取Class实例；

- （3）使用Class类的静态方法forName("包名+类名")，用类的名字获取一个Class实例

  ![image-20200913202846994](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200913202855.png)

**实例：**简单理解，就是new，就是对类的实例化，创建这个`类对应的实际对象`，`类只是对事物的描述`，而`实例化`就相当于为`这个描述新开辟了一块内存`，可以改变这块区域里的各种属性（成员变量），用操作方法。当然，也可以实例化多块区域，只是不同的对象而已。

总结：在java里，`类只是信息描述`的，写明了有哪些内部属性及接口，你可以理解为是定义了`一套规则`；而`Class对象`在java里被用来对类的情况进行表述的一个实例，也就是是`类的实际表征`，可以理解为是对规则的图表化，这样`JVM才能直观的看懂，可以看做是一个模版`；而类的`实例化对象，就是通过模版，开辟出的一块内存进行实际的使用`。

### JVM的运行机制？

运行Java字节码的虚拟机，包括一套字节码指令集、一组程序寄存器、一个虚拟机栈、一个虚拟机堆、一个方法区和一个垃圾回收器。
	**Java源文件被编译器编译成.Class文件，.Class文件被解释器解释成机器码，机器码调用相应操作系统的本地方法库执行相应的方法**。
	在一个Java进程开始运行后，虚拟机就开始**实例化**了，**有多个进程启动就会实例化多个虚拟机实例**。虚拟机实例之间不能共享数据。

### JVM（Java虚拟机）有哪些部分组成？

- `类加载器：`于将编译好的. Class文件加载到JVM中
- `运行时数据区：`用于存储在JVM运行过程中产生的数据，包括线程私有的`程序计数器、虚拟机栈、本地方法栈`和线程共享的`方法区、虚拟机堆`；
- `执行引擎：`包括`即时编译器`和`垃圾回收器`，即时编译器用于将Java字节码编译成具体的机器码，垃圾回收器用于回收在运行过程中不再使用的对象
- `本地接口库`用于调用操作系统的本地方法库完成具体的指令操

![image-20200912193207228](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200912193208.png)



### 运行时数据区（内存区域）

线程到底在私有区域在干什么？哪些是在栈中的？概述

每个区域都是干什么的，都存储了什么

![image-20200912194906222](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200912194907.png)

**线程私有区域**：

- `程序计数器：`**记录当前运行线程在该方法中执行的字节码指令位置（行号指示器）**。在方法正在执行时，该方法的程序计数器记录的是实时虚拟机字节码指令的地址，Native方法，程序计数器的值为空（undefined）。唯一**无内存溢出**（Out Of Memory）问题的地方。

- `虚拟机栈：`描述的是**执行Java方法的线程内存模型**。在**方法**被执行时虚拟机会为其创建一个**与之对应的栈帧**，里面存储：局部变量表、操作栈、动态链接、方法出口等信息。`方法的执行和返回对应栈帧在虚拟机栈的入栈和出栈`。每个运行中的线程当前只有一个栈帧处于活动状态（线程执行代码是顺序的）。
  	  	`栈帧存储：`
  
  - `局部变量表`：存放`编译期可知的数据类型`，数据类型在局部变量表中的存储空间以局部变量槽（Sot）来表示，其中64位长度的`long和double类型`的数据会占用`两个变量槽`，`其余`的数据类型只`占用一个`。数据类型所需空间在编译期完成，进入方法前已经确定，运行期间不会改变局部变量表大小。
    - 基本数据类型
    - 对象引用
    - returnAddress（指向了一条字节码的地址）
  - `操作栈`：
  - `动态链接`：
  - `方法出口等`：
  
  ​		异常：
    				StackOverflowError：请求栈大于虚拟机深度
    				OutOfMemoryError：虚拟机栈容量可以动态扩展，但无法申请足够的内存。
  
- `本地方法栈：` 线程私有，本地方法区和虚拟机栈的作用类似，区别是虚拟机栈为执行Java 方法服务，`本地方法栈为Native方法服务`	

**线程共享区域**：

- 方法区：（`Java8元空间概念所在，采用本地内存实现`）用于存储已被虚拟机加载的**静态常量池**，**类型信息（即时编译器编译后的机器码）**等数据。垃圾回收器主要做针对**常量池的回收**，和**类型的卸载**。（所有的Class文件一次性都加载进内存？什么时候加载？）

  - 静态常量池

    - 字面量
    - 符合引用

    ![image-20200912205138122](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200912205139.png)

  **注：**而当类加载到内存中后，JVM就会将`静态常量池中的内容存放到运行时常量池`中。在静态常量池的符号引用有`一部分是会被转变为直接引用`的，比如说**类的静态方法或私有方法，实例构造方法，父类方法**，这是因为这些方法不能被重写其他版本，所以能在加载的时候就可以将符号引用转变为直接引用，而其他的一些方法是在这个方法被**第一次调用（线程调用到虚拟机栈？）**的时候才会将符号引用转变为直接引用的。

- `虚拟机堆：`虚拟机管理最大的区域，`虚拟机启动时创建`。在JVM运行过程中**几乎**所有的**对象实例**和**产生的数据**都被存储在堆中。垃圾回收器（GC）工作的区域。

  JDK8：

  - 对象实例
  - 运行时常量池
    - 字符串常量池：存的是在堆中的字符串的引用？还是字符串对象？

  **注1：**对堆的区域划分，仅仅是垃圾收集器的设计风格，一种概念，而非JVM具体实现的固有布局。

  **注2：**字符串常量池存的是引用值？，还是对象存在于运行时常量池之中？。

  **注3：**类（.class文件）加载到内存中后，JVM就会将`静态常量池中的内容存放到运行时常量池`中，运行时常量池更重要的的特征：`动态性`。Java要求，编译期静态常量池的内容可以进入运行时常量池（字符串），运行时产生的常量也可以放入池中：常用的是String类的intern()方法。（类加载器不是一次将所有的的.class文件都加载进内存）

  注4：几乎？：值类型的支持，以及编译技术进步，逃逸分析，栈上分配，标量替换优化手段导致一些微妙的变化，对象都分配到栈上已经不那么绝对了。

**直接内存：**

直接内存也叫作堆外内存，它**并不是JVM运行时数据区**的一部分，但在并发编程中被频繁使用。
		例如：JDK的**NIO模块提供的基于 通道（Channel）与缓冲区（Buffer）的I/O操作方式**就是基于堆外内存实现的，NIO模块通过**调用Native函数库直接在操作系统上分配堆外内存**，然后使用DirectByteBuffer对象作为这块内存的引用对内存进行操作
					Java进程可以通过堆外内存技术**避免在Java堆和 Native堆中来回复制数据带来的资源占用和性能消耗**，因此堆外内存在高并发应用场景下被广泛使用（ Netty、F1ink、 HBase、 Hadoop都有用到堆外内存）

#### 静态常量池在Class文件中的位置

![image-20200912211433506](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200912211434.png)

从上图可以看出，Class文件中包括：

魔数：它的唯一作用是确定这个文件是否可以被JVM接受。很多文件储存标准中都使用魔数来进行身份识别的，其占用这个文件的前四个字节。

版本号：第5和第6个字节是副版本号，第7个和第8 个是主版本号。

常量池计数器：也就是常量池的入口，代表常量池的容量计数器。

常量池：常量池中主要存放两类常量：字面量和符号引用。字面量比较接近Java语言层面的常量概念。就是我们什么提到的常量。而符号引用则属于编译原理的方面的概念。包括以下三类常量：

（1）类和接口的全限定名

（2）字段的名称和描述符

（3）方法的名称和描述符

### 对象

#### 对象的创建

对象的创建过程：通常指new[^其他创建方式]一个对象[^讨论对象]，创建对象是由`一个线程参与完成`的。

1. `类加载检查：`当Java虚拟机遇到一条字节码`new指令`时，首先将去检査这个指令的参数是否能在`常量池中定位到个类的符号引用（哪个常量池？不能怎么办？）`，并且检査这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。

   `类加载过程：`

2. `分配内存（方法区-->堆-->Eden）：`在类加载检查通过后，接下来虚拟机将为新生对象在Java堆中划分内存。对象所需内存的大小在类加载完成后便可完全确定（怎么确定）。

   （1）类加载完成后，怎么确定内存大小。

   - 

   （2）划分方式：

   - `指针碰撞：`适合`堆中内存绝对规整`。所有被使用过的内存都被放在边，空闲的内存被放在另一边，中间放着一个`指针作为分界点的指示器`，那所分配内存就仅仅是把那个指针向空闲空间方向挪动一段与对象大小相等的距离。
   - `空闲列表`：适合`堆中的内存并不是规整`。虚拟机就必须`维护一个列表`，`记录`上哪些`内存块`是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录

   选择**哪种分配方式由Java堆是否规整**决定，而Java堆是**否规整又由所采用的垃圾收集器**是否带有空间压缩整理的能力决定。

   - 压缩整理：使用 `Serial、 ParNew`等带压缩整理过程的收集器时，系统采用的分配算法是`指针碰撞`，既简单又高效
   - 清除算法：理论上山就只能采用较为复杂的空闲列表来分配内存
     - 强调¨理论上”是因为在CMS的实现里面，为了能在多数情况下`分配得更快`，设计了一个叫作 `Linear Allocation Buffer的分配缓冲区`，通过空闲列表`拿到一大块分配缓冲区`之后，在它里面仍然可以使用`指针碰撞`方式来分配。

   （3）频繁对象创建，移动指针不是线程安全的。

   - `对分配内存空间的动作进行同步处理`：实际上虚拟机是采用`CAS配上失败重试`的方式`保证更新操作的原子性`
   - `把内存分配的动作按照线程划分在不同的空间之中进行`：即`每个线程在Java堆中预先分配一小块内存`，称为本地线程分配缓冲（ Thread Local Allocation Buffer,TLAB）。**哪个线程要分配内存**，就在哪个线程的本地缓冲区中分配，只有本地缓冲区用完了，**分配新的缓存区时才需要同步锁定**。（虚拟机是否使用TLAB，可以通过-XX：+/- UseTlAB参数来设定）。

3. `内存空初始化为零值：`内存分配完成之后，虚拟机`必须将分配到的内存空间（但不包括对象头）都初始化为零值`，如果使用了TLAB的话，这一项工作也可以提前至TLAB分配时顺便进行。这步操作保证了`对象的实例字段在Java代码中可以不赋初始值就直接使用，使程序能访问到这些字段的数据类型所对应的零值`。

4. `Java虚拟机还要对对象头进行必要的设置`：

   - 见对象的内存布局：对象头部分：运行时数据，和类型指针。

5. `构造函数初始化字段`：因为目前所有的字段都为默认的零值。需要用构造函数，即 Class文件中的<init>()方法对对象需要的其他资源和状态信息按照程序员预定的意图构造好。

   - 一般来说（由字节码流中new指令后面是否跟随 invokespecial指令所决定，Java编译器会在遇到new关键字的地方同时生成这两条字节码指令，但如果直接通过其他方式产生的则不一定如此），`new指令之后会接着执行<init>方法`

![image-20200913220431790](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200913220433.png)

[^其他创建方式]:clone，反序列化
[^讨论对象]:普通Java对象，不包含数组，Class对象

#### 对象的内存布局

在 HotSpot虚拟机里，对象在堆内存中的存储布局可以划分为三个部分：对象头（ Header）、实例数据（ Instance data）和对齐填充（ Padding）。

[对象头](https://blog.csdn.net/zhaocuit/article/details/100208879)：对象头部分包括两类信息。

- 用于存储对象`自身的运行时数据`：叫`Mark Word`（32位32bit，64位64bit），被设计成一个有着`动态定义的数据结构`，即根据自身状态复用存储空间。

  - **哈希码（HashCode）**、**GC分代年龄**、**锁状态标志**、**线程持有的锁**、**偏向线程ID**、**偏向时间戳**等。

  ![image-20200914212749892](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200914212751.png)

- `类型指针：`即对象`指向它的类型元数据的指针`，Java虚拟机通过这个指针来确定该对象是哪个类的实例。

  - 并不是所有的虚拟机实现都必须在对象数据上保留类型指针，如果reference类型采用`句柄定位的方式，对象头中就没必要存储类型的指针`。
  - `如果对象是一个Java数组`，那在`对象头`中还必须`有`一块用于`记录数组长度的数据`，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是如果`数组的长度是不确定`的，将无法通过元数据中的信息推断出数组的大小。

- `实例数据：`对象真正存储的有效信息，即我们在**程序代码里面所定义的各种类型的字**

  **段内容**，无论是从父类继承下来的，还是在子类中定义的字段都必须记录起来。这部分的存储顺序会受到虚拟机分配策略参数（-XX: Fields Allocation Sty le参数）和字段在Java源码中定义顺序的影响。

- `对齐填充：`它仅仅`起着占位符的作用`。由于 HotSpot虚拟机的自动内存管理系统要求`任何对象的大小都必须是8字节的整数倍`。对象头部分已经被精心设计成正好是8字节的倍数（1倍或者2倍），因此，如果对象实例数据部分没有对齐的话，就需要通过对齐填充来补全。（为什么?）

#### 对象的访问定位

Java程序会通过`栈上的 reference数据来操作堆上的具体对象`。

由于 `reference类型`在《Java虚拟机规范》里面`只规定了它是一个指向对象的引用`，并没有定义。

reference类型主流的访问：

句柄：Java堆中将可能会划分出一块内存来作为句柄池， `reference`中存储的就是对象的`句柄地址`，而`句柄中`包含了`对象实例数据`与`类型数据`各自具体的地址信息。

![image-20200914215057178](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200914215058.png)

直接指针： reference中`存储`的直接就是在`Java堆中对象实例地址`，**对象头中存储有指向元数据类型实例的指针**。

![image-20200914215738526](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200914215739.png)

`优缺点：`

- 使用`句柄`来访问的最大好处，就是 reference 中存储的是稳定的句柄地址，在`对象被移动`（垃圾收集时移动对象是非常普遍的行为）时`只会改变句柄中`的实例数据指针，而 `reference 本身不需要修改`。
- 使用`直接指针`访问方式，如果`只访问对象本身`的话，它`节省了一次指针定位的时间`开销，最大好处就是速度更快，，由于对象的访问在 Java 中非常频繁，并且也不经常访问数据类型，因此这类开销积少成多后也是一项非常可观的执行成本。

**HotSpot采用的是直接指针的方式**。

### Java内存模型

为了在同样的制程工艺下，追求最大的运算能力。人们用多核并发除了来提升计算机的运算加速能力。

随着并发处理的广泛应用是 `Amdahl（阿姆达尔）定律`代替 `摩尔定律`成为计算机性能发展源动力的根本原因，也是人类压榨计算机运算能力的最有力武器。

- Amdahl定律通过系统`中并行化与串行化的比重`来描述多处理器系统能获得的运算加速能力
- 摩尔定律则用于描述处`理器晶体管数量与运行效率`之间的发展关系。

这两个定律的更替代表了近年来硬件发展从`追求处理器频率到追求多核心并行处理的发展过程`。

“内存模型”：它可以理解为在特定的`操作协议`下，对特定的内存或高速缓存`进行读写访问`的过程抽象。

- 操作协议：为了`解决一致性`的问题，需要各个处理器访问缓存时都`遵循`一些`协议`，在`读写时`要根据协议来进行操作

#### 主内存与工作内存

为了获得更好的执行效能，Java内存模型并*没有限制*执行引擎使用处理器的特定寄存器或*缓存*来和主内存进行交互，*也没有限制*即时编译器是否要进行*调整代码执行顺序这类优化措施*。

Java内存模型的主要目的：

- `定义`程序中各种`变量的访问规则`，即关注在虚拟机中把变量值`存储`到内存和从内存中`取出`变量值这样的底层细节。
  
  - 此处的**变量（ Variables）**与Java编程中所说的变量有所区别，它包括了`实例字段`、`静态字段`和`构成数组对象的元素`，但是不包括局部变量与方法参数，因为`后者是线程私有`的，不会被共享，自然就不会存在竞争问题。
    - 如果局部变量是一个 reference类型，它引用的对象在Java堆中可被各个线程共享，但是 reference本身在Java栈的局部变量表中是线程私有的。
  
  

Java内存模型规定了所有的变量都存储在`主内存`（ Main memory）中。每条线程还有自己的`工作内存`（ Working Memory，可与前面讲的处理器高速缓存类比），线程的工作内存中保存了被该线程使用的变量的主内存`副本【1】`，线程对变量的`所有操作`（读取、赋值等）都必须`在工作内存中`进行，而不能直接读写主内存中的数据【2】。不同的线程之间也无法直接访问对方工作内存中的变量，`线程间变量值的传递均需要通过主内存来完成`。

1. 有部分读者会对这段描述中的“副本”提出疑问，如“假设线程中访问一个10MB大小的对象，也会把这10MB的内存复制一份出来吗？”，事实上并不会如此，这个**对象的引用、对象中某个在线程访问到的字段是有可能被复制**的，但不会有虚拟机把整个对象复制一次
2.  volatile变量依然有工作内存的拷贝，但是由于**它特殊的操作顺序性规定**（后文会讲到），所以看起来如同直接在主内存中读写访问一般，因此这里的描述对于 volatile也并不存在例外。

线程、主内存、工作内存三者的交互关系如图所示：

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200915192525.png" alt="image-20200915192524484" style="zoom:33%;" />

![image-20200915192941238](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200915192943.png)



#### 内存交互操作

一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存这一类的实现细节，Java内存模型中定义了以下8种操作来完成。Java虚拟机实现时必须保证下面提及的每一种**操作**都是**原子的**、**不可再分的**（对于 double和long类型的变量来说，load、 store、read和wite操作在某些平台上允许有例外，这个问题在12.3.4节会专门讨论）：

- lock（锁定）:作用于主内存的变量，它把一个变量标识为一条线程独占的状态。
- unlock（解锁）:作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。
- read（读取）:作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的lad动作使用。
- load（载入）:作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。
- use（使用）:作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。
-  assign（赋值）:作用于工作内存的变量，它把一个从执行引擎接收的值赋给工作内存的变量，当虚拟杋遇到一个给变量赋值的字节码指令时执行这个操作
- store（存储）:作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的 write操作使用。
- write（写入）:作用于主内存的变量，它把 store操作从工作内存中得到的变量的值放入主内存的变量中。

基于理解和严谨性考虑，Java设计团队已经放弃了采用这8种操作去定义**Java内存模型的访问协议**，将Java内存模型的`操作`简化为**read、 write、lock和 unlock**四种，但这只是语言描述上的等价化简，仅是描述方式改变了，Java内存模型的设计基础并没有改变。

Java内存模型还规定了在执行上述8种基本操作时必须满足如下规则：

- （1）：`不允许read和load、 store和 write操作之一单独出现（精简为 read、write）`，即不允许一个变量从主内存读取了但工作内存不接受，或者工作内存发起回写了但主内存不接受的情况出现。
- （2）：不允许一个线程丢弃它最近的 assign操作，即`变量在工作内存中改变了之后必须把该变化同步回主内存`。
- （3）：不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。`没有复制操作，不能重新写入主内存（即load进线程内部，没动，就不要写回去了，防止发生安全问题）`。
- （4）：一个*新的变量（不包含内部变量）*只能在主内存中“诞生”，`不允许在工作内存中直接使用一个未被初始化（load或assign）的变量`，换句话说就是对一个变量实施use、 store操作之前，必须先执行 assign和load操作。
- （5）：**一个变量在同一个时刻只允许一条线程对其进行lock操作**，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的 unlock操作，变量才会被解锁。
- （6）：如果对`一个变量执行lock操作，那将会清空工作内存中此变量的值`，在执行引擎*使用这个变量前，需要重新执行load或 assign操作以初始化变量的值*
- （7）：如果一个变量事先`没有被lock操作`锁定，那就`不允许`对它执行 `unlock`操作，也不允许去 unlock一个被其他线程锁定的变量。
- （8）：对一个变量执行 `unlock操作之前，必须先把此变量同步回主内存中`（执行 store、 write操作）

#### 内存模型中对于 volatile型变量的特殊规则

关键字 volatile可以说是Java虚拟机提供的最轻量级的同步机制（比synchronized轻得多），

了解 volatile变量的语义对后面理解多线程操作的其他特性很有意义。

`Java内存模型为 volatile专门`定义了一些`特殊的访问规则`。

volatile关键字的作用：当一个变量被定义成 volatile之后，它将具备两项特性

- 第一项是`保证此变量对所有线程的可见性，及保证使用前的一致性`，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的（从物理存储的角度看，各个线程的工作内存中 volatile变量也可以存在不一致的情况，但由于`每次使用之前都要先刷新`，执行引擎看不到不一致的情况，因此可以认为不存在一致性问题）。

  - 但是Java里面的运算操作符并非原子操作，这导致 volatile变量的运算在并发下一样是不安全的。也就是说执行引擎`用（use）的时候`，其他的线程可能会修改。

  `volatile变量只能保证可见性`，只能在以下两种情况可以使用（其他情况我们仍然要通过加锁使用 synchronized、 javautil.concurrent中的锁或原子类来保证原子性）：

  - `运算结果并不依赖变量的当前值`，或者能够确保只有单一的线程修改变量的值。

  - 变量不需要与其他的状态变量共同参与不变约束。（？）

    `总结：`可以用来当标识。

- volatile变量的第二个语义是`禁止指令重排序优化`，普通的变量`仅会保证`在该方法的执行过程中所有依赖赋值结果的地方都能`获取到正确的结果`，而`不能保证变量赋值操作的顺序与程序代码中的执行顺序一致`。因为在同一个线程的方法执行过程中无法感知到变量的变化，只看见了最终结果。这就是Java内存模型中描述的所谓“`线程内表现为串行`的语义”（**注：**栈中的语句是执行的最终结果是一样的：线程不知道使用的对象有什么变化，只关注获取变量的结果。变量也不知道线程对自己做了什么操作，只关注写入的结果。在这之间就是指令重排优化的地方）。

  - 有 volatile修饰的变量，赋值后多执行了一个字节码指令（ `lock add$0x0,(％esp)`）操作，这个操作的作用相当于一个内存屏障（ `Memory Barrier`或 Memory Fence，`指重排序时不能把后面的指令重排序到内存屏障之前的位置`，注意不要与第3章中介绍的垃圾收集器用于捕获变量访问的内存屏障互相混淆）它的作用是将*本处理器*的*缓存*写入了内存，该写入动作也会引起**别的处理器或者别的内核无效化（ Invalidate）其缓存**，*即保证了禁止指令重排，又保证了所有线程的可见*。所以通过这样一个空操作，可让前面 volatile变量的修改对其他处理器立即可见。
    - 那为何说它禁止指令重排序呢？从硬件架构上讲，指令重排序是指处理器采用了`允许将多条指令不按程序规定的顺序分开发`送给各个相应的电路单元进行处理。但并不是说指令任意重排，处理器必须能正确处理指令依赖情况保障程序能得岀正确的执行结果。譬如指令1把地址A中的值加10，指令2把地址A中的值乘以2，指令3把地址B中的值减去3，这时指令1和指令2是有依赖的，它们之间的顺序不能重排—（A+10）*2与A*2+10显然不相等，但指令3可以重排到指令1、2之前或者中间，只要保证处理器执行后面依赖到A、B值的操作时能获取正确的A和B值即可。所以在同一个处理器中，重排序过的代码看起来依然是有序的。因此， lock addISOx（0，（％esp）指令把`修改同步到内存时，意味着所有之前的操作都已经执行完成（同步到主内存前，处理器必须计算完成，即满足Java内存操作的第2条规则，处理器内部怎么指令重排不管）`，这样便*形成了“指令重排序无法越过内存屏障”*的效果。

  后续思考：

  <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200916192736.png" alt="image-20200916192727502" style="zoom:33%;" />

#### 对bong和 double型变量的特殊规则

`Java内存模型`要求lock、 unlock、read、load、 assign、use、 store、 write这八种操作都具有原子性，但是对于64位的数据类型（long和 double），在模型中特别定义了一条宽松的规定：允许虚拟机将没有被 volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现自行选择是否要保证64位数据类型的load、 store、read和 write这四个操作的原子性，这就是所谓的“`long和 double的非原子性协定`”（Non- Atomic Treatment of double and long Variables）。

而针对 double类型，由于现代中央处理器中一般都包含专门用于处理浮点数据的浮点运算器（ Floating point unit,FPU），用来专门处理单、双精度的浮点数据，所以哪怕是32位虚拟机中通常也不会岀现非原子性访问的问题，实际测试也证实了这一点。笔者的看法是，在实际开发中，除非该数据有明确可知的线程竞争，否则我们在编写代码时`一般不需要`因为这个原因刻意把用到的long和 double变量专门声明为 volatile。


#### 原子性、可见性与有序性

1. 原子性（ Atomicity）

   - 由Java内存模型来直接保证的原子性变量操作包括read、load、 assign、use、 store和 write这六个。*单线程情况下*，`基本数据类型`的访问、读写都是`具备原子性`的（例外就是ong和 double的非原子性协定，读者只要知道这件事情就可以了，无须太过在意这些几乎不会发生的例外情况）。
   - 更大范围的原子性保证（代码块）：Java内存模型还提供了`lock和unlock操作`来满足这种需求，尽管虚拟机未把lock和 unlock操作直接开放给用户使用，但是却提供了更高层次的*字节码指令* `monitorenter`和 `monitorexit`来隐式地使用这两个操作。这两个字节码指令反映到Java代码中就是同步块— synchronized关键字，因此在 sy chroniκed块之间的操作也具备原子性。

2. 可见性（ Visibility）
   可见性就是指当一个线程修改了共享变量的值时，其他线程能够立即得知这个修改。

   - volatile**：Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性**的，*无论是普通变量还是 volatile变量都是如此*。

     - 普通变量与 volatile变量的区别是， **volatile的特殊规则保证**了新值能**立即同步**到主内存，以及每次使用前**立即**从主内存刷新。因此我们可以说 volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。

   - synchronized：同步块的可见性是由“*对一个变量执行 unlock操作之前，必须先把此**变量**同步回主内存中（执行 store、 write操作）*”这条规则获得的

   -  final关键字： final关键字的可见性是指：被 final修饰的字段在构造器中**一旦被初始化完成**，并且构造器没有把“this”的引用传递出去（*this引用逃逸*是一件很危险的事情，其他线程有`可能通过这个引用访问到“初始化了一半”的对象`），那么在**其他线程中就能看见 final字段**的值。如代码所示，变量i与j都具备可见性，它们无须同步就能被其他线程正确访问。

     ```java
     public static final int i;
     public final int i;
     ```

3. 有序性（Ordering）

   Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“**线程内似表现为串行的语义**”（ Within- Thread As- f-Serial Semantics），后半句是指“**指令重排序**ˆ现象和**“工作内存与主内存同步延迟**'现象。

   如下图所示：*时间先后顺序与先行发生原则之间基本没有因果关系*，所以我们衡量并发安全问题的时候不要受时间顺序的干扰，**一切必须以先行发生原则为准**。

   <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200916210147.png" alt="image-20200916210145150" style="zoom:50%;" />
   
   Java语言提供了 volatile和 synchronized两个关键字来保证线程之间操作的有序性， 
   
   - volatile：关键字本身就包含了禁止指令重排序的语义，
   - 而synchronized：是由“*一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的*，这个规则决定了持有同一个锁的两个同步块只能串行地进入。

 synchronized关键字在需要这三种特性的时候都可以作为其中一种的解决方案。看起来很“万能”吧？的确，`绝大部分并发控制操作都能使用 synchronized来完成`。*越“万能”的并发控制，通常会伴随着越大的性能影响*。

#### 先行发生原则

为了程序员不陷入`苦涩难懂的Java内存模型`定义之中，判断数据是否存在竞争，线程是否安全定义了几条简单的规则，叫**“先行发生”（ Happens- Before）**的原则。一揽子解决并发环境下两个操作之间是否可能存在冲突的所有问题。（就是之前内存模型定义抽象出来的人话）

如果两个操作之间的关系`不在此列`，`并且无法`从下列规则`推导`出来，则它们就没有顺序性保障，`虚拟机可以对它们随意地进行重排序`，*遵守以下原则就能保证前一个操作是对后一个操作时可见的*。

- *程序次序规则（ Program Order rule）*：**在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作**。注意，这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。
- `在一个线程内，使用变量前，变量必选赋值完毕`：前边变量assign之后，我后边再进行操作，至于你即时编译期做了什么优化，我不管。
  
- *管程锁定规则（ Monitor lock rule）*：一个 unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是“**同一个锁**”，而“后面”是指时间上的先后。由以下2条规则保证：
- （6）：如果对`一个变量执行lock操作，那将会清空工作内存中此变量的值`，在执行引擎*使用这个变量前，需要重新执行load或 assign操作以初始化变量的值*
  - （8）：对一个变量执行 `unlock操作之前，必须先把此变量同步回主内存中`（执行 store、 write操作）
  
- *volatile变量规则（ Volatile variable rule）：*对一个 volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面同样是指时间上的先后。
- **volatile的特殊规则保证**了新值能**立即同步**到主内存，以及每次使用前**立即**从主内存刷新
  
- *线程启动规则（ Thread Start rule）:* Thread对象的 start方法先行发生于此线程的每一个动作
- 主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。
  
- *线程终止规则（ Thread Termination rule）:*线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过 Thread::join方法是否结束、 Thread::isAlive()的返回值等手段检测线程是否已经终止执行。
- （2）：不允许一个线程丢弃它最近的 assign操作，即`变量在工作内存中改变了之后必须把该变化同步回主内存`。

- *线程中断规则（ Thread Interruption Rule）:*对线程 `interrupt方法的调用先行发生于被中断线程的代码检测到中断事件的发生`，可以通过 Thread: interrupted方法检测到是否有中断发生。
- *对象终结规则（ Finalizer rule）:*一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize()方法的开始。
  - 别还没初始化，就被垃圾回收器消灭了。
- *传递性（ Transitivity）:*如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。

使用这些规则去判定操作间是否具备顺序性，对于读写共享变量的操作来说，就是线程是否安全。

### Java与线程

#### 线程的实现

线程是比进程更轻量级的调度执行单位。

线程的引入，可以*把一个进程的资源分配和执行调度分开*

- 各个线程既可以共享进程资源（内存地址、文件IO等），又可以独立调度。

目前*线程是Java里面进行处理器资源调度的最基本单位*。

- 如果日后Loom项目能成功为Java引入纤程（ Fiber）的话，可能就会改变这一点。

主流的操作系统都提供了线程实现，Java语言则提供了在不同硬件和操作系统平台下对线程操作的统一处理，**每个已经调用过 start（方法且还未结束的 Jjava. lang. Thread类的实例就代表着一个线程**。

- Java中的线程是线程的一种实现方式。而不是用Java实现的线程。

实现线程主要有三种方式:

- **使用内核线程实现（1:1实现）**：

  内核线程（ Kernel- Level thread，KLT）就是直接由操作系统内核完成线程切换、调度的线程。程序一般不会直接使用内核线程，而是使用内核线程的一种高级接口——**轻量级进程**（ LightWeight Process，LWP），轻量级进程就是我们通常意义上所讲的线程，由于*每个轻量级进程都由一个内核线程*支持，因此只有先支持内核线程，才能有轻量级进程。

  - 局限性:首先，由于是基于内核线程实现的，所以*各种线程操作，如创建、析构及同步，都需要进行系统调用*。而`系统调用的代价相对较高`，需要在用户态（ User mode）和内核态（ Kernel mode）中来回切换（就是**轻量级进程LWT**和**内核线程KLT**来回切换）。
- 这两种状态的开销主要来自于**响应中断**、**保护**和**恢复**执行现场的成本。
  - <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200916213213.png" alt="image-20200916213211109" style="zoom: 25%;" />
    - p（用户）：JVM
    - LWP：轻量级进程（类似用户线程）
    - KLT：内核线程
    - ThreadScheduler：操作系统内核用来调度KLT的调度器
    - CPU：操作系统内核将任务从KLT分发给cpu

- `使用用户线程实现（1:N实现）`：

  - 而狭义上的用户线程指的是：完全建立在`用户空间`的线程库上，系统内核不能感知到用户线程的存在及如何实现的。`用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助`。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也能够支持规模更大的线程数量。这种进程与用户线程之间1:N的关系称为一对多的线程模型，如图12-4所示。

    用户线程的*优势在于不需要系统内核支援，劣势也在于没有系统内核的支援*，所有的线程操作都需要由用户程序自己去处理。线程的创建、销毁、切换和调度都是用户必须考虑的问题，而且由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理”·多处理器系统中如何将线程映射到其他处理器上”*这类问题解决起来将会异常困难，甚至有些是不可能实现的*。

  - Java、Ruby等语言都曾经使用过用户线程，最终又都放弃了使用它。但是近年来许多新的、以高并发为卖点的编程语言又普遍支持了用户线程，譬如 `Golanh`、 Erlang等，使得用户线程的使用率有所回升。

    <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200916214636.png" alt="image-20200916214635048" style="zoom: 25%;" />

- `使用用户线程加轻量级进程混合实现（N:M实现）`

  **内核线程和用户线程一起使用**的实现起使用的实现方式，被称为N:M实现。在这种混合实现下，既存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。而操作系统支持的`轻量级进程则作为用户线程和内核线程之间`的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级进程来完成，这大大降低了整个进程被完全阻塞的风险。在这种混合模式中，用户线程与轻量级进程的数量比是不定的，是N:M的关系，如图12-5所示，这种就是多对多的线程模型。

  <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200916214922.png" alt="image-20200916214920158" style="zoom:25%;" />

##### Java线程的实现

HotSpot，它的`每一个Java线程都是直接映射到一个操作系统原生线程来实现`的，而且中间没有额外的间接结构，所以 `HotSpot自己是不会去干涉线程调度的`（*可以设置线程优先级给操作系统提供调度建议*），全权交给底下的操作系统去处理，所以**何时冻结或唤醒线程、该给线程分配多少处理器执行时间、该把线程安排给哪个处理器核心去执行等，都是由操作系统完成的，也都是由操作系统全权决定的。**

线程模型只对线程的`并发规模和操作成本产生影响`，对Java程序的编码和运行过程来说，这些差异都是完全透明的。

个人总结：

​	内核线程实现（1:1实现）：好处是简单，`脏活累活都有操作系统干了`，坏处是并发规模受限

   用户线程实现（1:N实现）：操作系统是封装了一个通用的调度方式，你为了提升并发规模，想自定义，那`脏活累活就得自己干`，可能有的地方干的还不如操作系统呢。

   用户线程加轻量级进程混合实现（N:M实现）：属于典型的贪多嚼不烂，这玩意`没有“银弹”`，好处你贪了，两种方式的坏处肯定也带上了。

#### Java线程调度

`线程调度`是指**系统**`为线程分配处理器使用权`的过程，调度主要方式有两种，分别是协同式
（ Cooperative Threads- Scheduling）线程调度和抢占式（ Preemptive Threads- Scheduling）线程调度。

- `协同式线程调度`：*线程的执行时间由线程本身来控制*，线程把自己的工作执行完了之后，要*主动通知系统切换*到另外一个线程上去。
  - **好处：**协同式多线程的最大好处是`实现简单`，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以`一般没有什么线程同步`的问题。Lua语言中的“协同例程”就是这类实现。
  - **坏处：**它的坏处也很明显：`线程执行时间不可控制`，甚至如果一个线程的代码编写有问题，一直`不告知系统进行线程切换`，那么`程序`就会一直`阻塞`在那里。很久以前的 Windows3.x系统就是使用协同式来实现多进程多任务的，那是相当不稳定的，只要有*一个进程坚持不让岀处理器执行时间，就可能会导致整个系统崩溃*。
- `抢占式线程调度`：每个线程将由`系统来分配执行时间`，线程的切换不由线程本身来决定。譬如在Java中，*有 Thread:yield方法可以主动让出执行时间，但是如果想要主动获取执行时间，线程本身是没有什么办法的*。
  - **好处：**在这种实现线程调度的方式下，`线程的执行时间是系统可控的`，也不会有一个线程导致整个进程甚至整个系统阻塞的问题。**Java使用的线程调度方式就是抢占式调度**。与前面所说的 Windows3x的例子相对，在 Windows9xNT内核中就是使用抢占式来实现多进程的，当一个进程出了问题，我们还可以使用任务管理器把这个进程杀掉，而不至于导致系统崩溃。
  - **坏处：线程切换不可知，会产生线程安全问题。**

虽然说Java线程调度是系统自动完成的，但是我们仍然可以**"建议"**操作系统给某些线程多分配点执行时间，另外的一些线程则可以少分配一点—这项操作是通过设置线程优先级来完成的。Java语言一共设置了10个级别的线程优先级（ `Thread.MIN_PRIORITY至 Thread.MAX_PRIORITY`）。在两个线程同时处于 Ready状态时，优先级越高的线程越容易被系统选择执行。

Java对应windows优先级神秘代码：`221221`

`线程优先级并不是一项稳定的调节手段`，这不仅仅体现在某些操作系统上不同的优先级实际会变得相同这一点上，还有其他情况让我们`不能过于依赖线`程优先级：

- 优先级可能会被系统自行改变，例如在 Windows系统中存在一个叫“优先级推进器”的功能（ Priority boosting，当然它可以被关掉），大致作用是当*系统发现一个线程被执行得特别频繁时，可能会越过线程优先级去为它分配执行时间，从而减少因为线程频繁切换而带来的性能损耗*。因此，我们并不能在程序中通过优先级来完全准确判断组状态都为 Ready的线程将会先执行哪一个。

#### 状态转换

见**并发**-*Java线程的生命周期*。

### Java与协程

Java语言抽象出来*隐藏了各种操作系统线程差异性的统一线程接口*。语言与框架已经*自动屏蔽了相当多同步和并发的复杂性*，对于普通开发者而言，几乎不需要专门针对多线程进行学习训练就能完成一般的并发任务。但是在**某些场景下，却也已经显现出了疲态**。

#### 内核线程的局限

目前Java线程面临的困境：

今天对Web应用的服务要求，不论是在请求数量上还是在复杂度上，与十多年前相比已不可同日而语，

- `业务量的增长`

- 为了应对业务复杂化而`不断进行的服务细分`

现代BS系统中一次对外部业务请求的响应，往往需要分布在不同机器上的`大量服务共同协作来实现`，这种服务细分的架构在*减少单个服务复杂度、增加复用性的同时，也不可避免地增加了服务的数量，缩短了留给每个服务的响应时间*。这要求**每一个服务都必须在极短的时间内完成计算**，这样组合多个服务的总耗时才不会太长;**也要求每个服务提供者都要能同时处理数量更庞大的请求**，这样才不会出现请求由于某个服务被阻塞而出现等待。



Java目前的并发编程杋制就与上述架构趋势产生了一些矛盾，*1:1的内核线程模型是如今Java虚拟机线程实现的主流选择*，但是这种映射到操作系统上的线程天然的*缺陷是切换、调度成本高昂，系统能容纳的线程数量也很有限*。以前处理一个请求可以允许花费很长时间在单体应用中，具有这种线程切换的成本也是无伤大雅的，但现在在*每个请求本身的执行时间变得很短、数量变得很多的前提下用户线程切换的开销甚至可能会接近用于计算本身的开销*，这就会造成严重的浪费。传统的 JJava Web服务器的线程池的容量通常在几十个到两百之间，当程序员把数以百万计的请求往线程池里面灌时，系统即使能处理得过来，但其中的切换损耗也是相当可观的。现实的需求在迫使。

#### 协程的复苏

因为映射到了系统的内核线程中，所以切换调度成本会比较高昂

##### 为什么内核线程调度切换起来成本就要更高？

内核线程的调度成本主要来自于用户态与核心态之间的状态转换，而这两种状态转换的开销主要来自于**响应中断**、**保护**和**恢复执行现场**的成本。

内核线程调度流程：

- 处理器要去执行线程A的程序代码时，并不是仅有代码程序就能跑得起来，*程序是数据与代码的组合体，代码执行时还必须要有上下文数据的支撑*。

  “上下文”：

  - 以**程序员**的角度来看，是*方法调用过程中的各种局部的变量与资源*;
  - 以**线程**的角度来看，是*方法的调用栈中存储的各类信息*;
  - 以**操作系统和硬件**的角度来看，则是**存储在内存、缓存和寄存器中的一个个具体数值**。物理硬件的

- **各种存储设备**和**寄存器**是被操作系统内**所有线程共享的资源**，
- **当中断发生**，从线程A切换到线程B去执行之前，*操作系统首先要把线程A的上下文数据妥善保管好，然后把寄存器、内存分页等恢复到线程B挂起时候的状态*，这样线程B被重新激活后才能仿佛从来没有被挂起过。这种*保护和恢复现场的工作，涉及一系列数据在各种寄存器、缓存中的来回拷贝，当然不可能是一种轻量级的操作*。

如果说内核线程的切换开销是来自于保护和恢复现场的成本，那如*果改为采用用户线程，这部分开销就能够省略掉吗？答案是“不能”*。但是，一旦把保护、恢复现场及调度的工作从操作系统交到程序员手上，那我们就可以打开脑洞，通过玩出很多新的花样来缩减这些开销。

有一些古老的操作系统（譬如DOS）是单人单工作业形式的，天生就不支持多线程，自然也不会有多个调用栈这样的基础设施。而早在那样的蛮荒时代，就已经出现了今天被称为`栈纠缠（ StackTwine）`

由用户**自己模拟多线程、自己保护恢复现场的工作模式**。

- 其大致的原理是通过在**内存里给线程划出一片私有额外空间来模拟调用栈**，只要其他“**线程**”中方法**压栈、退栈时遵守规则**，不破坏这片空间即可，这样多段代码执行时就会像相互缠绕着一样，非常形象。

到后来，操作系统开始提供多线程的支持，靠应用自己模拟多线程的做法自然是变少了许多，但也并没有完全消失，而是`演化为用户线程继续存在`。

**用户线程是被设计成协同式调度（ Cooperative Scheduling）的，所以它有了一个别名—“协程”（ Coroutine）**。

- 又由于这时候的协程**会完整地做调用栈的保护、恢复工作**，所以今天也被称为“`有栈协程”（ Stackfull coroutineε）`。
- 与`“无栈协程”（ Stackless coroutine）`区分开。协程本质上是一种*有限状态机，状态保存在闭包里*，自然比有栈协程恢复调用栈要轻量得多。
  - 它的典型应用，即各种语言中的 await、 async、 yield这类关键字。
  - 无栈，但功能也相对更有限协程的**主要优势是轻量**。

无论是有栈协程还是无栈协程，都要比传统内核线程要轻量得多。如果进行量化的话，那么如果不显式设置-XsS或XX: Thread Stack size，则在**64位 Linux上 HotSpot的线程栈容量默认是1MB**，此外**内核数据结构（ Kernel data structures）还会额外消耗16KB内存**。

与之相对的，**一个协程的栈通常在几百个字节到几KB之间**，所以*Java虚拟机里线程池容量达到两百就已经不算小了，而很多支持协程的应用中，同时并存的协程数量可数以十万计*。

- 协程当然也有它的局限，需要在`应用层面实现的内容（调用栈、调度器这些）特别多`，这个缺点就不赘述了。
- 除此之外，协程在最初，甚至在今天很多语言和框架中会被**设计成协同式调度**，这样在语言运行平台或者框架上的调度器就可以做得非常简单。
- 不过有不少资料上显示，既然取了“协程‘这样的名字，它们之间就一定以协同调度的方式工作。笔者并没有査证到这种“规定”的出处，只能说这种提法在今天太过狭隘了，**非协同式、可自定义调度的协程的例子并不少见**。

具体到Java语言，还会有一些别的限制，譬如 Hot spot这样的虚拟机**，Java调用栈跟本地调用栈是做在一起的**。

- 如果在协程中**调用了本地方法**，还**能否正常切换**协程而不影响整个线程？
- 如果协程中**遇传统的线程冋步措施会怎样**？
  - 譬如`Kotlin`提供的协程实现，一旦遭遇 `synchronize`关键字，那**挂起来的仍将是整个线程**。

#### Java的解决方案

对于*有栈协程，有一种特例实现名为纤程（ Fiber）*，这个词最早是来自微软公司，后来微软还推出过系统层面的纤程包来方便应用做现场保存、恢复和纤程调度。

 OpenJDK在2018年创建了[Loom项目](https://zhuanlan.zhihu.com/p/96874807)，这是Java用来`应内核线程的局限`而提出的`官方解决方案`。日后该项目为Java语言引入的、*与现在线程模型平行的新并发编程机制*。

从 Oracle官方对“什么是纤程”的解释里可以看出，它就是一种`典型的有栈协程`。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200918093353.png" alt="image-20200918093351662" style="zoom:33%;" />

Loom项目背后的意图是`重新提供对用户线程的支持`，这些新功能*不是为了取代当前基于操作系统的线程实现，而是会有两个并发编程模型在Java虚拟机中并存*，可以在程序中同时使用。

新模型有意地*保持了与目前线程模型相似的API设计*，它们甚至可以拥有一个共同的基类，这样现有的代码就*不需要为了使用纤程而进行过多改动，甚至不需要知道背后釆用了哪个并发编程模型*。

Loom团队在 JVMLS2018大会上公布了他们对Jetty基于纤程改造后的测试结果，同样在5000QPS的压力下，

- 以**容量为400的线程池的传统模式**：请求响应延迟在10000至20000毫秒之间。
- **每个请求配以一个纤程的新并发处理模式**：延迟普遍在200毫秒以下。

![image-20200918093902470](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200918093903.png)



**同等的机器下，请求的延迟变短，意味着能支持更大的并发。那省出来的机器就是创造的价值。**



在新并发模型下，一段使用纤程并发的代码会被分为两部分—执行过程（ Continuation）和调度器（ Scheduler）。

- **执行过程**主要用于*维护执行现场，保护、恢复上下文状态*
- **调度器**则*负责编排所有要执行的代码的顺序*。

将**调度程序与执行过程分离的好处**是，*用户可以选择自行控制其中的一个或者多个*，而且Java中现有的调度器也可以被直接重用。事实上，*Loom中默认的调度器就是原来已存在的用于任务分解的 Fork/Join池*（JDK7中加入的 ForkJoinPool）。

Loom项目目前仍然在进行当中，还没有明确的发布日期，上面笔者介绍的内容日后都有被改动的可能。如果读者现在就想尝试协程，那可以在项目中使用 Quasar协程库口，这是一个不依赖Java虚拟杋的独立实现的协程库。**不依赖虚拟机来实现协程**是完全可能的， Kotlin语言的协程就已经证明了这一点。 Quasar的实现*原理是字节码注入，在字节码层面对当前被调用函数中的所有局部变量进行保存和恢复*。这种不依赖Java虚拟杋的现场保护虽然能够工作，但很影响性能，对即时编译器的干扰也非常大，而且必须要求用户手动标注每一个函数是否会在协程上下文被调用，这些都是未来Loom项目要解决的问题。

### 线程安全

#### 面向过程与面向对象

在软件业发展的初期，程序编写都是*以算法为核心*的，程序员会*把数据和过程分别作为独立的部分来考虑*，`数据代表问题空间中的客体，程序代码则用于处理这些数据`，这种思维方式**直接站在计算机的角度去抽象问题和解决问题**，被称为**面向过程的编程思想**。

与此相对，**面向对象**的编程思想则站`在现实世界的角度去抽象和解决问题，它把数据和行为都看作对象的一部分`，这样可以让程序员能以符合现实世界的思维方式来编写和组织程序。

面向对象的编程思想极大地提升了现代软件开发的效率和软件可以达到的规模，但是现实世界与计算机世界之间不可避免地存在一些差异。

- 例如，人们很难想象现实中的对象在一项工作进行期间，会被不停地中断和切换，对象的属性（数据）可能会在中断期间被修改和变脏，而这些事件在计算机世界中是再普通不过的事情。有时候，*良好的设计原则不得不向现实做出一些妥协，我们必须保证程序在计算机中正确无误地运行*，**然后再考虑如何将代码组织得更好，让程序运行得更快**。

高效并发：`首先`需要`保证并发的正确性`，`然后`在此基础上`来实现髙效`。本章就先从如何保证并发的正确性及如何实现线程安全说起。

#### Java语言中的线程安全

按照线程安全的“安全程度”由强至弱来排序，我们山可以将Java语言中各种操作共享的数据分为以下五类:

`不可变 < 绝对线程安全 < 相对线程安全 < 线程兼容 < 线程对立`

##### 1.不可变

在Java语言里面（*特指JDK5以后，即Java内存模型被修正之后的Java语言*），**不可变（ Immutable）的对象一定是线程安全**的，无论是对象的方法实现还是方法的调用者，都不需要再进行任何线程安全保障措施。

只要一个不可变的对象**被正确地构建出来**（`即没有发生this引用逃逸的情况`），那其*外部的可见状态永远都不会改变，永远都不会看到它在多个线程之中处于不一致的状态*。“不可变”带来的安全性是最直接、最纯粹的。



Java语言中，如果多线程共享的数据是一个**基本数据类型**，那么只要在**定义时使用 final关键字修饰它就可以保证它是不可变的**。

如果*共享数据是一个对象，由于Java语言目前暂时还没有提供值类型的支持*，那就需要`对象自行保证其行为不会对其状态产生任何影响才行`。

- 不妨类比 java.lang.String类的对象实例，它是一个典型的不可变对象，用户调用它的subString()、 replace()和 concat()这些方法都不会影响它原来的值，只会返回一个新构造的字符串对象保证对象行为不影响自己状态的途径:

创建不可变对象：

1. 

在Java类库AP中符合不可变要求的类型：

- `String`
- `枚举`类型
- `java.lang.Number的部分子类`，如`Long`和 `Double`等数值包装类型、`Biglnteger`和 `BigDecimal`等大数据类型。

*但同为 Number子类型的原子类 Atomiclnteger和 AtomicLong则是可变的*，不妨看看这两个原子类的源码，想一想为什么它们要设计成可变的。

##### 绝对线程安全

`绝对的线程安全`能够完全满足 Brian goetz给出的线程安全的定义：

一个类要达到“*不管运行时环境如何，调用者都不需要任何额外的同步措施*”可能需要付出非常高昂的甚至不切实际的代价。

在 Java aPI中标注自己是线程安全的类，大多数都不是绝对的线程安全。

如果说java.util.Vector是一个线程安全的容器，即使它所有的方法都被修饰成 synchronized，也不意味着调用它的时候就永远都不再需要同步手段了。

- 调用对象的方法是绝对线程安全的，但两个方法中间的间隔不是线程安全的。

假如 Vector定要做到绝对的线程安全，那就*必须在它内部维护一组一致性的快照访问*才行，每次对其中元素进行改动都要产生新的快照，这样要付出的时间和空间成本都是非常大的。

##### 相对线程安全

`相对线程安全`就是我们*通常意义上所讲的线程安全*，它需要保证对这个*对象单次的操作是线程安全*的，我们在调用的时候不需要进行额外的保障措施，但是对于*一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性*。

在Java语言中，大部分声称线程安全的类都属于这种类型，例如`Ⅴector`、 `HashTable`、 `Collections的synchronizedCollection（）方法包装`的集合等

##### 线程兼容

`线程兼容`是指*对象本身并不是线程安全*的，但是可以通过在*调用端正确地使用同步手段*来保证对象在并发环境中可以安全地使用。我们平常说一个类不是线程安全的，通常就是指这种情况。

Java类库APP中大部分的类都是线程兼容的，*如与前面的Ⅴector和 Hashtable相对应的集合类 Array list和HashMap等*。

##### 线程对立

`线程对立`是指*不管调用端是否采取了同步措施，都无法在多线程环境中并发使用代码*。

由于Java语言天生就支持多线程的特性，线程对立这种排斥多线程的代码是很少出现的，而且*通常都是有害的，应当尽量避免*。

一个线程对立的例子是 Thread类的 suspend和 resumed方法。

- 如果有两个线程同时持有一个线程对象，一个尝试去中断线程，一个尝试去恢复线程，在并发进行的情况下，无论调用时是否进行了同步，目标线程都存在死锁风险——假如 *suspend中断的线程就是即将要执行 resumed的那个线程，那就肯定要产生死锁了*。也正是这个原因， suspend()和 resumed方法都已经被声明废弃了。
- 常见的线程对立的操作还有 System.setIn()、 Sytem.setOut()和 System.runFinalizersOn Exit()等。
  - 如果程序调用了System.runFinalizerOnExit(true);，那么JVM会对所有的还未结束的对象调用Finalizer。

#### 线程安全的实现方法

如何实现线程安全与代码编写有很大的关系，但虚拟机提供的同步和锁机制也起到了至关重要的作用。

##### 1.互斥同步

`互斥同步（ Mutual exclusion＆ Sy nchronization）`是一种最常见也是最主要的并发正确性保障手段。*同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一条（或者是一些，当使用信号量的时候）线程使用*。

而互斥是实现同步的一种手段

- 临界区（ Critical section）
- 互斥量（ Mutex）
- 信号量（ Semaphore）都是常见的互斥实现方式。

因此在“互斥同步”这四个字里面，**互斥是因，同步是果;互斥是方法，同步是目的**。

在Java里面，最基本的互斥同步手段就是 `synchronized`关键字，是一种块结构的同步语法。 synchronized关键字`经过 Javac编译之后`，会在同步块的前后分别形成`monitorenter`和 `monitorexit`这两个字节码指令。这两个字节码指令都需要一个 `reference类型`的参数来指明要锁定和解锁的对象。

- 如果Java源码中的 sy nchronized明确指定了对象参数，那就以这个对象的引用作为 reference;
- 如果没有明确指定，那将根据 synchronized修饰的方法类型（如实例方法或类方法），来决定是取代码所在的对象实例还是取类型对应的 class对象来作为线程要持有的锁。

两个synchronized的直接推论：

- 被 synchronized修饰的同步块对同一条线程来说是**可重入**的。这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况。

- 被 synchronized修饰的同步块在持有锁的线程执行完毕并释放锁之前，会无条件地阻塞后面其他线程的进入。
  - 这意味着无法像处理某些数据库中的锁那样，**强制已获取锁的线程释放锁**;也无法强制正在等待锁的线程中断等待或超时退出。

从执行成本的角度看，持有锁是一个重量级（ Heavy- Weight）的操作。

- Java的线程是**映射到操作系统的原生内核线程**之上的，如果要阻塞或唤醒一条线程，则需要操作系统来帮忙完成，这就不可避免地陷入**用户态到核心态的转换中**，进行这种状态转换需要耗费很多的处理器时间。*如果代码特别简单状态转换消耗的时间甚至会比用户代码本身执行的时间还要长。*







### 锁优化











### 如何确定垃圾？

引用计数法

在为对象添加一个引用时，引用计数加 1；在为对象删除一个引用时，引进计数减1；如果一个对象的引用计数为 0，则表示此刻该对象没有被引用，可以被回收。

容易产生循环引用的问题，即互为引用，引用计数一直为1。

![image-20200910215537317](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200910215539.png)

![image-20200911165721598](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200911165730.png)

可达性分析通过根搜索算法（GC Roots Tracing）来实现。

首先定义GC Roots对象，以`GC Roots对象作为起点`根据`引用关系`向下搜索，在一个对象到任何GC Roots都没有引用链相连时，说明其已经死亡，但不可达对象要经过至少两次标记才能判定其是否可以被回收。

根搜索算法主要针对栈中的引用、方法区中的静态引用和JNI中的引用展开分析。

#### Java中哪些是GC Root是对象？

在Java技术体系里面，固定可作为 GC Roots的对象包括以下几种：

- 在虚拟机栈（`栈帧中的本地变量表`）中引用的对象，譬如各个线程被调用的方法堆栈中使用到的`参数、局部变量、临时变量`等。

- 在`方法区中类静态属性引用的对象`，譬如Java类的`引用类型静态变量`。

- 在`方法区中常量引用的对象`，譬如`字符串常量池`（ String Table）里的引用。

- 在本地方法栈中JNⅠ（即通常所说的 Native方法）引用的对象。

- Java虚拟机内部的引用，如基本数据类型对应的Class对象，一些`常驻的异常对象`（比如NullPointExcepiton、 OutOfMemoryError）等，还有`系统类加载器`。

- 所有`被同步锁`（ synchronized关键字）`持有的对象`

- 反映Java虚拟机内部情况的JMⅹBean、JMTI中注册的回调、本地代码缓存等。

  除了这些固定的 GC Roots集合以外，根据`用户所选用的垃圾收集器以及当前回收的内存区域不同`，还可以有其他对象“`临时性`”地加入，共同构成完整 GC Roots集合。

  譬如后文将会提到的分代收集和局部回收（ Partial gc），如果只针对Java堆中某一块区域发起垃圾收集时（如最典型的只针对新生代的垃圾收集），必须考虑到`内存区域`是虚拟机自己的实现细节（在用户视角里任何内存区域都是不可见的），更`不是孤立封闭`的，所以`某个区域里的对象完全有可能被位于堆中其他区域的对象所引用`，这时候就需要将这些关联区域的对象也一并加GC Roots集合中去，才能保证可达性分析的正确性

  目前最新的几款垃圾收集器(OpenJDK中的G1、 Shenandoah、ZGC),无一例外都具备了局部回收的特征，为了避免 GC Roots包含过多对象而过度膨胀，它们在实现上也做出了各种优化处理。

#### Java中的四种引用类型

在Java中一切皆对象，对象的操作是通过该对象的引用（Reference）实现的，Java中的引用类型有4种，分别为强引用、软引用、弱引用和虚引用。

- 强引用：最传统的引用定义，值代码之中普遍存在的引用赋值。在把`一个对象赋给一个引用变量即 new`时，这个引用变量就是一个`强引用`。有强引用的对象定为可达性状态，所以不会被垃圾回收机制回收。因此，强引用是造成Java内存泄漏（ Memory link）的主要原因。
  - 定义：如果 reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称该 reference数据是代表某块内存、某个对象的引用。
- 软引用：描述一些还有用，但非必须的对象。如果一个对象`只有软引用`，在系统将要发生`内存溢出异常前`，会把这些对象`列进回收范围`之中进行第`二次回收`，如果这次回收还没有足够的内存，才会抛出内存溢出异常。软引用通过 SoftReference类实现
- 弱引用：描述一些非必须的对象，如果一个对象只有弱引用，则在`垃圾回收过程中一定会`被回收。弱引用通过 WeakReference类实现。
- 虚引用：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也`无法`通过虚引用来`取得一个对象实例`。为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器`回收时收到一个系统通知`。`虚引用和引用队列联合使用`，主要用于跟踪对象的垃圾回收状态。虚引用通过 PhantomReference类实现

#### 对象真正死亡？

真正宣告一个对象死亡，至少要经历两次标记，一次可达性分析标记，一次在判定有必要执行 finalized方法判定后，放入F- Queue中等待Finalizer线程去执行，之后收集器将对F- Queue中的对象进行第二次小规模的标记。：

- 如果对象在进行可达性分析后发现`没有与 GC Roots`相连接的`引用链`，那它将会被第一次标记，
- 随后`进行一次筛选`，筛选的条件是此对象是否有必要执行 finalized方法。假如对象没有覆盖 finalized方法，或者 finalize方法已经被虚拟机调用过，那这个对象就死了。
- 如果这个对象被判定为确`有必要执行 finalized方法`，那么该对象将会被放置在一个名为`F- Queue的队列`之中，并在稍后由一条由虚拟机自动建立的、`低调度优先级`的 `Finalizer线程去执行`它们的 finalized方法。这里所说的“执行”是指虚拟机会`触发`这个方法开始`运行`，但并`不承诺`一定会`等待`它运行`结束`。这样做的原因是，如果某个对象的 finalize方法`执行缓慢`，或者更极端地发生了`死循环`，将很可能导致F- Queue队列中的其他对象永久处于等待，甚至导致整个内存回收子系统的崩溃。
- finalized方法是对象逃脱死亡命运的最后一次机会，`稍后收集器将对F- Queue中的对象进行第二次小规模的标记`，如果对象要在 finalized中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可，`譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量`，那在第二次标记时它将被移出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的要被回收了。
  - 注：但也`不是百分百成功`，因为不知道收集器啥时候来遍历F-Queue，所以不能做关闭资源的操作。 而且finalize方法只能被系统调用一次。


#### 方法区垃圾回收

虽然方法区垃圾回收性价比低，回收的判断条件苛刻，但是在大量使用反射、动态代理、 CGLib等`动态生成字节码`的框架，动态生成JSP以及OSGi这类`频繁自定乂类加载器`的场景中，通常都需要Java虚拟机`具备类型卸载`的能力，以保证不会对方法区造成过大的内存压力。

方法区的垃圾收集主要回收两部分内容

- `废弃`的常量：回收常量池中的字面量，接口、方法、字段的符号引用等。
  
  - `字面量：`假如一个字符串“java曾经进入常量池中，但是当前系统又没有任何一个字符串对象的值是“java”，换句话说，已经`没有任何字符串对象引用`常量池中的“java常量，且虚拟机中`也没有其他地方引用`这个字面量。如果JVM判断`有必要的话会进行回收`。
- `不再使用的类型`：判断一个类是否属于不再使用的类，需满足以下三个条件。
  - 该类`所有的实例`都已经`被回收`，也就是Java堆中不存在该类及其任何派生子类的实例。
  
  - `加载该类的类加载器已经被回收`，这个条件除非是经过精心设计的可替换类加载器的场景，如OSGi、JSP的重加载等，否则通常是很难达成的。
  
  - 该类对应的 `java. lang.Class`对象没有在任何地方被引用，无法在任何地方通过`反射`访问该类的方。
  
    注：Java虚拟机被允许对满足上述三个条件的无用类进行回收，这里说的仅仅是“`被允许`”，而`并不是和对象一样，没有引用了就必然会回收`。关于是否要对类型进行回收， Hot spot虚拟机提供了Xnoclassgc参数进行控制。



### 垃圾回收算法？

垃圾回收算法，始于分带收集理论。

而分带收集理论建立在两个分代假说之上：绝大多数对象都是朝生夕灭的，熬过越多次垃圾收集过程的对象就越难以消亡。

这两个假说奠定了多款常用的垃圾收集器的一致的设计原则：收集器应该将Java堆划分出不同的区域，然后将回收对象依据其年龄（年龄即对象熬过垃圾收集过程的次数）分配到不同的区域之中存储。

将大多数对象都是朝生夕灭对象集中放在一起，每次回收时`只关注如何保留少量存活`，而不是去标记那些大量将要被回收的对象，就能以较低代价回收到大量的空间。

如果剩下的都是`难以消亡`的对象，那把它们集中放在一块，虚拟机便可以使用`较低的频率`来回收这个区域，这就同时兼顾了垃圾收集的时间开销和内存的空间有效利用。

`划分出不同的区域之后`，垃圾收集器才可以每次只回收其中某一个或者某些部分的区域——才有了“ MinorGC MajorGC Full Go”这样的`回收类型的划分`；

也才能够`针对不同的区域安排与里面存储对象存亡特征相匹配`的垃圾收集算法。



但分带收集不是简单的划分内存，对象存在跨代引用。在新生代用数据结构标识出老年代哪些地方存在跨代引用。MinorGC时将其加入到GC Roots扫描。



通常能单独发生收集行为的只是新生代，所以这里“反过来”的情况只是理论上允许，实际上除了CMS收集器，其他都不存在只针对老年代的收集。

分代收集算法根据对象的不同类型将内存划分为不同的区域，JVM将堆划分为新生代和老年代。

- `新生代：`主要存放新生成的对象，其特点是对象数量多，但是小而且生命周期短，采用复制算法。
- `老年代：`主要存放大对象和生命周期长的对象，因此可回收的对象相对较少。采用标记清楚。

Jaa中常用的垃圾回收算法有

- `标记-清除算法：`执行效率随内存增长而降低，内存碎片化。

- `标记-复制算法：`将内存分为两块，每次只使用一块，用完后，将存活对象复制到另一块，已用过的内存，一次性清理掉。

  内存清理销量高，且易于实现，并且没有空间碎片 。

  但由于同一时刻只有一个内存区域可用，因此存在大量的内存浪费。但如果有大量长时间存活的对象时，这些对象的来回复制也会影响系统的运行效率。因此，该算法只在对象为“朝生夕死”状态时运行效率较高。

  优化：因为98%的对象熬不过第一轮垃圾收集。为了针对空间浪费情况，设计出Eden，和两个survivor，为8:1:1，这样只浪费了10%。并提供了分配担保机制，如果存活大于10%，这些对象讲直接进入老年代。不能用在老年代的原因：存活率较高时，复制效率低，并且需要分配担保。

- `标记-整理算法：`标记整理算法结合了标记清除算法和复制算法的优点，其标记阶段和标记清除算法的标记阶段相同，在标记完成后将存活的对象移到内存的另一端，然后清除该端的对象并释放内存。但标记整理是一种移动式的回收算法，在老年代这种大量存活对象的区域，移动对象并更新所有引用这些对象的地方将是极为负重的操作，并且移动时需要暂停用户应用程序（STW）。

#### 分代收集算法和分区收集算法

  - 分代收集算法：JVM根据对象存活周期的不同将内存划分为新生代、老年代和永久代，并根据各年代的特点分别采用不同的GC算法。
    - `新生代：`主要存放新生成的对象，其特点是对象数量多，但是小而且生命周期短，采用复制算法。
    - `老年代：`主要存放大对象和生命周期长的对象，因此可回收的对象相对较少。采用标记清楚。
  - 分区收集算法：分区算法将整个堆空间`划分为连续的大小不同的小区域`，对每个小区域都`单独进行内存使用和垃圾回收`，这样做的好处是可以根据每个小区域内存的大小灵活使用和释放内存。
    分区收集算法可以根据系统可接受的停顿时间，`每次都快速回收若干个小区域`的内存，`以缩短垃圾回收时系统停顿的时间`，最后以多次并行累加的方式逐步完成整个内存区域的垃圾回收。如果垃圾回收机制一次回收整个堆内存，则需要更长的系统停顿时间，长时间的系统停顿将影响系统运行的稳定性。

### 为什么MajorGC之前，要进行一次MinorGC？



因为老代空间中的对象可能持有对年轻代空间中的对象的引用。如果年轻代空间没有被垃圾收集，那么在老代空间中`持有对年轻代空间中的对象的引用`的任何`对象`都`不能`被垃圾收集。

![image-20200911171512671](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200911171514.png)

老年代的是GC root是？？  这

### 垃圾收集器





## 熟悉

### （新）多线程

​	JVM中的线程与操作系统中的线程是相互对应的。在JVM线程的本地存储、缓冲区分配、同步对象、栈、程序计数器等准备工作都完成时，JVM会调用操作系统的接口创建一个与之对应的原生线程。
​	操作系统负责调度所有线程，并为其分配CPU时间片，在原生线程初始化完毕时，就会调用Java线程的run()执行该线程，在线程结束时，会释放原生线程和Java线程所对应的资源。
​	JVM后台运行的线程主要有

- 虚拟机线程（ JVMThread）：虚拟机线程在JVM到达安全点（ SafePoint）时出现
- 周期性仼务线程：通过定时器调度线程来实现周期性操作的执
- GC线程：GC线程支持JⅥM中不同的垃圾回收活动	
- 编译器线程：编译器线程在运行时将字节码动态编译成本地平台机器码，是JWM跨平台的具体实现
- 信号分发线程：接收发送到JM的信号并调用JVM方法。





## 了解



### 内存和硬盘

内存条才是电脑真正的内存，硬盘是电脑的外存，即存储设备，IO设备。外存中任何数据只有调入内存中才能真正使用。