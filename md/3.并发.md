当线程 A 执行 CPU 计算的时候，线程 B 执行 I/O 操作；当线程 A 执行 I/O 操作的时候，线程 B 执行 CPU 计算



# 并发

## 精通

### （新）简述线程、进程、程序的基本概念？

`程序`，存储在磁盘上的能够`被系统运行`的含有`指令`和`数据`的文件。

`进程`，是系统运行程序的基本单位。当程序在执行时，将会被操作系统载入内存中，计算机运行程序的指令，去操作数据，`正在执行中的程序，就是进程`。

`线程`，与进程相似，但线程是一个比进程更小的执行单位，被称为轻量级进程。一个进程在其执行的过程中可以产生多个线程。在Java中，多个线程共享进程的堆和方法区（J0K1.8之后的元空间）资源，但是每个线程有自己的程序计数器、虚拟机栈和本地方法栈。

基本上各进程是独立的，但同一进程中的线程极有可能会，互相协作，相互影响。

`线程可以理解为需要CPU处理的细分任务，进程就是线程汇总出来为人类实现特定功能，它和卖CPU说的8核16线程可不是一个概念，16线程相当于16个虚拟核心`。

### （新）多线程的优缺点？

1）好处

- 使用多线程可以把`程序中占据时间长的任务放到后台`去处理，如图片、视屏的下载。
- 发挥`多核处理器的优势`，并发执行让系统运行的更快、更流畅，用户体验更好。

2）坏处

- 大量的线程`降低代码的可读性`。
- 更多的线程需要`更多的内存空间`。
- 当多个线程对同一个资源出现争夺时候要注意`线程安全的问题`。

### （新）什么是多线程上下文切换？

多线程会共同使用一组计算机上的 CPU ，而线程数大于给程序分配的 CPU 数量时，为了让各个线程都有执行的机会，就需要`轮转使用 CPU` 。CPU利用时间片轮询来为每个任务都服务一定的时间，然后把当前任务的状态保存下来，继续服务下一个任务。`任务的状态保存及再加载就叫作线程的上下文切换`。线程切换时CPU寄存器和程序计数器所保存的当前线程的信息，就是上下文。

- 进程：指一个运行中的程序的实例。在一个进程内部可以有多个线程在同时运行，并与创建它的进程共享同一地址空间（一段内存区域）和其他资源。
- 上下文：指线程切换时`CPU寄存器和程序计数器所保存的当前线程的信息`。
- 寄存器：指**CPU内部容量较小但速度很快的内存区域**（与之对应的是CPU外部相对较慢的RAM主内存）。寄存器**通过对常用值（通常是运算的中间值）的快速访问来加快计算机程序运行的速度**。
- 程序计数器：是**一个专用的寄存器**，用于`表明指令序列中CPU正在执行的位置`，存储的值为正在执行的指令的位置或者下一个将被执行的指令的位置，这依赖于特定的系统。

#### 上下文切换流程？

- （1）挂起一个进程，将这个进程在CPU中的状态（`上下文信息`）
  `存储于内存的PCB中`
- （2）在PCB中检索下一个进程的上下文并`将其在CPU的寄存器中恢复`
- （3）`跳转到程序计数器所指向的位置`（即跳转到进程被中断时的代码行）并恢复该进程

![image-20200912173053210](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200912173054.png)

#### 引起线程上下文切换的原因引起线程上下文切换（线程让出CPU的情况）的原因？

- 当前正在执行的任务完成，系统的`CPU正常调度`下一个任务
- 当前正在执行的任务遇到`I0等阻塞操作，调度器挂起此任务`，继续调度下一个任务。
- 多个任务并发抢占锁资源，`当前任务没有抢到锁资源`，`被调度器挂起`，继续调度下一个任务
- 用户的`代码挂起当前任务`，比如线程执行 `sleep方法，让出CPU`
- `硬件中断`。

### （新）进程调度算法

系统`多进程分时复用`

进程调度算法包括：

- 优先调度算法
  - `先来先服务调度算法：`运行最早进入的任务，实现简单相对公平
  - `短作业优先调度算法：`估运行时间最短的进程，为其分配CPU资源并运行。该算法优`先运行短时间作业`，以提高CPU整体的`利用率和系统运行效率`，某些大任务可能会出现长时间得不到调度的情况（**饥饿**）。

- 高优先权优先调度算法
  - `非抢占式优先杈算法：`该算法**优先运行优先权高**的作业，且一旦将CPU分配给某个进程，就**不会主动回收CPU资源**，直到任务主动放弃。
  - `抢占式优先权调度算法：`抢占式优先调度算法首先把**CPU资源分配**给优先权最高的任务并运行，但如果在运行过程中出现比当前运行**任务优先权更高**的任务，调度算法就会暂停运行该任务并回收CPU资源，为其分配新的优先权更高的任务。该算法真正保障了CPU在整个运行过程中**完全按照任务的优先权分配资源**，这样如果临时有紧急作业，则也可以保障其第一时间被执行。
  - `高响应比优先调度算法：`高响应比优先调度算法使用了动态优先权的概念，即任务的`执行时间越短，其优先权越高，任务的等待时间越长，优先权越高`。
    高响应比优先调度算法在`保障效率`（短作业优先能在很大程度上提高CPU的使用率和系统性能）的基础上`尽可能提高了调度的公平性`（随着任务等待时间的增加，优先权提高，遵循了先来先到原则）。

- 基于时间片的轮转调度算法。

  - `时间片轮转算法：`时间片轮转法指按照`先来先服务原则`从就绪队列中取出一个仼务，并为该任务分配一定的CPU时间片去运行，在进程使用完CPU`时间片后由一个时间计时器发出时钟中断请求`，`调度器`在收到时钟中断请求信号后停止该进程的运行并将该进程放入就绪`队列的队尾`，然后从就绪队列的队首取出一个任务并为其分配CPU时间片去执行。这样，就绪队列中的任务就将轮流获取一定的CPU时间片去运行

  - 多级反馈队列调度算法：多级反馈队列调度算法`在时间片轮询算法的基础上`设置`多个就绪队列`，并为每个就绪队列都设置不同的优先权。队列的优先权越高队列中的任务被分配的时间片就越大。默认第一个队列优先权最高，其他次之。

    调度流程：

    - 任务进来，先放第一个队列末尾，规定时间内任务没有运行完成，将此任务放入第二队列，以此类推。前面队列的任务的全部完成后，调度器才回调度当前队列，并且前面队列有新任务进来时，它还会被停止，然后放入队列末尾。

    先来先服务调度算法和时间片轮询算法的优势，使得对进程的调度更加合理。

### Java 中用到的线程调度算法是什么？

一个多线程的并发运行，其实是指从宏观上看，各个线程轮流获得 CPU 的使用权，分别执行各自的任务。Java 虚拟机的一项任务就是负责按照特定机制为多个线程分配 CPU 的使用权。

Java 虚拟机采用`抢占式调度模型`，是指优先让可运行池中`优先级高的线程占用 CPU` ，如果可运行池中的线程优先级相同，那么就随机选择一个线程，使其占用 CPU 。优先级低的线程只是获取CPU时间片的优先级被降低，但**不会永久分配不到CPU时间片**。Java的线程调度在保障效率的前提下尽可能保障线程调度的公平性。容易`导致其他线程饥饿`。

#### 什么是线程饥饿？

饥饿，一个或者多个线程因为种种原因无法获得所需要的资源（数据、CPU时间片、运行指令等），导致一直无法执行的状态。

Java 中导致饥饿的原因：

- `高优先级线程`吞噬所有的低优先级线程的 CPU 时间。
- `线程被永久堵塞在一个等待进入同步块的状态`，因为其他线程总是能在它之前持续地对该同步块进行访问。
- `线程在等待一个本身也处于永久等待完成的对象`(比如调用这个对象的 `wait 方法`)，因为其他线程总是被持续地获得唤醒。

#### 你对线程优先级的理解是什么？

每一个线程都是有优先级的，一般来说，`高优先级的线程在运行时会具有优先权`。线程优先级是一个 int 变量(从`1-10`)，1 代表最低优先级，10 代表最高优先级。我们可以定义线程的优先级，但是这并`不能保证高优先级`的线程会在低优先级的线程前`执行`。Java 的线程优先级调度会委托给操作系统去处理，所以与具体的操作系统优先级有关，如非特别需要，一般无需设置线程优先级。

### （新）什么叫线程安全？

线程安全，指某个函数、函数库在多线程环境中被调用时，`能够正确地处理多个线程之间的共享变量`，使程序功能正确完成。可能会带来内存泄漏、上下文切换、死锁等问题。

### （新）并发原理

#### 并发编程需要解决的核心问题？

**分工**：指的是如何`高效地拆解任务并分配给线程`，直接决定了并发程序的性能。一个任务下发了，怎么执行能更快的完成。

**同步（协作）**：指的是线程之间如何协作，一个线程执行完了一个任务，如何通知执行后续任务的线程开工。即当某个条件不满足时，线程需要等待，当某个条件满足时，线程需要被唤醒执行。

**互斥**：也叫线程安全。是保证同一时刻只允许一个线程访问共享资源。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。可以看做一种特殊的协作。

Java解决并发编程：

![image-20200912162649563](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200912162658.png)



#### 并发产生的原因？

为了平衡CPU、内存、I/O 设备三者速度的差异：

`缓存：CPU 增加了缓存`，以均衡与内存的速度差异。但在多核时代，每颗 CPU 都有自己的缓存，存在CPU 缓存与内存的数据一致性问题。一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为可见性。

`指令优化：`为了使得`缓存`和`处理器的内部单元`能够得到更加合理地`利用`，编译程序优化`指令执行次序`。

`线程切换：`操作系统增加了进程、线程，用以`分时复用 CPU`，进而均衡 CPU 与 I/O 设备的速度差异。`但操作系统切换线程可以在任何一条CPU指令完成后`，所以无法保证高级语言的操作符的原子性。我们把一个或者多个操作在 `CPU 执行的过程中不被中断`的特性称为`原子性`：解决原子性问题，是要保证中间状态对外不可见。

**为了获得更好的执行效能**，Java内存模型**并没有限制执行引擎**使用处理器的特定寄存器或缓存来和主内存进行交互，也**没有限制即时编译器**是否要进行调整代码执行顺序这类优化措施。

#### Java如何解决可见性、有序性、原子性？

Java 内存模型是一个规范，规范了 JVM 如何提供按需禁用缓存和编译优化的方法以保证有序性问题。包括volatile、synchronized 和 final 三个关键字，以及8项 Happens-Before 规则保证前面一个操作的结果对后续操作是可见的。

**三个关键字：**

volatile：告诉编译器，对这个变量的读写，不能使用 CPU 缓存，必须从内存中读取或者写入。**应用场景应该是不依赖之前的结果而改变数据**。并在1.5版本通过程序顺序性、volatile 变量规则、传递性这三项Happens-Before规则，对volatile进行了语义增强，如下所示： 

![image-20200914155306845](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200914155308.png)

`final：`这个变量生而不变，可以可劲儿优化。

- Java 编译器在 1.5 以前的版本会因构造函数的错误重排导致线程可能看到 final 变量的值会变化。1.5以后对final类型变量得类型变量的重排进行了约束，但要避免构造函数溢出。

  ![image-20200914155058458](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200914155100.png)

  将this赋值给global.obj时，this还没有初始化完

`synchronized：`为了保证`操作`的`原子性`，在多核CPU时代，不需要`禁止线程切换`，还需要“同一时刻只有一个线程执行”这个条件，称之为`线程互斥`。Java提供了锁技术，锁并不能改变CPU时间片切换的特点，只是保证当CPU走了后，不让其他线程操作数据。当其他线程要访问锁修饰的这个资源时，发现锁还未释放，所以只能在外面等待，以此来保证操作的原子性。并根据 Happens-Before 中的`管程中锁的规则`，保证后续线程`加锁时`对受保护资源的`可见性`。

`（保护资源）对象`：每个对象都有唯一的一把锁。加锁只会保证框定的区域（临界区）里，对保护资源  `操作`  （方法：可以有多个操作）的原子性，所以不能多把锁保护同一个资源。

锁，一定有一个要锁定的对象（临界区），至于这个`锁定的对象要保护的”资源“`以及在哪里加锁 / 解锁（门），就属于设计层面的事情了，受保护资源和锁之间合理的关联关系应该是 `N:1` 的关系。

- 同步代码块：锁定指定的一个 obj 对象
- 修饰非静态方法：当前实例对象 this
- 修饰静态方法：锁定的是当前类的 Class 对象，在上面的例子中就是 Class X

`原理：`

加锁的本质（待整理）：synchronized的理解是这样，它并不能改变CPU时间片切换的特点，只是当其他线程要访问这个资源时，发现锁还未释放，所以只能在外面等待。

Sync优化：sync锁的对象monitor指针指向一个ObjectMonitor对象，所有线程加入他的entrylist里面，去cas抢锁，更改state加1拿锁，执行完代码，释放锁state减1，和aqs机制差不多，只是所有线程不阻塞，cas抢锁，没有队列，属于非公平锁。 wait的时候，线程进waitset休眠，等待notify唤醒。

**8项 Happens-Before 规则：**

- `程序的顺序性规则:``一个线程`中，按照程序顺序，前面的操作 Happens-Before 于后续的任意操作。
- `volatile 变量规则：`这条规则是指对一个 volatile 变量的写操作， Happens-Before 于后续对这个 volatile 变量的读操作。
- `传递性：` 这条规则是指如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C。
- `管程中锁的规则：`是指对`一个锁的解锁` Happens-Before 于后续对这个锁的加锁。线程B进入同步块后能看见线程A的写操作
- `线程 start() 规则：`它是指主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。
- `线程 join() 规则：`这条是关于线程等待的。`它是指主线程 A 等待子线程 B 完成`（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），`主线程能够看到子线程的操作`。
- `线程中断规则:`对线程interrupt（）方法的调用happen—before发生于被中断线程的代码检测到中断时事件的发生。可以通过Thread::interrupted（）方法检查是否有中断发生。
- `对象终结规则：`一个对象的初始化完成（构造函数执行结束）happen—before它的finalize（）方法的开始。

### 互斥锁

#### 锁和资源

`不能用，可变对象做锁`：我觉得不能用balance和password做为锁对象。这两个对象balance是Integer，password是String都是不可变变对象，一但对他们进行赋值就会变成新的对象，加的锁就失效了。

##### 保护没有关联关系的多个资源

各自用一把锁。

用不同的锁对受保护资源进行精细化管理，能够提升性能。这种锁还有个名字，叫`细粒度锁。`

##### 保护有关联关系（之间有数据交换）的多个资源

转账问题：锁能覆盖所有受保护资源，即多个对象共用一把锁。

注：转账实际使用数据库事务+乐观锁的方式解决（select * from account where account_id = ? for update 加锁，锁住锁定两条记录）。并且实际中转账和到账操作有延迟，转入操作放到mq里面，mq消费失败会重试，所以能保证最终一致性。

- 创建多个对象时，`传入唯一的lock对象来当锁`。万一不是一样的对象，就没用了，并且会出现，锁自家门来保护他家资产的荒唐事。

- 用 `Account.class 作为共享的锁`。这个对象是 Java 虚拟机在加载 Account 类的时候创建的，所以我们不用担心它的唯一性。`但所有的转账操作都变成串行，不可行`。

  - 还可以在Account中添加一个final静态object，通过锁这个object来实现一个锁保护多个资源。这种方式比锁class更安全。如果用 Account.class 的话，其他使用的者也可以用这个锁，可以说这种锁是暴露的，而这种则是私有的锁，不会有暴露的风险。

    ![image-20200914171740854](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200914171742.png)

#### 死锁

 Account.class 作为互斥锁，虽然这个方案不存在并发问题，但是所有账户的转账操作都是串行的。解决这个问题，可以`一次性获取两把锁`：转出账户 this锁，转入账户锁。

![image-20200914173910745](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200914173912.png)

将锁的细粒度变小，使用`细粒度锁`可以提高并行度，是性能优化的一个重要手段。

`但代价`就是可能会导致`死锁`:一组互相竞争资源的线程因互相等待，导致“永久”阻塞的现象。

以下四个条件`都发生`时才会出现`死锁`：

- `互斥`，共享资源 X 和 Y 只能被一个线程占用；
- `占有且等待`，线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X；
- `不可抢占`，其他线程不能强行抢占线程 T1 占有的资源；
- `循环等待`，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源，就是循环等待。

破坏其中一个，就可以成功避免死锁的发生：

- `互斥：`无法破坏，用`锁为的就是互斥`。

- `占用且等待：`我们可以*一次性申请所有的资源（串行申请）*。需要一个`管理员角色：Allocator`（Java 里面的类）来管理这个临界区，用来同时申请资源，同时释放资源。账户 Account 类里面持有一个 `Allocator 的单例`（管理员必须是唯一的）。

  <img src="upload\image-20200914180535649.png" alt="image-20200914180535649" style="zoom:25%;" />

- `不可抢占：`占用部分资源的线程进一步申请其他资源时，如果申请不到，可以`主动释放它占有的资源`（可以*并行申请*）。`synchronized 是做不到`，synchronized 申请资源的时候，如果申请不到，线程直接进入`阻塞状态`。java.util.concurrent 这个包下面提供的 `Lock` 是可以轻松`解决`这个问题的

  - 原因是synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。

- `循环等待：`让他们*串行申请*，不让有机会循环。可以靠`先排序`，然后`按序申请资源`来预防。按照序号从小到大的顺序锁定账户。<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200914181031.png" alt="image-20200914181029958" style="zoom:25%;" />

**总结：**用细粒度锁来锁定多个资源时，要注意死锁的问题。识别出风险很重要。

`破坏占用且等待条件`，我们也是`锁了所有的账户`，而且还是用了`死循环` while(!actr.apply(this, target));(**方法实际项目中，应该加个timeout避免一直阻塞**），不过好在 apply() 这个方法基本不耗时。 在转账这个例子中，`破坏循环等待条件就是成本最低`的一个方案。

所以我们在选择具体方案的时候，还需要`评估一下操作成本`，从中选择一个成本最低的方案。

##### “等待-通知”机制`优化while循环等待`

用死循环的方式来循环等待，如果 apply() 操作耗时非常短，而且并发冲突量也不大时，方案可行。但如果`apply() 耗时长，并发大`，循环获取锁太`耗CPU`。需要`等待通知机制`去优化。

`等待 - 通知机制`：线程首先**获取互斥锁**，当线程要求的条件**不满足**时，**释放互斥锁**，进入等待状态；当要求的条件**满足**时，**通知等待的线程，重新获取互斥锁**。

- 获取锁，`获取不到`，将线程放入对象等待池里等待。（对象、互斥锁、对象等待池一一对应）

- 线程进入临界区后，某些`条件不满足`，线程需要调`用对象的wait()方法`，将自己放入`对象等待池`里，并释放持有的互斥锁。

- 当条件满足时调用 notifyAll()，会通知`对象等待池中的线程`，告诉它条件`曾经满足过`（只保证通知的那个时间点条件满足，不保证被唤醒的线程执行时满足，有人可能插队），即将线程`从对象等待池中`的所有线程都移动到该对象的`锁标志等待池`，线程开始抢占锁标志（`只有锁标志等待池中的线程可以获取锁标志`）。

  - 为了解决曾经满足这个问题，当wait()满足时，需要重新检查等待条件。MESA 管程经典范式：

    ```java
    while(条件不满足) {
        wait();
    }
    ```

    用了等待-通知机制，就干掉了Account中的while循环，如果线程获取不到锁，让线程`到Allocator的等待队列里去等`。等别人还回来的通知。

    <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200914195703.png" alt="image-20200914195701587" style="zoom:25%;" />

注：除非深思熟虑，否则尽量使用 notifyAll()。notify() 是会随机地通知等待队列中的一个线程，而 notifyAll() 会通知等待队列中的所有线程。notify() 的随机通知，可能会导致`真正该唤醒的再也没有机会被唤醒`。

何时使用notify() ，满足以下三个条件:

- 所有等待线程拥有`相同的等待条件`；
- 所有等待线程被唤醒后，`执行相同的操作`；
- `只需要唤醒一个线程`。

### （新）安全性、活跃性，以及性能问题

#### 安全性问题

线程安全：其实本质上就是`正确性`，而正确性的含义就`是程序按照我们期望`的执行，不要让我们感到意外。

`理论上`线程安全的程序，就要`避免出现原子性问题、可见性问题和有序性问题`。

`什么情况下`需要分析线程安全问题：存在共享数据并且该数据会发生变化，通俗地讲就是`有多个线程会同时读写同一数据`。

- 那如果能够做到`不共享数据`或者`数据状态不发生`变化，就能够保证线程的安全性。
  - 线程本地存储（Thread Local Storage，TLS）
  - 不变模式

`数据竞争`：当多个线程同时访问同一数据，并且至少有一个线程会写这个数据的时候，如果我们不采取防护措施，那么就会导致并发 Bug

`竞态条件：`指的是程序的执行结果依赖线程执行的顺序。

XX是线程安全带指的是它`方法单独执行的时候没有并发正确性`问题，并不代表把它的操作组合在一起问木有。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200915152625.png" alt="image-20200915152617838" style="zoom:33%;" />

- 在并发场景中，程序的执行依赖于某个状态变量，也就是类似于下面这样：

  ```java
  if (状态变量 满足 执行条件) {
      执行操作
  }
  ```

#### 活跃性问题

指的是某个操作无法执行下去

##### 死锁

线程互相等待，并且一直等待下去

##### 活锁

有时线程虽然没有发生阻塞，但仍然会存在执行不下去的情况，这就是所谓的“活锁”。

理解：线程间`互相谦让`，但再获取时又撞到一起了，又再次谦让，不断循环的情况。

解决：`谦让时，尝试等待一个随机的时间`。降低再次相撞的概率。

案例：Raft 这样知名的分布式一致性算法中。

##### 饥饿

`饥饿：`指的是线程因无法访问所需资源而无法执行下去的情况。

- 如果线程`优先级“不均”`，在 CPU 繁忙的情况下，优先级低的线程得到执行的机会很小，就可能发生线程“饥饿”；
- `持有锁的线程，如果执行的时间过长`，也可能导致“饥饿”问题。

解决饥饿方案：

- 保证资源充足
- 公平地分配资源：主要是`使用公平锁`。所谓公平锁，是一种先来后到的方案，线程的等待是有顺序的，排在等待队列前面的线程会优先获得资源。
- 避免持有锁的线程长时间执行：

这三个方案中，方案一和方案三的适用场景比较有限，因为很多场景下，资源的稀缺性是没办法解决的，持有锁的线程执行的时间也很难缩短。

#### 性能问题

`互斥锁本质`上是管程思想的实现，为了保证线程安全，将`并行的程序串行化`。所以锁的过度使用可能导致串行化的范围过大。

那怎么才能避免锁带来的性能问题呢？

Java SDK 并发包里之所以有那么多东西，有很大一部分原因就是要提升在某个特定领域的性能。

- 既然使用锁会带来性能问题，那最好的方案自然就是使用`无锁的算法和数据结构`。
  - 线程本地存储 (Thread Local Storage, TLS)
  - 写入时复制 (Copy-on-write)
  - 乐观锁
  - Java 并发包里面的原子类也是一种无锁的数据结构
  - Disruptor 则是一个无锁的内存队列
- `减少锁持有的时间`：使用管程思想，用**并发包实现更细粒度的锁**
  - 使`用细粒度的锁`：Java 并发包里的 ConcurrentHashMap，它使用了所谓分段锁的技术。1.8后没有分段锁 ，是syn + cas
  - `读写锁：`也就是读是无锁的，只有写的时候才会互斥

性能方面的度量指标：

1. `吞吐量：`指的是`单位时间`内能处理的请求数量。吞吐量越高，说明性能越好。
2. `延迟：`指的是从发出请求到收到`响应的时间`。延迟越小，说明性能越好。
3. `并发量：`指的是能`同时处理的请求数量`，一般来说随着并发量的增加、延迟也会增加。所以延迟这个指标，一般都会是基于并发量来说的。例如并发量是 1000 的时候，延迟是 50 毫秒。

#### 总结

并发编程是一个复杂的技术领域，微观上涉及到原子性问题、可见性问题和有序性问题，宏观则表现为安全性、活跃性以及性能问题。

我们在设计并发程序的时候，`主要是从宏观出发，也就是要重点关注它的安全性、活跃性以及性能`。安全性方面要注意数据竞争和竞态条件，活跃性方面需要注意死锁、活锁、饥饿等问题，性能方面我们虽然介绍了两个方案，但是遇到具体问题，你还是要具体分析，根据特定的场景选择合适的数据结构和算法。

### 管程：并发编程的万能钥匙（synchronized：管程的实现）

#### Java管程：MESA模型

`管程技术：`Java 语言在 1.5 之前，提供的唯一的并发原语就是用synchronized实现的管程，而且 1.5 之后提供的 SDK 并发包，也是以管程技术为基础的。

Java 采用的是管程技术，**synchronized 关键字及 wait()、notify()、notifyAll() 这三个方法都是管程的组成部分**。而**管程和信号量是等价的**，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。但是管程更容易使用，所以 Java 选择了管程。

`Monitor(管程/监视器)`：指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。Java 领域的语言，就是`管理类的成员变量`和`成员方法`，让这个类是线程安全的。管程是实现对象监视器的思想。

并发编程领域，有两大核心问题：

- 一个是**互斥**，即同一时刻只允许一个线程访问共享资源：管程解决互斥问题的思路很简单，就是`将共享变量及其对共享变量的操作统一封装起来`

- 另一个是**同步**，即线程之间如何通信、协作：

  - MESA 模型的主要组成部分：每个**条件变量（对象等待池细分：能唤醒对象等待池区域）**都对应有一个**等待队列**

    - 条件等待队列（对象条件等待池）
    - 入口等待队列（锁标识等待池）

    <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200915162425.png" alt="image-20200915162417017" style="zoom:50%;" />

- **同步一般是建立在互斥**的基础上，只有**资源具有排它性**才需要同步来解决并发编程过程中对资源的协作问题



利用管程思想，实现一个线程安全的阻塞队列：利用Java可重入锁(ReentrantLock)实现。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200915163632.png" alt="image-20200915163630622" style="zoom: 33%;" />

#### Hasen 模型、Hoare 模型和 MESA 模型的一个核心区别：

Hasen 模型、Hoare 模型和 MESA 模型的一个核心区别就是当条件满足后，`如何通知相关线程`。管程要求同一时刻只允许一个线程执行，那当线程 T2 的操作使线程 T1 等待的条件满足时，T1 和 T2 究竟谁可以执行呢？

- `Hasen 模型（嗨森）`里面，要求 `notify() 放在代码的最后`，这样 T2 通知完 T1 后，T2 就结束了，然后 T1 再执行，这样就能保证同一时刻只有一个线程执行。
- `Hoare 模型（霍尔）`里面，T2 通知完 T1 后，`T2 阻塞`，T1 马上执行；等 T1 执行完，`再唤醒 T2`，也能保证同一时刻只有一个线程执行。但是相比 Hasen 模型，T2 多了一次阻塞唤醒操作。（但两个线程，满足你的条件与我何干）
- `MESA 管程（麦撒）`里面，T2 通知完 T1 后，T2 还是会接着执行，T1 并不立即执行，`仅仅是从条件变量的等待队列进到入口等待队列里面（对象等待池->锁标志等待池）`。这样做的好处是 notify() 不用放到代码的最后，T2 也没有多余的阻塞唤醒操作。但是也有个`副作用（曾经满足）`，就是当 T1 再次执行的时候，可能曾经满足的条件，现在已经不满足了，所以需要以循环方式检验条件变量。

`MESA模型`和其他两种模型相比可以实现`更好的公平性`，因为唤醒只是把你放到队列里而不保证你一定可以执行，最后能不能执行还是要看你自己可不可以抢得到执行权也就是入口，`其他两种模型是显式地唤醒`，有点`内定`的意思了。

#### 总结

`总结：`Java 参考了 MESA 模型，语言内置的管程（synchronized）对 MESA 模型进行了精简。MESA 模型中，条件变量可以有多个，`Java 语言内置的管程（synchronized）里只有一个条件变量`。具体如下图所示。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200915164909.png" alt="image-20200915164907349" style="zoom:33%;" />

Java 内置的管程方案（synchronized）使用简单，`synchronized` 关键字修饰的代码块，在编译期会自动生成相关加锁和解锁的代码，但是`仅支持一个条件变量`；

而 `Java SDK 并发包`实现的管程`支持多个条件变量`，不过**并发包里的锁，需要开发人员自己进行加锁和解锁操作**。

**问题：**wait() 方法，在 Hasen 模型和 Hoare 模型里面，都是没有参数的，而在 MESA 模型里面，增加了超时参数，你觉得这个参数有必要吗？

wait() 方法，增加超时参数，避免没有人唤醒，傻等。如果能时间随机还能避免**活锁**。但是唤醒仅仅保证你有机会争抢锁，如果你优先级比较低，可能会被**饿死**（CPU繁忙，饥饿性死锁）。

### 线程的生命周期？

线程的生命周期，需要搞懂生命周期中各个*节点*的**状态转换机制**。

#### 通用的线程生命周期

通用的线程生命周期基本上可以用下图这个“五态模型”来描述。这五态分别是：初始状态、可运行状态、运行状态、休眠状态和终止状态。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200916143232.png" alt="image-20200916143159072" style="zoom: 33%;" />

1. `初始状态`，指的是线程已经被创建，但是还不允许分配 CPU 执行。这个状态属于编程语言特有的，不过这里所谓的被创建，仅仅是`在编程语言层面被创建`，而在操作系统层面，真正的线程还没有创建。
2. `可运行状态`，`指的是线程可以分配 CPU 执行`。在这种状态下，真正的操作系统线程已经被成功创建了，所以可以分配 CPU 执行。
3. 当有空闲的 CPU 时，操作系统会将其分配给一个处于可运行状态的线程，被`分配到 CPU` 的线程的状态就转换成了`运行状态`。
4. 运行状态的线程如果调用一个`阻塞的 API`（例如以阻塞方式读文件）或者等待某个事件（例如条件变量），那么线程的状态就会转换到`休眠状态`，同时`释放 CPU 使用权`，*休眠状态的线程永远没有机会获得 CPU 使用权*。当等待的事件出现了，线程就会从休眠状态转换到可运行状态。
5. 线程执行完或者出现异常就会进入`终止状态`，终止状态的线程不会切换到其他任何状态，进入终止状态也就意味着`线程的生命周期结束`了。

这五种状态在不同编程语言里会有简化合并。

- C 语言的 POSIX Threads 规范：
  - **简化：**就把初始状态和可运行状态合并了
- Java 语言：
  - **简化：**把`可运行状态和运行状态合并`了，这两个状态在操作系统调度层面有用，而 JVM 层面不关心这两个状态，因为 `JVM 把线程调度交给操作系统处理`了。
  - **细化：**细化了休眠状态，BLOCKED、WAITING、TIMED_WAITING。

#### Java 中线程的生命周期

Java 语言中线程共有六种状态:

1. NEW（初始化状态）：Java 刚`创建出来`的 Thread 对象就是 `NEW 状态`。从 `NEW 状态转换到 RUNNABLE 状态`很简单，只要调用`线程对象的 start() 方法`就可以了。
2. RUNNABLE（可运行 / 运行状态）：包括操作`系统线程状态`中的 `Running和 Ready`，也就是处于此状态的线程有可能正在执行，也有可能正在等待着操作系统为它分配执行时间。
3. BLOCKED（阻塞状态）
4. WAITING（无时限等待）
5. TIMED_WAITING（有时限等待）
6. TERMINATED（终止状态）

Java 线程的生命周期可以简化为下图:

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200916144941.png" alt="image-20200916144937502" style="zoom: 50%;" />

##### RUNNABLE(运行状态) 与 BLOCKED（阻塞） 的状态转换

只有一种场景会触发这种转换，就是线程`等待 synchronized 的隐式锁`。

- *synchronized 修饰的方法、代码块同一时刻只允许一个线程执行，其他线程只能等待，这种情况下，等待的线程就会从 RUNNABLE 转换到 BLOCKED 状态*。而当等待的线程获得 synchronized 隐式锁时，就又会从 BLOCKED 转换到 RUNNABLE 状态。如果你熟悉操作系统线程的生命周期的话，可能会有个疑问：线程调用阻塞式 API 时，是否会转换到 BLOCKED 状态呢？在操作系统层面，线程是会转换到休眠状态的，但是在 JVM 层面，Java 线程的状态不会发生变化，也就是说 Java 线程的状态会依然保持 RUNNABLE 状态。JVM 层面并不关心操作系统调度相关的状态，*因为在 JVM 看来，等待 CPU 使用权（操作系统层面此时处于可执行状态）与等待 I/O（操作系统层面此时处于休眠状态）没有区别，都是在等待某个资源，所以都归入了 RUNNABLE 状态*。而我们平时所谓的 Java 在调用阻塞式 API 时，线程会阻塞，指的是操作系统线程的状态，并不是 Java 线程的状态。

##### RUNNABLE（运行状态） 与 WAITING（无时限等待） 的状态转换

总体来说，有三种场景会触发这种转换。

- 第一种场景，获得 synchronized 隐式锁的线程，调用`无参数的 Object.wait()` 方法。线程将进入 `wait pool` 等待唤醒条件。
- 第二种场景，调用`无参数的 Thread.join()` 方法。其中的 join() 是一种线程同步方法，例如有一个线程对象 thread A，当调用 A.join() 的时候，执行这条语句的线程会等待 thread A 执行完，而等待中的这个线程，其状态会从 RUNNABLE 转换到 WAITING。当线程 thread A `执行完`，原来等待它的线程又会从 WAITING 状态转换到 RUNNABLE。
- 第三种场景，调用 `LockSupport.park() 方法`。其中的 LockSupport 对象，也许你有点陌生，其实 Java 并发包中的锁，都是基于它实现的。调用 `LockSupport.park()` 方法，当前线程会`阻塞`，线程的状态会从 RUNNABLE 转换到 WAITING。调用 `LockSupport.unpark(Thread thread)` `可唤醒目标线程（指定的）`，目标线程的状态又会从 WAITING 状态转换到 RUNNABLE。

##### RUNNABLE（运行） 与 TIMED_WAITING（有时限等待） 的状态转换

有五种场景会触发这种转换：

1. 调用带`超时参数`的 `Thread.sleep(long millis)` 方法；
2. 获得 synchronized 隐式锁的线程，调用带`超时参数`的 `Object.wait(long timeout)` 方法；
3. 调用带`超时参数`的 `Thread.join(long millis)` 方法；
4. 调用带`超时参数`的 `LockSupport.parkNanos(Object blocker, long deadline)` 方法；
5. 调用带`超时参数`的 `LockSupport.parkUntil(long deadline)` 方法。

这里你会发现 TIMED_WAITING 和 WAITING 状态的区别，仅仅是触发条件多了`超时参数`。

从 NEW 到 RUNNABLE 状态

##### 从 NEW （初始化）到 RUNNABLE（运行） 状态

Java 刚`创建出来`的 Thread 对象就是 `NEW 状态`，NEW 状态的线程，不会被操作系统调度，因此不会执行。Java 线程要执行，就必须转换到 RUNNABLE 状态。从 `NEW 状态转换到 RUNNABLE 状态`很简单，只要调用`线程对象的 start() 方法`就可以了

##### 从 RUNNABLE（运行状态） 到 TERMINATED （终止状态）状态

- 线程`执行完 run() 方法后`，会自动转换到 TERMINATED 状态，
- 当然如果执行 run() 方法的时候`异常抛出`，也会导致线程终止。
- 有时候我们需要强制中断 run() 方法的执行，例如 run() 方法访问一个很慢的网络，我们等不下去了，想终止怎么办呢？Java 的 Thread 类里面倒是有个 `stop() 方法`，不过已经标记为 @Deprecated，所以不建议使用了。正确的姿势其实是`调用 interrupt() 方法`。

###### 那 stop() 和 interrupt() 方法的主要区别是什么呢？

**sotp()**

*stop() 方法会无声的杀死线程，不给线程喘息的机会*，

- **待议：**如果`线程持有 ReentrantLock 锁`，被 stop() 的线程并`不会自动调用` ReentrantLock 的 `unlock() 去释放锁`，那其他`线程就再也没机会获得 ReentrantLock 锁`。
- [docs.oracle.com：](https://docs.oracle.com/javase/1.5.0/docs/guide/misc/threadPrimitiveDeprecation.html)因为它本质上是不安全的。停止线程会使它解锁它已锁定的锁。（当`ThreadDeath`异常在堆栈中传播时，锁将被解锁 。）如果先前由这些锁*保护的任何对象处于不一致状态*，则其他线程现在可能会以不一致状态查看这些对象。据说这类物体已*损坏*。当线程对损坏的对象进行操作时，可能会导致任意行为。此行为可能是微妙的，难以检测，或者可能是明显的。
  - 无论是synchronized还是JUC的Lock，在stop线程时都会释放锁。所以stop之所以deprecated和释放不释放锁没有关系，还是因为stop太粗暴，导致`终止的位置不确定`，所以才不推荐使用的。（难道voliate）
- 类似的方法还有 suspend() 和 resume() 方法，这两个方法同样也都不建议使用了。

**interrupt()**

interrupt() 方法仅仅是`通知线程`，线程有机会执行一些后续操作，同时也可以无视这个通知。即用于接收特定的事件，从而执行后续的操作。

被 interrupt 的线程，是怎么收到通知的呢？

1. `异常：`

- 当`线程 A 处于 WAITING、TIMED_WAITING 状态`时，如果其他线程调用线程 A 的 interrupt() 方法，会使线程 A 返回到 RUNNABLE 状态，同时线程 A 的`代码会触发 InterruptedException 异常`。上面我们提到转换到 WAITING、TIMED_WAITING 状态的触发条件，都是调用了类似 **wait()、join()、sleep()** 这样的方法，我们看这些方法的签名，发现都会 throws InterruptedException 这个异常。这个异常的触发条件就是：*其他线程调用了该线程的 interrupt() 方法*。
  - 因InterruptedException退出同步代码块会释放当前线程持有的锁，所以相比外部强制stop是安全的（已手动测试）。**sleep、join**等会抛出InterruptedException的操作会**立即抛出异常**，**wait在被唤醒之后才会抛出异常**（就像阻塞一样，不被打扰）
- 当`线程 A 处于 RUNNABLE 状态`时，并且`阻塞在 java.nio.channels.InterruptibleChannel` 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 会`触发 java.nio.channels.ClosedByInterruptException` 这个异常；而*阻塞在 java.nio.channels.Selector 上*时，如果其他线程调用线程 A 的 interrupt() 方法，*线程 A 的 java.nio.channels.Selector 会立即返回*。

2. 主动监测：
   - 如果线程`处于 RUNNABLE 状态`，并且没有阻塞在某个 I/O 操作上，例如中断计算圆周率的线程 A，这时就得依赖线程 A 主动检测中断状态了。如果其他线程调用线程 A 的 interrupt() 方法，那么线程 A 可以`通过 isInterrupted() 方法`，`检测是不是自己被中断`了。

![img](http://static2.iocoder.cn/04a277229fd3b24e058417f9c571681c)

##### 如何诊断多线程BUG

多线程程序很难调试，出了 Bug 基本上都是`靠日志`，靠`线程 dump 来跟踪问题`，分析线程 dump 的一个基本功就是`分析线程状态`，大部分的死锁、饥饿、活锁问题都需要跟踪分析线程的状态。

通过 `jstack 命令`或者`Java VisualVM`这个可视化工具将 JVM 所有的线程栈信息导出来，完整的线程栈信息不仅包括线程的**当前状态**、**调用栈**，还包括了**锁的信息**。

例：发生死锁的线程

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200916155921.png" alt="image-20200916155920057" style="zoom:50%;" />

##### 问题

下面代码的本意是当前线程被中断之后，退出while(true)，你觉得这段代码是否正确呢？

```java

Thread th = Thread.currentThread();
while(true) {
  if(th.isInterrupted()) {
    break;
  }
  // 省略业务代码无数
  try {
    Thread.sleep(100);
  }catch (InterruptedException e){
    e.printStackTrace();
  }
}
```

答案：可能出现无限循环，线程在sleep期间被打断了，抛出一个InterruptedException异常，抛出异常后，中断标示会自动清除掉。所以try catch捕捉此异常，应该重置一下中断标示。

#### （旧版：待整理）

线程的生命周期分为新建（NeW）、就绪（ Runnable）、运行（ Running）、阻塞（ Blocked）和死亡（Dead）这5种状态。

![image-20200910153023382](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200910153025.png)

- `新建状态：New`在Java中使用new关键字创建一个线程，新创建的线程将处于新建状态。在创建线程时主要是`为线程分配内存(线程私有的区域：程序计数器、虚拟机栈、本地方法栈)并初始化其成员变量的值`

- `就绪状态：Runnab1e`新建的线程对象在调用 start方法之后将转为就绪状态。此时JVM完成了方法调用栈和程序计数器的创建，等待该线程的调度和运行（JVM会调用操作系统的接口创建一个与之对应的原生线程）。

- `运行状态：Running`就绪状态的线程在竞争到CPU的使用权并开始执行run方法的线程执行体时，会转为运行状态，处于运行状态的线程的主要任务就是执行run方法中的逻辑代码。

- `阻塞状态：Waitting` 运行中的线程会主动或被动地放弃CPU的使用权并暂停运行，此时该线程将转为阻塞状态，直到再次进入可运行状态，才有机会再次竞争到CPU使用权并转为运行状态。阻塞的状态分为以下三种。

  1. 等待阻塞：在运行状态的线程调用o.wait方法时，JVM会把该线程放入等待队列（ Waitting Queue）中，线程转为阻塞状态。
  2. 同步阻塞：在运行状态的线程尝试获取正在被其他线程占用的对象同步锁时，JVM会把该线程放入锁池（ Lock Poo1）中，此时线程转为阻塞状态。
  3. 其他阻塞：运行状态的线程在执行 Thread. sleep（long ms）、 Thread.join、 调用socket的 recelver、 accept方法或者发出I/0请求时，，JVM会把该线程转为阻塞状态。直到 sleep()状态超时、 Thread. join等待线程终止或超时，或者I/0处理完毕，线程才重新转为可运行状态。

  ![img](http://static2.iocoder.cn/04a277229fd3b24e058417f9c571681c)

- `线程死亡：Dead`线程在以下面三种方式结束后转为死亡状态。

  - 线程正常结東：run方法或ca11方法执行完成。
  - 线程异常退出：运行中的线程抛出一个 Error或未捕获的Exception，线程异常退出
  - 手动结束：调用线程对象的stop方法手动结束运行中的线程该方式会瞬间释放线程占用的同步对象锁，导致锁混乱和死锁，不推荐使用。

### 创建多少线程才是合适的？

##### 为什么要使用多线程？

使用多线程，本质上就是`提升程序性能`，主要是`降低延迟，提高吞吐量`。

- 延迟指的是发出请求到收到响应这个过程的时间；延迟越短，意味着程序执行得越快，性能也就越好。
-  吞吐量指的是在单位时间内能处理请求的数量；吞吐量越大，意味着程序能处理的请求越多，性能也就越好。
- 这两个指标内部有一定的联系（同等条件下，延迟越短，吞吐量越大），但是由于它们隶属不同的维度（一个是时间维度，一个是空间维度），并不能互相转换。

#### 多线程的应用场景

要想“降低延迟，提高吞吐量”，对应的方法呢，基本上有两个方向，

- **优化算法：**

- **将硬件的性能发挥到极致：**在并发编程领域，提升性能本质上就是提升硬件的利用率，再具体点来说，解决 CPU 和 I/O 设备综合利用率的问题。不让两者空闲。如果 CPU 和 I/O 设备的利用率都很低，那么可以尝试通过`增加线程来提高吞吐量`。

  - 当线程 A 执行 CPU 计算的时候，线程 B 执行 I/O 操作；当线程 A 执行 I/O 操作的时候，线程 B 执行 CPU 计算。
  - 如果程序只有 CPU 计算，而没有 I/O 操作的话，多线程不但不会提升性能，还会使性能变得更差，原因是增加了线程切换的成本。

#### 创建多少线程合适（实际要靠压测）？

 使用cpu计算，几核就可以支持几个线程， 所以 线程数量= cpu核数。 但是由于线程可能存在偶尔的内存页失效或者其他原因导致阻塞，因此 工程上认为：`线程数量= cpu核数+1`

- 针对单核 CPU ：对于 `I/O 密集型计算场景`，最佳的线程数是与程序中 CPU 计算和 I/O 操作的耗时比相关的，我们可以总结出这样一个公式
  - `最佳线程数 =1 +（I/O 耗时 / CPU 耗时）`
- 多核 CPU:等比扩大
  - `最佳线程数 =CPU 核数 * [ 1 +（I/O 耗时 / CPU 耗时）]`

#### 实际工作中

对于 I/O 密集型计算场景，I/O 耗时和 CPU 耗时的比值是一个关键参数，不幸的是这个参数是未知的，而且是动态变化的，所以工程上，我们要估算这个参数，然后做各种不同场景下的压测来验证我们的估计。不过工程上，原则还是将硬件的性能发挥到极致，所以压测时，我们需要重点关注 `CPU、I/O 设备的利用率和性能指标（响应时间、吞吐量）`之间的关系。

- 工作中都是按照逻辑核数来的，理论值和经验值只是提供个指导，实际上还是要靠压测。
  - apm测试IO/CPU 耗时比例
- 公式话性能问题有些不妥，定性的io密集或者cpu密集很难在定量的维度上反应出性能瓶颈，而且公式上忽略了线程数增加带来的cpu消耗，性能优化还是要定量比较好，这样不会盲目，比如`io已经成为了瓶颈`，增加线程或许带来不了性能提升，这个时候是不是可以考虑用*cpu换取带宽*，*压缩数据*，或者*逻辑上少发送一些*。最后一个问题，我的答案是大部分应用环境是合理的，老师也说了是积累了一些调优经验后给出的方案，没有特殊需求，初始值我会选大家都在用伪标准

工作意见：

- 算法：提高吞吐量可以通过使用缓存、优化业务逻辑、提前计算好等方式来处理
- 线程池：一类业务一个线程池比较好
  - 不同名字线程池，方便排查问题。
  - 工程上有些服务需要做资源隔离，来保证对应服务执行线程的稳定性，不会受其他非重要业务影响。
    - 共用一个线程池，如果遇到某些任务处理数量大且时间较长，会影响到后续加到线程池任务队列里面的其他任务，尤其是一些对时效性要求较高的任务。
  - 服务中的线程池统一管理：美团有篇文章，实时修改线程池。

### 为什么局部变量是线程安全的？

1. CPU 去哪里找到调用方法的参数和返回地址？
   - 通过 CPU 的堆栈寄存器，`先入后出`，称为调用栈。
2. 每个方法在调用栈里都有自己的独立空间，称为栈帧，每个栈帧里都有对应方法需要的参数和返回地址。当调用方法时，会创建新的栈帧，并压入调用栈；当方法返回时，对应的栈帧就会被自动弹出。也就是说，`栈帧和方法是同生共死`的。
   - 利用栈结构来支持方法调用这个方案非常普遍，以至于 `CPU 里内置了栈寄存器`。虽然各家编程语言定义的方法千奇百怪，但是方法的内部执行原理却是出奇的一致：`都是靠栈结构解决的`。Java 语言虽然是靠虚拟机解释执行的，但是方法的调用也是利用栈结构解决的。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200916173122.png" alt="image-20200916173120445" style="zoom: 50%;" />

3. 局部变量存哪里？

   - `局部变量就是放到了调用栈`里，仅在单线程内访问局部变量，因为不会和其他线程共享，所以没有并发问题。

     <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200916173312.png" alt="image-20200916173310530" style="zoom:50%;" />

4. 每个`线程都有自己独立的调用栈`，在堆中都有自己的工作内存。

   - 即使在同一个线程中，调用一次方法，就产生一个栈帧，他们从不共享

     <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200916173501.png" alt="image-20200916173500108" style="zoom:50%;" />

#### 递归调用太深，可能导致栈溢出。你思考一下原因是什么？

栈溢出原因：

- 因为*每调用一个方法就会在栈上创建一个栈帧*，方法调用结束后就会弹出该栈帧，而*栈的大小不是无限*（线程的栈大小是有限）的，所以递归调用次数过多的话就会导致栈溢出。
- 而递归调用的特点是每递归一次，就要创建一个新的栈帧（在给线程分配的内存中），而且还要保留之前的环境（栈帧），直到遇到结束条件。所以`递归调用一定要明确好结束条件`，不要出现死循环，而且要`避免栈太深`。
  解决方法：
  1. 简单粗暴，不要使用递归，使用循环替代。缺点：代码逻辑不够清晰；
  2. 限制递归次数；
  3.  使用尾递归，尾递归是指在方法返回时只调用自己本身，且不能包含表达式。编译器或解释器会把尾递归做优化，使递归方法不论调用多少次，都只占用一个栈帧，所以不会出现栈溢出。然鹅，Java没有尾递归优化。

### 如何用面向对象思想写好并发程序？

在 Java 语言里，`面向对象思想能够让并发编程变得更简单`。

##### 一、封装共享变量

面向对象思想里面有一个很重要的特性是`封装`，封装的通俗解释就是**将属性和实现细节封装在对象内部**，外界对象只能通过目标对象提供的公共方法来间接访问这些内部属性。

利用面向对象思想写并发程序的思路：*将共享变量作为对象属性封装在内部，对所有公共方法制定并发访问策略*。

- 对共享变量进行封装，要避免“逸出”，所谓“逸出”简单讲就是共享变量逃逸到对象的外面。即让其他人获取到对象的引用地址。

会发现，很多共享变量的值是不会变的，例如信用卡账户的卡号、姓名、身份证。对于这些**不会发生变化的共享变量，建议你用 final 关键字来修饰**。

##### 二、识别共享变量间的约束条件

**识别共享变量间的约束条件**非常重要。因为这些约束条件，决定了并发访问策略。

共享变量之间的约束条件，反映在代码里，基本上都会有 if 语句，所以，一定要`特别注意竞态条件`。

如图：<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200917145813.png" alt="image-20200917145811069" style="zoom:33%;" />

###### 问题

类 SafeWM 不满足库存下限要小于库存上限这个约束条件，那你来试试修改一下，让它能够在并发条件下满足库存下限要小于库存上限这个约束条件。

1. setUpper() 跟 setLower() 都加上 "synchronized" 关键字。不要太在意性能，老师都说了，避免过早优化。

2. 如果性能有问题，可以把 lower 跟 upper 两个变量封装到一个类中，例如

   ```java
   public class Boundary {
       private final lower;
       private final upper;
       
       public Boundary(long lower, long upper) {
           if(lower >= upper) {
               // throw exception
           }
           this.lower = lower;
           this.upper = upper;
       }
   }
   ```

   移除 SafeVM 的 setUpper() 跟 setLower() 方法，并增入 setBoundary(Boundary boundary) 方法。每次进去都是修改对象。但还是得加锁，

3. ```java
   // 原子类的引用类型,一种思想：对象用volatile修饰
   volatile AtomicReference<Inventory> inventory = new AtomicReference<>();
   
       static class Inventory {
           private final long upper = 0;
   
           private final long lower = 0;
       }
   
       void setUpper(long v) {
           long low;
           Inventory oldObj;
           Inventory newObj;
           do {
               oldObj = inventory.get();
               if (v >= (low = oldObj.lower)) {
                   throw new IllegalArgumentException();
               }
               newObj = new Inventory();
               newObj.lower = low;
               newObj.upper = v;
   
           //一旦碰到冲突，就重试当前操作直到没有冲突为止。
           //无锁的策略使用一种叫做比较交换的技术（CAS Compare And Swap）来鉴别线程冲突，一旦检测到冲突产生，就重试当前操作直到没有冲突为止。
           } while (inventory.compareAndSet(oldObj, newObj));
       }
   
       void setLower(long v) {
           long upp;
           Inventory oldObj;
           Inventory newObj;
           do {
               oldObj = inventory.get();
               if (v <= (upp = oldObj.upper)) {
                   throw new IllegalArgumentException();
               }
               newObj = new Inventory();
               newObj.lower = v;
               newObj.upper = upp;
   
           } while (inventory.compareAndSet(oldObj, newObj));
       }
   
   ```

   

#### 三、制定并发访问策略

制定并发访问策略：

1. `避免共享：`避免共享的技术主要是利于`线程本地存储`以及为`每个任务分配独立的线程`。
2. `不变模式：`这个在 Java 领域应用的很少，但在其他领域却有着广泛的应用，例如 Actor 模式、CSP 模式以及函数式编程的基础都是不变模式。
3. `管程及其他同步工具：`Java 领域万能的解决方案是管程，但是对于很多`特定场景`，使用 Java 并发包提供的`读写锁`、`并发容器`等同步工具会更好。

### 理论基础总结

#### **串行的故事**

起源是一个硬件的核心矛盾：CPU 与内存、I/O 的速度差异，系统软件（操作系统、编译器）在解决这个核心矛盾的同时，引入了可见性、原子性和有序性问题，这三个问题就是很多并发程序的 Bug 之源。

Java 语言它提供了 Java 内存模型，应对可见性和有序性问题，其中的互斥锁应对原子性问题。

虽说互斥锁是解决并发问题的核心工具，但它也可能会带来死锁问题，并引出了线程间的协作机制：等待 - 通知。

更多地是站在微观的角度看待并发问题。

管程，是 Java 并发编程技术的基础，是解决并发问题的万能钥匙。并发编程里两大核心问题——互斥和同步，都是可以由管程来解决的。

毕竟 Java 并发编程是要靠多线程来实现的，包括线程的生命周期、如何计算合适的线程数以及线程内部是如何执行的。

![img](https://static001.geekbang.org/resource/image/7f/8e/7fed6a485a694c794ee205c346b5338e.png)



##### 前面试题的总结

一个是 Integer 和 String ，Boolean类型的对象不适合做锁。如果锁发生变化，就意味着失去了互斥功能。 Integer 和 String 类型的对象在 JVM 里面是可能被重用的。

- Integer String Boolean相关的知识，Integer会缓存-128～127这个范围内的数值，String对象同样会缓存字符串常量到字符串常量池，可供重复使用，所以不能用来用作锁对象，网上有相关的[知识讲解](https://blog.csdn.net/xiaohai0504/article/details/6885137)和面试问题
  - Boolean：(全部缓存)
  - Byte：(全部缓存)
  - 
  -  Integer,：-128 — 127
  - Character(<= 127缓存)
  - Short(-128 — 127缓存)
  - Long(-128 — 127缓存)
  - 
  - Float(没有缓存)
  - ﻿﻿﻿﻿﻿﻿Doulbe(没有缓存)

锁，应是私有的、不可变的、不可重用的。

锁，应是私有的、不可变的、不可重用的。我们经常看到别人家的锁，都长成下面示例代码这样，这种写法貌不惊人，却能避免各种意想不到的坑，这个其实就是最佳实践。最佳实践这方面的资料推荐你看《Java 安全编码标准》这本书，研读里面的每一条规则都会让你受益匪浅。

```java
// 普通对象锁
private final Object lock = new Object();
// 静态对象锁
private static final Object lock = new Object(); 
```

不过，还有同学对07文中所举的例子有疑议，认为set(get()+1);这条语句是进入 set() 方法之后才执行 get() 方法，其实并不是这样的。`方法的调用，是先计算参数，然后将参数压入调用栈之后才会执行方法体`，方法调用的过程在11这篇文章中我们已经做了详细的介绍，你可以再次重温一下。

先计算参数这个事情也是容易被忽视的细节。例如，下面写日志的代码，如果日志级别设置为 INFO，虽然这行代码不会写日志，但是会计算"The var1：" + var1 + ", var2:" + var2的值，因为方法调用前会先计算参数。

`logger.debug("The var1：" + var1 + ", var2:" + var2);`

更好地写法应该是下面这样，这种写法仅仅是讲参数压栈，而没有参数的计算。使用{}占位符是写日志的一个良好习惯。

`logger.debug("The var1：{}, var2:{}", var1, var2);`



不同的 I/O 模型对最佳线程数的影响非常大，例如大名鼎鼎的 Nginx 用的是`非阻塞 I/O`，采用的是`多进程单线程结构`，Nginx 本来是一个 `I/O 密集型系统`，但是最佳进程数设置的却是 CPU 的核数，完全参考的是 CPU 密集型的算法。

- `对于Nginx为什么属于IO密集型的？`

  - 我的理解是这样，这个也要看场景，Nginx作为反向代理服务器，那么它会通过负载均衡策略调用后端的服务器，而**远程调用属于IO操作**，所以此处Nginx作为IO密集型的操作。

  - 但因为它 **采用的是非阻塞IO模型**，所以*工作的方式又类似于CPU密集型*，所以设置的最佳线程数为CPU的核数。**nginx里一般都是设置成worker进程和CPU一一对应的**

### 线程的基本方法？

线程相关的基本方法有wait、 notify、 notifyAll、 sleep、join、 yield等，这些方法控制线程的运行，并影响线程的状态变化。

- `线程等待：wait方法`调用wait方法的线程会进入 WAITING状态，只有等到其他线程的通知或被中断后才会返回。需要注意的是，在调用wait方法后会释放对象的锁，因此wait方法一般被用于同步方法或同步代码块中。

- `线程睡眠：sleep方法`调用 sleep方法会导致当前线程休眠。与wait方法不同的是， sleep方法不会释放当前占有的锁，会导致线程进入 TIMED-WATING状态，而wai方法会导致当前线程进入 WATING状态

- `线程让步：yield方法`调用 yield方法会使当前线程让出（释放）CPU执行时间片，与其他线程一起重新竞争CPU时间片。在一般情况下，优先级高的线程更有可能竞争到CPU时间片，但这不是绝对的，有的操作系统对线程的优先级并不敏感。

- `线程中断：interrupt方法`Interrupt方法用于向线程发行一个`终止通知信号`，会影响该线程内部的一个中断标识位，这个线程木身并不会因为调用了 interrupt方法而改变状态（阻塞、终止等）。状态的具体变化需要等待接收到中断标识的程序的最终处理结果来判定。对 interrupt方法的理解需要注意以下4个核心点
  - `调用 interrupt方法并不会中断一个正在运行的线程`，也就是说处于 Running状态的线程并不会因为被中断而终止，仅仅改变了内部维护的中断标识位而已。
  - 若因为调用 sleep方法而使线程处于 TIMED- WATING状态，则这时调用 interrupt方法会抛出 InterruptedException，使线程提前结東TIMED-WATING状态
  - 许多声明抛出 InterruptedException的方法如Thread. sleep（ long mills），`在抛出异常前都会清除中断标识位`，所以在抛出异常后调用 interrupted方法将会返回 false。
  - 中断状态是线程固有的一个标识位，可以通过此标识位安全终上线程。比如，在想终止一个线程时，可以先调用该线程的 Interrupt方法，然后在线程的run方法中根据该线程 isInterrupted方法的返回状态值安全终止线程
  
- `线程加入：join方法`join方法用于等待其他线程终止，如果在当前线程中调用一个线程的join方法，则当前线程转为阻塞状态，等到另一个线程结束，前线程再由阻塞状态转为就绪状态，等待获取CPU的使用权。在很多情况下，主线程生成并启动了子线程，需要等到子线程返回结果并收集和处理再退出，这时就要用到join方法，具体的使用方法如下![](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200910173847.png)

- `线程唤醒：notify方法`Object类有个 notify方法，用于唤醒在此对象监视器上等待的一个线程，如果所有线程都在此对象上等待，则会选择唤醒其中一个线程，选择是任意的。
  `实战：`我们通常调用其中一个对象的wait方法在对象的监视器上等待，直到当前线程放弃此对象上的锁定，才能继续执行被唤醒的线程，被唤醒的线程将以常规方式与在该对象上主动同步的其他线程竞争。类似的方法还有 notify1l，用于唤醒在监视器上等待的所有线程
  
- `后台守护线程：setDaemon方法`setDaemon方法用于定义一个守护线程，也叫作“服务线程”，该线程是后台线程，有一个特性，即为用户线程提供公共服务，在没有用户线程可服务时会自动离开。
  
  守护线程的`优先级较低`，用于为系统中的其他对象和线程提供服务。将一个用户线程设置为守护线程的方法是在线程`对象创建之前（start之前）`用线程对象的 setDaemon（true）来`设置`。
  
  在后台守护线程中定义的线程（子线程）也是后台守护线程。后台`守护线程是JVM级别`的，比如垃圾回收线程就是一个经典的守护线程，在我们的程序中不再有任何线程运行时，程序就不会再产生垃圾，垃圾回收器也就无事可做，所以在回收JVM上仅剩的线程时，垃圾回收线程会自动离开。它始终在低级别的状态下运行，用于实时监控和管理系统中的可回收资源。
  `实战：`守护线程是运行在后台的一种特殊线程，独立于控制终端并且周期性地执行某种任务或等待处理某些已发生的事件。也就是说，守护线程`不依赖于终端，但是依赖于JVM，与JVM“同生共死”`。在JM中的所有线程都是守护线程时，JVM就可以退出了，如果还有一个或一个以上的非守护线程，则JVM不会退出。

![image-20200910175149849](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200910175151.png)

####  （待整理）sleep方法与wait方法的区别？

- sleep方法属于 `Thread类`的静态方法，wait方法则属于 `Object类`。
-  wait只能在同步方法和同步块中使用，而`sleep任何地方`都可以。
- wait无需捕捉异常，而sleep需要捕捉`抛出 InterruptException异常`。
- 线程调用当前对象的wait()方法会`让渡CPU`执行时间，并释放对象的“`锁标志`”，将该线程放入`对象等待池（wait pool）`。只有调用对象的notify() 和 notifyAll()方法时，才会把线程从对象等待池挪到`锁标志等待池（lock pool）`中去让他们重新争抢锁标识，线程重新`获得对象的锁就可以进入就绪状态`。
- sleep方法暂停执行指定的时间，`让出CPU`给其他线程，但`不会释放对象锁`，该方法既可以让其他同优先级或者高优先级的线程得到执行的机会，也可以让低优先级的线程得到执行机会。其他线程依旧在对象等待池，在`指定的时间过后又会自动恢复到就绪状态`。
- 在调用 `sleep方法`的过程中，线程`不会释放对象锁`。

#### start方法与run方法的区别?

- start方法用于启动线程，真正实现了多线程运行。在调用了线程的 start方法后，线程会在`后台执行`，`无须等待run方法体的代码执行完毕`，就可以继续执行下面的代码
- 在通过调用 Thread类的 `start方法启动`一个线程时，此线程处于`就绪状态`，并没有运行。
- run方法也叫作线程体，包含了要执行的线程的逻辑代码，`在调用run方法后`，不会创建线程，线程就进入`运行状态`，开始运行run方法中的代码。`在run方法运行结束后，该线程终止`，CPU再调度其他线程。（不会创建线程，就一个普通方法）

#### 线程的 sleep 方法和 yield 方法有什么区别？

- `sleep 方法`给其他线程运行机会时`不考虑线程的优先级`，因此会给低优先级的线程以运行的机会。`yield 方法只会给相同优先级或更高优先级的线程以运行的机会`。
- 线程执行 `sleep 方法后转入阻塞（blocked）状态`，而执行 `yield 方法后转入就绪（ready）状态`。
- sleep 方法声明抛出 InterruptedException 异常，而 yield 方法没有声明任何异常。
- `sleep 方法`比 yield 方法（跟操作系统 CPU 调度相关）`具有更好的可移植性`。

#### 为什么 Thread 类的 sleep 和 yield 方法是静态的？

Thread 类的 sleep 和 yield 方法，将在`当前正在执行的线程上运行`。

所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。

#### sleep(0) 有什么用途？

`Thread#sleep(0)` 方法，并非是真的要线程挂起 0 毫秒，意义在于这次调用 `Thread#sleep(0)` 方法，把当前线程确实的被冻结了一下，`让其他线程有机会优先执行`。`Thread#sleep(0)` 方法，是你的线程`暂时放弃 CPU` ，也就是释放一些未用的时间片给其他线程或进程使用，就相当于一个**让位动作**。

为了防止循环检查条件时，一直占用CPU时间片做无用功。交出CPU时间片，让别人干。

[《Sleep(0) 的妙用》](https://blog.csdn.net/qiaoquan3/article/details/56281092) ：假如AB两个线程为合作关系，A线程处理一些原始数据，数据处理到一定程度，交给B线程处理，在A处理原始数据的时候，B也要做一些准备工作，所以，AB是并发的，但是B做好准备之后，需要等待A处理好那些数据，接过A的数据，继续处理，因此，这个等待，如果A不使用信号或者等待条件来通知B的话，那么B必须一直轮询，查看A是否已完成，B线程所做的这个轮询是否会一直占用CPU来做无用的循环查看呢？因此B这个时候占用的cpu时间片做的是无用功，因此，这里sleep(0)就有作用，当B查看A没处理完数据的时候，B马上sleep(0)交出B的时间片，让操作系统调度A来运行(假设只有AB两个线程），那么这个时候，A就会得到充分的时间来处理它的数据。

![image-20200910195136862](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200910195138.png)

#### 定义一个可以安全退出的线程？

![image-20200910173135789](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200910173137.png)

注：`在抛出异常前都会清除中断标识位`，所以需要在catch里重新设置中断标识。方便后续判断，做一些资源释放工作。

### 终止线程的4中方式？

1. `正常运行结束`指线程体执行完成，线程自动结束

2. `使用退出标志退出`可以使用一个变量来控制循环，比如设置一个 boolean类型的标志，并通过设置这个标志为true或false来控制 while循环是否退出，在定义exit时使用了一个Java关键字 `volatile`，这个关键字用于使exit线程同步安全，也就是说在同一时刻只能有一个线程修改exit的值，在exit为true时， While循环退出。

   ![image-20200910162721647](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200910162722.png)

3. 使用interrupted方法终止线程，有一线两种情况：

   - 线程处于阻塞状态。当线程处于阻塞状态：s`leep()、wait()、join()或者调用 socket的 recelver、 accept等方法时`。在调用该线程的 Interrupt方法时，会抛出 InterruptException异常。我们通过代码捕获该异常，然后通过 break跳出状态检测循环(`在抛出异常前都会清除中断标识位，不break就会死循环`)，可以有机会结束这个线程的执行。

   - 线程未处于阻塞状态。此时，使用 isInterrupt方法判断线程的中断标志来退出循环（当标识用）。在调用 interrupt方法时，中断标志会被设置为true，并不能立刻退出线程，而是执行线程终止前的资源释放操作，等待资源释放完毕后退出该线程。

     ![image-20200910164038659](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200910164040.png)

4. `使用stop方法终止线程：不安全`就像突然关闭计算机的电源，可能会产生不可预料的后果。在程序使用 Thread.stop方法终止线程时，瞬间释放线程占用的同步对象锁，导致锁混乱和死锁，被保护的数据就可能岀现不一致的情况，并不推荐采用这种方法终止线程。

#### interrupted 和 isInterrupted 方法的区别？

`Thread#interrupted()` **静态**方法，查询当前线程的中断状态，并且清除原状态。如果一个线程被中断了，第一次调用 `#interrupted()` 方法则返回 `true` ，第二次和后面的就返回 `false` 了。线程中断仅仅是置线程的中断状态位，不会停止线程。需要用户自己去监视线程（用是否抛出异常来判断）的状态为并做处理。

`Thread#isInterrupted()` 方法，查询指定线程的中断状态，不会清除原状态。

### 为什么 wait, notify 和 notifyAll 这三方法不在 Thread 类里面？为什么 wait 和 notify 方法要在同步块中调用？

这三个是方法用于Java中锁对于线程间的等待通知机制的实现。三个方法能够被调用的前提是已经获取了对象的互斥锁。

Java提供的锁是属于对象的，每个对象都有唯一的一把锁标识。通过让线程争抢唯一的锁标识，并让争抢锁失败、或者主动放弃锁的线程，进入对象等待池中，来保证在线程并发的情况下，对共享资源操作的原子性，和先线程间的互斥。

wait()是让线程主动放弃锁，并进入对象等待池。而notify() 和 notifyAll()是把线程从对象等待池挪到锁标志等待池中去让他们重新争抢锁标识。

总之对象负责协调线程的工作，而 wait, notify 和 notifyAll 方法是对象协调线程互斥的手段。所以这三个方法需要放到Object中。

#### [为什么 wait 和 notify 方法要在同步块中调用？](https://blog.csdn.net/lsgqjh/article/details/61915074)

- wait()、notify()、notifyAll() 这三个方法能够被调用的`前提`是已经`获取了相应的互斥锁。`所以是在 synchronized{}内部被调用的。
- Java API 强制要求这样做，如果在synchronized{}外部调用，或者锁定的 this，而用 target.wait() 调用的话，你的代码会`抛出 IllegalMonitorStateException异常`。
- 还有一个原因是为了避免 wait 和 notify 之间产生竞态条件。

## ThreadLocal

https://www.cnblogs.com/ilellen/p/4135266.html

http://ifeve.com/java-threadlocal%E7%9A%84%E4%BD%BF%E7%94%A8/

## 并发工具类

### Lock和Condition

Java SDK 并发包通过 Lock 和 Condition 两个接口来实现管程，其中 Lock 用于解决互斥问题，Condition 用于解决同步问题。

synchronized 没有办法解决“破坏不可抢占条件方案”。 原因是synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。

#### 再造管程的理由

Java 语言本身提供的 synchronized 也是管程的一种实现，那为什么还要在 SDK 里提供Lock实现呢？

- `synchronized` *没有办法解决“破坏不可抢占条件方案”*。 原因是synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。除非线程重新获得synchronized隐式锁。
- `破坏不可抢占条件，对于程序来说性能（吞吐量、并发量）是最高的`。
  - 占有且等待：一次申请所有资源：得等其他资源全部释放，等待时间耗时，影响其他使用线程手里的资源
  - 不可抢占：申请不到，就不等了。不影响其他线程使用手里的资源。
  - 循环等待：顺序申请资源：得等其他资源释放，也耗时。影响其他使用线程手里的资源

对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果`申请不到，可以主动释放它占有的资源`，这样不可抢占这个条件就破坏掉了。

Lock接口的三个方法（三种方案）：这三种方案全面弥补 synchronized 的问题

1. `能够响应中断：`synchronized 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，`一旦发生死锁`，就没有任何机会来唤醒阻塞的线程。但如果`阻塞状态的线程能够响应中断信号`，也就是说当我们给阻塞的线程发送`中断信号`的时候，`能够唤醒它`，那它就有机会释放曾经持有的锁 A。这样就破坏了不可抢占条件了。

   - 支持中断的API  
     - `void lockInterruptibly() throws InterruptedException;`

2. `支持超时`：如果线程在一段时间之内`没有获取到锁`，`不是进入阻塞状态`，而是`返回一个错误`，那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。

   - 支持超时的API

     boolean tryLock(long time, TimeUnit unit) throws InterruptedException;

3. `非阻塞地获取锁：`如果尝试获取锁失败，并`不进入阻塞状态`，而是`直接返回`，那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。

   - 支持非阻塞获取锁的API
     - `boolean tryLock();`

#### Java SDK 里面 Lock 靠什么保证可见性呢？

```java

class X {
  private final Lock rtl =
  new ReentrantLock();
  int value;
  public void addOne() {
    // 获取锁
    rtl.lock();  
    try {
      value+=1;
    } finally {
      // 保证锁能释放
      rtl.unlock();
    }
  }
}
```

它是利用了 volatile 相关的 Happens-Before 规则。Java SDK 里面的 ReentrantLock，`内部持有一个 volatile 的成员变量 state`，获取锁的时候，会读写 state 的值；解锁的时候，也会读写 state 的值（简化后的代码如下面所示）。也就是说，在执行 value+=1 之前，程序先读写了一次 volatile 变量 state，在执行 value+=1 之后，又读写了一次 volatile 变量 state。

根据相关的 Happens-Before 规则：

- 顺序性规则：对于线程 T1，value+=1 Happens-Before 释放锁的操作 unlock()；
- volatile 变量规则：由于 state = 1 会先读取 state，所以线程 T1 的 unlock() 操作 Happens-Before 线程 T2 的 lock() 操作；
- 传递性规则：**线程 T1 的 value+=1 Happens-Before 线程 T2 的 lock() 操作。**

```java

class SampleLock {
  volatile int state;
  // 加锁
  lock() {
    // 省略代码无数
    state = 1;
  }
  // 解锁
  unlock() {
    // 省略代码无数
    state = 0;
  }
}
```

底层原理：就是对volatile对象操作后会跟着一个字节码指令：它的作用是将*本处理器*的*缓存*写入了主内存，该写入动作也会引起**别的处理器或者别的内核无效化（ Invalidate）其缓存**。

- 就是CPU 的堆栈寄存器里的缓存，刷新到内存中。

##### [Lock怎么保证原子性？](https://blog.csdn.net/tingfeng96/article/details/52219649?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.edu_weight&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.edu_weight)



#### 什么是可重入锁

`可重入锁：`指的是线程可以*重复获取同一把锁*。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200917173414.png" alt="image-20200917173412596" style="zoom: 50%;" />

`可重入函数：`指的是*多个线程可以同时调用该函数，每个线程都能得到正确结果*；同时在一个线程内**支持线程切换**，无论被切换多少次，结果都是正确的。

- 多线程可以同时执行，还支持线程切换，这意味着什么呢？线程安全啊。所以，可重入函数是线程安全的。

#### 公平锁与非公平锁

在使用 `ReentrantLock` 的时候，你会发现 ReentrantLock 这个类有两个构造函数。一个是无参构造函数，一个是`传入 fair 参数的构造函数`。

fair 参数代表的是锁的公平策略：锁都对应着一个等待队列，如果一个线程没有获得锁，就会进入等待队列，当有线程释放锁的时候，就需要从等待队列中唤醒一个等待的线程

- true: 就表示需要`构造一个公平锁`：如果是公平锁，唤醒的策略就是`谁等待的时间长，就唤醒谁`，很公平
- false：反之则表示要`构造一个非公平锁`：如果是非公平锁，则`不提供这个公平保证`，有可能等待时间短的线程反而先被唤醒。

```java

//无参构造函数：默认非公平锁
public ReentrantLock() {
    sync = new NonfairSync();
}
//根据公平策略参数创建锁
public ReentrantLock(boolean fair){
    sync = fair ? new FairSync() 
                : new NonfairSync();
}
```

#### Lock的底层实现

[synchronized和lock的实现原理](https://blog.csdn.net/tingfeng96/article/details/52219649?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.edu_weight&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.edu_weight)

[Lock与Synchronized底层问题讨论](https://blog.csdn.net/u013358266/article/details/106004820)

[Java锁--Lock实现原理(底层实现)](https://blog.csdn.net/Luxia_24/article/details/52403033)

[AQS实现原理](https://segmentfault.com/a/1190000017372067)

[死磕synchronized底层实现](https://zhuanlan.zhihu.com/p/141624304)

[Hotspot 重量级锁ObjectMonitor（二） 源码解析](https://blog.csdn.net/qq_31865983/article/details/105160248?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~all~first_rank_v2~rank_v25-2-105160248.nonecase&utm_term=objectmonitor%E8%A7%A3%E9%87%8A)

为什么要设置可重入锁？为什么要整出公平锁和非公平锁？

#### 用锁的最佳实践

最值得推荐的是并发大师 Doug Lea**《Java 并发编程：设计原则与模式》**一书中，推荐的三个用锁的最佳实践，它们分别是：

- 永远**只在**更新`对象的成员变量时加锁`
- 永远**只在**访问`可变的成员变量时加锁`
- 永远*不在*`调用其他对象的方法时加锁`
  - 因为调用其他对象的方法，实在是太不安全了，也许“其他”方法里面有线程 `sleep()` 的调用，也可能会有`奇慢无比的 I/O 操作`，这些都会*严重影响性能*。更可怕的是，**“其他”类的方法可能也会加锁**，然后双重加锁就可能导致**死锁**。

`减少锁的持有时间`、`减小锁的粒度等`业界广为人知的规则，其实本质上它们都是相通的，不过是在该加锁的地方加锁而已。

##### 总结

Java SDK 并发包里的 Lock 接口里面的每个方法，你可以感受到，都是经过深思熟虑的。除了支持`类似 synchronized 隐式加锁的 lock() 方法外`，还支持**超时、非阻塞、可中断**的方式获取锁，这三种方式为我们编写更加安全、健壮的并发程序提供了很大的便利。



#### 问题

你已经知道 tryLock() 支持非阻塞方式获取锁，下面这段关于转账的程序就使用到了 tryLock()，你来看看，它是否存在死锁问题呢？

```java

class Account {
  private int balance;
  private final Lock lock
          = new ReentrantLock();
  // 转账
  void transfer(Account tar, int amt){
    while (true) {
      if(this.lock.tryLock()) {
        try {
          if (tar.lock.tryLock()) {
            try {
              this.balance -= amt;
              tar.balance += amt;
            } finally {
              tar.lock.unlock();
            }
          }//if
        } finally {
          this.lock.unlock();
        }
      }//if
    }//while
  }//transfer
}
```

1. `死循环`，有锁没群，都出不来：可能是为了复现活锁的问题？

2. 不会出现死锁，`会出现活锁`：

   1. 默认构造函数的ReentrantLock是一个非公平搜，非公平锁不是按照排队的顺序被唤醒，非公平锁的场景：*应该是线程释放锁之后，如果来了一个线程获取锁，他不必去排队直接获取到，应该不会入队（疑问，待整理）*。

   - user1，user2`两账户相互转账`：线程A获取了user1.trylock，线程B获取了user2.trylock，线程A尝试获取u2.trylock，不能成功，线程A结束，同时线程B尝试获取user2.trylock，不能成功，线程B结束。他俩都不用排队又开始新的一轮，这样一直循环下去！形成活锁。

修改后的代码：

```java
class Account {
  private int balance;
  private final Lock lock
          = new ReentrantLock();
  // 转账
  void transfer(Account tar, int amt) throws InterruptedException {
        boolean flag = true;
        while (flag) {
          // 纳米秒
          if(this.lock.tryLock(new Random().nextInt(5)，TimeUnit.NANOSECONDS)) {
            try {
              // 这不加随机时间
              // 加时间：如果阻塞在内层，内层锁拿不到等一段时间，此时外层锁是没释放的，这段时间可能形成死锁；破解活锁一个随机时间就够了。
              if (tar.lock.tryLock()) {
                try {
                  this.balance -= amt;
                  tar.balance += amt;
                  flag = false;
                } finally {
                  tar.lock.unlock();
                }
              }//if
            } finally {
              this.lock.unlock();
            }
          }//if
        }//while
  }//transfer
}
```

#### Condition：Dubbo如何用管程实现异步转同步？

Java SDK 并发包里的 Condition，**Condition 实现了管程模型里面的条件变量。**

##### 阻塞队列

支持多个条件变量能够让我们的并发程序可读性更好，实现起来也更容易。例如，实现一个阻塞队列，就需要两个条件变量。

一个阻塞队列，需要两个条件变量，`一个是队列不空（空队列不允许出队）`，另一个是`队列不满（队列已满不允许入队）`。

不过，这里你需要注意，**Lock 和 Condition 实现的管程**，线程等待和通知需要调用 *await()、signal()、signalAll()，它们的语义和 wait()、notify()、notifyAll() 是相同的*。

- 如果一不小心在 Lock&Condition 实现的管程里调用了 wait()、notify()、notifyAll()，那程序可就彻底玩儿完了。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200918161252.png" alt="image-20200918161250353" style="zoom:33%;" />



##### 同步与异步

我们平时写的代码，基本都是同步的。但最近几年，`异步编程大火`。那同步和异步的区别到底是什么呢？

通俗点来讲就是调用方是否需要等待结果

- 如果需要**等待结果**，就是**同步**；
- 如果**不需要等待结果**，就是**异步**。

*同步，是 Java 代码默认的处理方式*。

如果你想让你的程序支持异步：

- 调用方`创建一个子线程`，在子线程中执行方法调用，这种调用我们称为异步调用；
- 方法实现的时候，`创建一个新的线程执行主要逻辑，主线程直接 return`，这种方法我们一般称为异步方法。

##### Dubbo 源码分析

其实在编程领域，异步的场景还是挺多的，

- 比如 `TCP 协议本身就是异步`的，我们工作中经常用到的 *RPC 调用，在 TCP 协议层面，发送完 RPC 请求后，线程是不会等待 RPC 的响应结果的*。

  

###### 为什么平时工作中的 RPC 调用大多数都是同步的？

有人帮你做了异步转同步的事情。例如目前知名的 RPC 框架 Dubbo 就给我们做了异步转同步的事情。

对于下面一个简单的 RPC 调用，默认情况下 sayHello() 方法，是个同步方法，也就是说，执行 service.sayHello(“dubbo”) 的时候，线程会停下来等结果。



将调用线程 dump 出来的话，如下图。发现调用线程阻塞了，线程状态是 TIMED_WAITING。*本来发送请求是异步的，但是调用线程却阻塞了*，说明 Dubbo 帮我们做了异步转同步的事情。

![image-20200918162630463](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200918162632.png)

通过调用栈，你能看到线程是阻塞在 DefaultFuture.get() 方法上，所以可以推断：*Dubbo 异步转同步的功能应该是通过 DefaultFuture 这个类实现的*。DubboInvoker 的 108 行调用了 DefaultFuture.get()，这一行很关键，我稍微修改了一下列在了下面。这一行先调用了 *request(inv, timeout)* 方法，这个方法其实就是发送 RPC 请求，之后通过*调用 get() 方法等待 RPC 返回结果*。

```java

public class DubboInvoker{
  Result doInvoke(Invocation inv){
    // 下面这行就是源码中108行
    // 为了便于展示，做了修改
    return currentClient 
      .request(inv, timeout)
      .get();
  }
}
```

DefaultFuture 这个类是很关键，我把相关的代码精简之后，列到了下面。不过在看代码之前，你还是有必要重复一下我们的需求：*当 RPC 返回结果之前，阻塞调用线程，让调用线程等待；当 RPC 返回结果后，唤醒调用线程，让调用线程重新执行*。不知道你有没有似曾相识的感觉，这不就是**经典的等待 - 通知机制**。

```java

// 创建锁与条件变量
private final Lock lock 
    = new ReentrantLock();
private final Condition done 
    = lock.newCondition();

// 调用方通过该方法等待结果
Object get(int timeout){
  long start = System.nanoTime();
  lock.lock();
  try {
      while (!isDone()) {
          done.await(timeout);
          long cur = System.nanoTime();
          // 返回数据或者潮湿结束
          if (isDone() || cur-start > timeout){
              break;
          }
      }
  } finally {
  	lock.unlock();
  }
    
  if (!isDone()) {
  throw new TimeoutException();
  }
    
  return returnFromResponse();
}
// RPC结果是否已经返回
boolean isDone() {
  return response != null;
}

// RPC结果返回时调用该方法   
private void doReceived(Response res) {
  lock.lock();
  try {
    response = res;
    if (done != null) {
      done.signal();
    }
  } finally {
    lock.unlock();
  }
}
```

例如 `websocket 也是一个异步的通信协议`，如果基于这个协议实现一个简单的 RPC，你也会遇到异步转同步的问题。

现在很`多公有云的 API 本身也是异步的`，例如创建云主机，就是一个异步的 API，调用虽然成功了，但是云主机并没有创建成功，你需要调用另外一个 API 去轮询云主机的状态。如果你需要在项目内部封装创建云主机的 API，你也会面临异步转同步的问题，因为同步的 API 更易用。

###### 课后思考

DefaultFuture 里面唤醒等待的线程，用的是 signal()，而不是 signalAll()，你来分析一下，这样做是否合理呢？

不合理，会导致很多请求超时，看了源码是调用signalAll()。

signalall可以避免极端情况线程一直没有被点名，只能等待超时。

### Semaphore（信号量）：如何快速实现一个限流器

在编程世界里，*线程能不能执行，也要看信号量是不是允许*。

#### 信号量模型

**信号量模型**：`一个计数器`，`一个等待队列`，`三个方法`。在信号量模型里，计数器和等待队列对外是透明的，所以只能通过信号量模型提供的三个方法来访问它们，这三个方法分别是：`init()、down() 和 up()`。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200918165336.png" alt="image-20200918165334622" style="zoom:50%;" />

这三个方法详细的语义具体如下所示

- `init()：`设置计数器的初始值。**计数器负值标识睡眠的线程数**。
- `down() 倒计时中的绿灯：`线程进来，先计数器的值**减 1**；如果此时计数器的值**小于 0**，则当前**线程将被阻塞**，否则当前线程可以继续执行。
- `up() 红灯：`计数器的值**加 1**；如果此时计数器的值**小于或者等于 0**，则**唤醒等待队列中的一个线程**，并将其**从等待队列中移除**。
  - \>0就意味着没有阻塞的线程了，所以只有<=0的情况才需要唤醒一个等待的线程

**up()  为什么判断  <= 0 ？**

1. 反证法验证一下，假如一个线程先执行down()操作，那么此时count的值是0，接着这个线程执行up()操作，此时count的值是1，如果count应该是大于等于0，那么*应该唤醒其他线程，可是此时并没有线程在睡眠呀，count的值不应该是大于等于0*。
2. 假如一个线程t1执行down()操作，此时count = 0，然后t1被中断，另外的线程t2执行down()操作，此时count=-1，t2阻塞睡眠，另外的线程t3执行down()操作，count=-2，t3也睡眠。*count=-2 说明有两个线程在睡眠，接着t1执行up() 操作，此时count=-1，小于等于0，唤醒t2或者t3其中一个线程，*假如计数器count是大于等于0才唤醒其他线程，这明显是不对的。

这里提到的 `init()、down() 和 up()` 三个方法都是**原子性**的，并且这个原子性是由信号量模型的实现方保证的。在 Java SDK 里面，信号量模型是由 java.util.concurrent.Semaphore 实现的，*Semaphore 这个类能够保证这三个方法都是原子操作*。

在 Java SDK 并发包里，`down() 和 up() 对应的则是 acquire() 和 release()`。

代码化的信号量模型:

```java

class Semaphore{
  // 计数器
  int count;
  // 等待队列
  Queue queue;
  // 初始化操作
  Semaphore(int c){
    this.count=c;
  }
  // 
  void down(){
    this.count--;
    if(this.count<0){
      //将当前线程插入等待队列
      //阻塞当前线程
    }
  }
  void up(){
    this.count++;
    if(this.count<=0) {
      //移除等待队列中的某个线程T
      //唤醒线程T
    }
  }
}
```

#### 如何使用信号量

##### 信号量实现累加器（互斥锁）

- count+=1 操作是个临界区，只允许一个线程执行，也就是说要保证互斥。
- 在进入临界区之前执行一下 down() 操作，退出临界区之前执行一下 up() 操作就可以了。下面是 Java 代码的示例，acquire() 就是信号量里的 down() 操作，release() 就是信号量里的 up() 操作。

```java

	static int count;
    //初始化信号量
    static final Semaphore s = new Semaphore(1);
    //用信号量保证互斥
    static void addOne() throws InterruptedException {
        // 能响应中断的 down() 获取
        s.acquire();
        try {
            count += 1;
        } finally {
            // up() 释放
            s.release();
        }
    }
```

##### 快速实现一个限流器

Java SDK 里面提供了 Lock，为啥还要提供一个 Semaphore ？其实实现一个互斥锁，仅仅是 Semaphore 的部分功能，Semaphore 还有一个功能是 Lock 不容易实现的，那就是：`Semaphore 可以允许多个线程访问一个临界区。`

- 比较常见的需求就是我们工作中遇到的**各种池化资源**，例如连接池、对象池、线程池等等。其中，你可能**最熟悉数据库连接池**，在同一时刻，一定是允许多个线程同时使用连接池的，当然，每个连接在被释放前，是不允许其他线程使用的。
- 一个**对象池的需求**。所谓对象池呢，*指的是一次性创建出 N 个对象，之后所有的线程重复利用这 N 个对象*，当然对象在被释放前，也是不允许其他线程使用的。
  - **对象池**，可以用 List 保存实例对象，这个很简单。
  - 但关键是**限流器的设计**，这里的限流，指的是不允许多于 N 个线程同时进入临界区。

对象池示例代码：

```java

class ObjPool<T, R> {
  final List<T> pool;
  // 用信号量实现限流器
  final Semaphore sem;
  // 构造函数
  ObjPool(int size, T t){
    pool = new Vector<T>(){};
    for(int i=0; i<size; i++){
      pool.add(t);
    }
    sem = new Semaphore(size);
  }
  // 利用对象池的对象，调用func
  R exec(Function<T,R> func) {
    T t = null;
    sem.acquire();
    try {
      t = pool.remove(0);
      return func.apply(t);
    } finally {
      pool.add(t);
      sem.release();
    }
  }
}
// 创建对象池
ObjPool<Long, String> pool = 
  new ObjPool<Long, String>(10, 2);
// 通过对象池获取t，之后执行  
pool.exec(t -> {
    System.out.println(t);
    return t.toString();
});
```

我们用一个 List来保存对象实例，用 Semaphore 实现限流器。

- 关键的代码是 ObjPool 里面的 exec() 方法，这个方法里面实现了限流的功能。
  - 在这个方法里面，我们首先调用 `acquire() 方法`（与之匹配的是在 finally 里面调用 release() 方法），假设对象池的大小是 10，信号量的计数器初始化为 10，那么前 10 个线程调用 acquire() 方法，都能继续执行，相当于通过了信号灯，而`其他线程则会阻塞在 acquire() 方法上`。对于通过信号灯的线程，我们*为每个线程分配了一个对象 t（这个分配工作是通过 pool.remove(0) 实现的），分配完之后会执行一个回调函数 func，而函数的参数正是前面分配的对象 t ；执行完回调函数之后，它们就会释放对象（这个释放工作是通过 pool.add(t) 实现的），同时调用 release() 方法来更新信号量的计数器*。如果此时信号量里计数器的值小于等于 0，那么说明有线程在等待，此时会自动唤醒等待的线程。

#### 总结

Java 在并发编程领域走的很快，重点支持的还是`管程模型`。 管程模型理论上解决了*信号量模型的一些不足，主要体现在易用性和工程化方面*，

- 条件模糊：例如用信号量解决我们曾经提到过的阻塞队列问题，就比管程模型麻烦很多。
  - 信号量可以实现的独特功能就是同时允许多个线程进入临界区，但是信号量不能做的就是同时唤醒多个线程去争抢锁，*只能唤醒一个阻塞中的线程*，而且信号量模型是*没有Condition的概念*的，即*阻塞线程被醒了直接就运行了而不会去检查此时临界条件是否已经不满足了*，基于此考虑信号量模型才会设计出只能让一个线程被唤醒，否则就会出现因为缺少Condition检查而带来的线程安全问题。正因为缺失了Condition，所以用信号量来实现阻塞队列就很麻烦，因为要自己实现类似Condition的逻辑。

##### 课后思考

在上面对象池的例子中，对象保存在了 Vector 中，Vector 是 Java 提供的线程安全的容器，如果我们把 Vector 换成 ArrayList，是否可以呢？

因为信号量支持多个线程进入临界区，执行list的add和remove方法时可能是多线程并发执行

### ReadWriteLock：如何快速实现一个完备的缓存？

**分场景优化性能，提升易用性**。

**针对读多写少**这种并发场景，Java SDK 并发包提供了读写锁——`ReadWriteLock`

读写锁都遵守以下三条基本原则：

- 允许多个线程`同时读`共享变量；
- `只允许一个线程写`共享变量；
- 如果一个`写`线程正在执行写操作，此`时禁止读`线程读共享变量。

读写锁与互斥锁的一个重要区别就是读写锁允许多个线程同时读共享变量，而互斥锁是不允许的，这是读写锁在读多写少场景下性能优于互斥锁的关键。但读写锁的写操作是互斥的，当一个线程在写共享变量的时候，是不允许其他线程执行写操作和读操作。

#### 快速实现一个缓存



使用缓存首**先要解决缓存数据的初始化问题**。缓存数据的初始化，可以采用一次性加载的方式，也可以使用按需加载的方式。

- 如果*源头数据的数据量不大*，就可以采用`一次性加载`的方式，只需在应用启动的时候把源头数据查询出来

  <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919155718.png" alt="image-20200919155717191" style="zoom:50%;" />

- 如果*源头数据量非常大*，那么就需要按需加载了，**按需加载也叫懒加载**，指的是只有当应用查询缓存，并且数据不在缓存里的时候，才触发加载源头相关数据进缓存的操作。

  <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919155807.png" alt="image-20200919155805902" style="zoom:50%;" />

##### 一次性加载

可重入的读写锁：`ReentrantReadWriteLock();`

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919155444.png" alt="image-20200919155434370" style="zoom:50%;" />

##### 按需加载（懒加载）

假设缓存的源头是数据库。如果缓存中*没有缓存目标对象，那么就需要从数据库中加载，然后写入缓存，写缓存需要用到写锁*，所以在代码中的⑤处，我们调用了 w.lock() 来获取写锁。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919160051.png" alt="image-20200919160050506" style="zoom:50%;" />

在获取写锁之后，我们并没有直接去查询数据库，而是在代码⑥⑦处，重新验证了一次缓存中是否存在，**再次验证**如果还是不存在，我们才去查询数据库并更新本地缓存。

- double check问题：原因是在高并发的场景下，有可能会有`多线程竞争写锁`。多个线程可能同时请求写锁，所以，再次验证的方式，`能够避免高并发场景下重复查询数据的问题`。

优化：

​	因为这里可能很多业务都会使用这个缓存懒加载，实际生产环境，写缓存操作可能会比较多，那么*不同的缓存key，实际上是没有并发冲突的*，所以这里的`读写锁可以按key前缀拆分`，即使是同一个key，也可以类似ConcurrentHash 一样`分段来减少并发冲突`

##### 读写锁的升级与降级

先是获取读锁，然后再升级为写锁，对此还有个专业的名字，叫`锁的升级`。可惜 `ReadWriteLock 并不支持这种升级`。在上面的代码示例中，*读锁还没有释放，此时获取写锁，会导致写锁永久等待，最终导致相关线程都被阻塞，永远也没有机会被唤醒*。锁的升级是不允许的，这个你一定要注意。

虽然**读写锁**，*锁的升级是不允许的，但是锁的降级却是允许的*。在释放写锁前降级为读锁。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919160835.png" alt="image-20200919160822628" style="zoom:50%;" />





#### 总结

读写锁类似于 ReentrantLock

- **支持公平模式和非公平模式**。
- 读锁和写锁都实现了 java.util.concurrent.locks.Lock 接口，所以除了`支持 lock() 方法`外，`tryLock()、lockInterruptibly()` 等方法也都是支持的。
- 但是有一点需要注意，那就是`只有写锁支持条件变量，读锁是不支持条件变量`的，读锁调用 newCondition() 会抛出 UnsupportedOperationException 异常。

`读写锁总结：`

1. *获取写锁的前提是读锁和写锁均未被占用*
2. *获取读锁的前提是没有其他线程占用写锁*
3. *申请写锁时不中断其他线程申请读锁（不能锁升级的原因）*
4. 公平锁如果过有写申请，能禁止读锁



用 ReadWriteLock 实现了一个简单的缓存，`虽然解决了缓存的初始化问题`，但是`没有解决`缓存数据与源头数据的同步问题，这里的数据同步指的是`保证缓存数据和源头数据的一致性`。

保证缓存一致性：

- **超时机制：**所谓超时机制指的是加载进`缓存的数据`不是长久有效的，而是`有时效`的，当缓存的数据超过时效，也就是超时之后，这条数据在缓存中就失效了。

  - 访问缓存中失效的数据，会*触发缓存重新从源头把数据加载进缓存*。
  - 当然也可以*在源头数据发生变化时，快速反馈给缓存*。
    - 例如 MySQL 作为数据源头，可以通过*近实时地解析 binlog 来识别数据是否发生了变化*，如果发生了变化就将最新的数据推送给缓存。

- **采取数据库和缓存的双写方案**：

  - **先写缓存再写数据库：使用分布式锁**
    - 先写缓存再写数据库这种方案**及时性比较高**，可以去慢慢去写数据库的，这种方式和cpu缓存写到内存差不多的。
  - **先写数据库再写缓存**：
    - 使用binlog，canal+mq，但是感觉这个还得看具体情况，有可能binlog使用了组提交，不是马上写的binlog文件中，感觉也是会有延迟
    - 定时任务定时的扫描任务表
    - 使用消息队列

  

#### 课后问题

有同学反映线上系统停止响应了，CPU 利用率很低，你怀疑有同学一不小心写出了读锁升级写锁的方案，那你该如何验证自己的怀疑呢？

`第一种方法：`

- ①ps -ef | grep java查看pid
- ②top -p查看java中的线程
- ③使用jstack将其堆栈信息保存下来，查看是否是锁升级导致的阻塞问题。

`第二种方法：`感觉可以**调用下有获取只有读锁的接口，看下是否会阻塞**，如果没有阻塞可以在调用下写锁的接口，如果阻塞表明有读锁。

`第三种方法：`**源代码分析**。查找ReentrantReadWriteLock在项目中的引用，看下写锁是否在读锁释放前尝试获取

`第四种方法：`如果线上是Web应用，应用服务器比如说是**Tomcat，并且开启了JMX，则可以通过JConsole等工具远程查看下线上死锁的具体情况**



### StampedLock：有没有比读写锁更快的锁？

在**读多写少的场景中**，比读写锁更快技术方案。Java 在 1.8 这个版本里，提供了一种叫 **StampedLock 的锁，它的性能就比读写锁还要好**。

如果处理业务需要保持互斥，那么就用互斥锁，如果不需要保持互斥才可以用读写锁。一般来讲缓存是不需要保持互斥性的，能接受瞬间的不一致。

#### StampedLock 支持的三种锁模式

ReadWriteLock 支持两种模式：

- 一种是读锁
- 一种是写锁

StampedLock 支持三种模式，分别是：

- 写锁
- 悲观读锁
- 乐观读：操作是无锁的。



*写锁、悲观读锁的语义和 ReadWriteLock 的写锁、读锁的语义非常类似*，允许多个线程同时获取悲观读锁，但是只允许一个线程获取写锁，写锁和悲观读锁是互斥的。

不同的是：StampedLock 里的写锁和悲观读锁`加锁成功`之后，都会返`回一个 stamp`；然后`解锁`的时候，需要`传入这个 stamp`。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919170505.png" alt="image-20200919170503720" style="zoom:50%;" />

StampedLock 的性能之所以比 ReadWriteLock 还要好，其关键是 StampedLock 支持乐观读的方式。ReadWriteLock 支持*多个线程同时读，但是当多个线程同时读的时候，所有的写操作会被阻塞*；而 StampedLock 提供的*乐观读，是允许一个线程获取写锁的*，也就是说不是所有的写操作都被阻塞。

**乐观读这个操作是无锁的**，所以相比较 ReadWriteLock 的读锁，乐观读的性能更好一些。

如果*执行乐观读操作的期间，存在写操作，会把乐观读升级为悲观读锁*。这个做法挺合理的，否则你就需要在一个循环里反复执行乐观读，直到执行乐观读操作的期间没有写操作（只有这样才能保证 x 和 y 的正确性和一致性），而*循环读会浪费大量的 CPU*。升级为悲观读锁，代码简练且不易出错，建议你在具体实践时也采用这样的方法。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919170927.png" alt="image-20200919170926560" style="zoom:50%;" />

##### 进一步理解乐观读

数据库乐观锁：在表增加了一个数值型版本号字段 version，每次更新 时候，都将 version 字段加 1。修改时将ID和version一起当条件查询，如果返回1，证明生产订单期间没有修改过数据。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919171352.png" alt="image-20200919171350698" style="zoom:50%;" />



乐观读中的 long stamp 就相当于数据库乐观锁中的version

#### StampedLock 使用注意事项

对于读多写少的场景 StampedLock 性能很好，简单的应用场景**基本上可以替代 ReadWriteLock**，但是 *StampedLock 的功能仅仅是 ReadWriteLock 的子集*

- StampedLock **不支持重入**
- StampedLock 的悲观读锁、写锁都**不支持条件变量**
- 如果线程**阻塞**在 StampedLock 的 readLock() 或者 writeLock() 上时，此时**调用该阻塞线程的 interrupt() 方法，会导致 CPU 飙升**。
  - 内部实现里while循环里面对`中断的处理有点问题`
  - 使用 StampedLock 一定不要调用中断操作，如果需要支持中断功能，一定使用可中断的`悲观读锁 readLockInterruptibly()` 和`写锁 writeLockInterruptibly()`。
  - <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919172128.png" alt="image-20200919172125512" style="zoom:50%;" />

#### 课后思考

`StampedLock` 支持锁的*降级（通过 tryConvertToReadLock()方法实现）和升级（通过 tryConvertToWriteLock() 方法实现）*，但是建议你要慎重使用。下面的代码也源自 Java 的官方示例，我仅仅做了一点修改，隐藏了一个 Bug，你来看看 Bug 出在哪里吧。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919173700.png" alt="image-20200919173659399" style="zoom:50%;" />

在锁升级成功的时候，最后没有释放最新的写锁`ws`，可以在if块的break上加个`stamp=ws`进行释放

### CountDownLatch和CyclicBarrier：让多线程步调一致

##### 对账系统

对账系统：

- 先确认存在未对账的订单，之后一个个订单对比差异。
- 先查询订单，然后查询派送单，之后对比订单和派送单，将差异写入差异库。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919180831.png" alt="image-20200919180827367" style="zoom:50%;" />

代码：

```java

while(存在未对账订单){
  // 查询未对账订单
  pos = getPOrders();
  // 查询派送单
  dos = getDOrders();
  // 执行对账操作
  diff = check(pos, dos);
  // 差异写入差异库
  save(diff);
} 
```

线程执行示意图：

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919181219.png" alt="image-20200919181216774" style="zoom:50%;" />

##### 并行优化，用 CountDownLatch 实现线程等待

CountDownLatch对计数器减 1 的操作是通过调用 `latch.countDown();` 来实现的

线程执行示意图：

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919181335.png" alt="image-20200919181334172" style="zoom:50%;" />

代码：

```java

// 创建2个线程的线程池
Executor executor = 
  Executors.newFixedThreadPool(2);
while(存在未对账订单){
  // 计数器初始化为2
  CountDownLatch latch = 
    new CountDownLatch(2);
  // 查询未对账订单
  executor.execute(()-> {
    pos = getPOrders();
    latch.countDown();
  });
  // 查询派送单
  executor.execute(()-> {
    dos = getDOrders();
    latch.countDown();
  });
  
  // 等待两个查询操作结束
  latch.await();
  
  // 执行对账操作
  diff = check(pos, dos);
  // 差异写入差异库
  save(diff);
}
```

#### CyclicBarrier进一步优化性能

查询操作和对账操作也是可以并行的，也就是说，在执行*对账操作的时候，可以同时去执行下一轮的查询操作*。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919192850.png" alt="image-20200919192848740" style="zoom:50%;" />

两次查询操作能够和对账操作并行，对账操作还依赖查询操作的结果，这明显有点生产者 - 消费者的意思，设计了两个队列，并且两个队列的元素之间还有对应关系。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919192907.png" alt="image-20200919192906037" style="zoom:50%;" />

CyclicBarrier 的计数器有自动重置的功能，当减到 0 的时候，会自动重置你设置的初始值。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200919193009.png" alt="image-20200919193008050" style="zoom:50%;" />



#### 总结

CountDownLatch 和 CyclicBarrier 是 Java 并发包提供的两个非常易用的`线程同步工具类`，这两个工具类用法的区别在这里还是有必要再强调一下：

`CountDownLatch` 主要用来解决`一个线程等待多个线程的场景`，可以类比旅游团团长要等待所有的游客到齐才能去下一个景点；

`CyclicBarrier` 是`一组线程之间互相等待`，更像是几个驴友之间不离不弃。

除此之外 *CountDownLatch 的计数器是不能循环利用的*，也就是说一旦计数器减到 0，*再有线程调用 await()，该线程会直接通过*。

但 *CyclicBarrier 的计数器是可以循环利用*的，而且*具备自动重置*的功能，一旦计数器减到 0 会自动重置到你设置的初始值。

除此之外，*CyclicBarrier 还可以设置回调函数*。

#### 课后思考

本章最后的示例代码中，CyclicBarrier 的回调函数我们使用了一个固定大小的线程池，你觉得是否有必要呢？

1. 使用线程池是为了`异步操作`，否则回掉函数是同步调用的，也就是本次对账操作执行完才能进行下一轮的检查。
2. 线程数量固定为1，`防止了多线程并发导致的数据不一致`，因为订单和派送单是两个队列，只有单线程去两个队列中取消息才不会出现消息不匹配的问题。

CyclicBarrier的回调函数在哪个线程执行啊？

CyclicBarrier的回调函数执行在一个回合里最后执行await()的线程上，而且同步调用回调函数check()，调用完check之后，才会开始第二回合。所以check如果不另开一线程异步执行，就起不到性能优化的作用了。

### 并发容器：都有哪些“坑”需要我们填？

#### 同步容器及其注意事项

Java 中的容器主要可以分为四个大类，分别是 List、Map、Set 和 Queue

如何将非线程安全的容器变成线程安全的容器？

- 只要把非线程安全的容器封装在对象内部，然后控制好访问路径就可以了。

Collections 这个类中还提供了一套完备的包装类，比如下面的示例代码中，分别把 ArrayList、HashSet 和 HashMap 包装成了线程安全的 List、Set 和 Map。

```java

List list = Collections.synchronizedList(new ArrayList());
Set set = Collections.synchronizedSet(new HashSet());
Map map = Collections.synchronizedMap(new HashMap());
```

- 组合操作需要注意竞态条件问题

  - 在容器领域一个容易被忽视的“坑”是用迭代器遍历容器，组合操作不具备原子性

    ```java
    List list = Collections.
      synchronizedList(new ArrayList());
    Iterator i = list.iterator(); 
    while (i.hasNext())
      foo(i.next());
    ```

#### 并发容器及其注意事项

Java 在 1.5 版本之前所谓的线程安全的容器，主要指的就是同步容器。不过同步容器有个最大的问题，那就是性能差，所有方法都用 synchronized 来保证互斥，串行度太高了。

- Vector
- Stack 
- Hashtable

因此 Java 在 1.5 及之后版本提供了性能更高的容器，我们一般称为并发容器。

![image-20200920155814476](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200920155816.png)

##### List

CopyOnWriteArrayList：`写的时候会将共享变量新复制一份出来`，这样做的好处是读操作完全无锁。

CopyOnWriteArrayList 的实现原理：

1. 读操作：

   CopyOnWriteArrayList `内部维护了一个数组`，成员变量 `array 就指向这个内部数组`，所有的`读操作`都是基于 `array 进行的`，如下图所示，迭代器 Iterator 遍历的就是 array 数组。

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200920160226.png" alt="image-20200920160224980" style="zoom:50%;" />



2. 写操作（增加元素）：加了锁：`final ReentrantLock lock = this.lock;`

   - CopyOnWriteArrayList `会将 array 复制一份，然后在新复制处理的数组上执行增加元素的操作`，执行完之后再将 array 指向这个新的数组

     <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200920160801.png" alt="image-20200920160759714" style="zoom:50%;" />

CopyOnWriteArrayList 需要注意的“坑”：

- CopyOnWriteArrayList `仅适用于写操作非常少的场景`，而且能够容忍读写的短暂不一致。例如上面的例子中，写入的新元素并不能立刻被遍历到。
  - 因为写时加了锁，所以不用担心切换数组时的安全性。
- CopyOnWriteArrayList `迭代器是只读的，不支持增删改`。因为迭代器遍历的仅仅是一个快照，而对快照进行增删改是没有意义的。

##### Map

Map 接口的两个实现是 `ConcurrentHashMap` 和 `ConcurrentSkipListMap`，

主要区别在于 `ConcurrentHashMap 的 key 是无序`的，

 `ConcurrentSkipListMap 的 key 是有序`的。所以如果你需要保证 key 的顺序，就只能使用 ConcurrentSkipListMap。

- ConcurrentSkipListMap 里面的 SkipList 本身就是一种数据结构，中文一般都翻译为“`跳表”`。*跳表插入、删除、查询操作平均的时间复杂度是 O(log n)*，理论上和并发线程数没有关系，所以在并发度非常高的情况下，若你对 ConcurrentHashMap 的性能还不满意，可以尝试一下 ConcurrentSkipListMap。
  - 如果`key冲突比较大`，hashmap还是要靠链表或者tree来解决冲突的，所以O(1)是理想值。同时`增删改操作很多也影响hashmap性能`。这个也是要看冲突情况。也就是`说hashmap的稳定性差`，如果很不幸正好偶遇它的稳定性问题，同时又接受不了，就`可以尝试skiplistmap，它能保证稳定性`，无论你的并发量是多大，也没有key冲突的问题。

它们的 `key 和 value 都不能为空`，否则会抛出NullPointerException这个运行时异常

<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200920162008.png" alt="image-20200920162006424" style="zoom:50%;" />

#### Set

Set接口的两个实现是 `CopyOnWriteArraySet 和 ConcurrentSkipListSet`，使用场景可以参考前面讲述的 CopyOnWriteArrayList 和 ConcurrentSkipListMap，它们的原理都是一样的。



#### Queue

Java 并发包里面 Queue 这类并发容器是最复杂的，你可以从以下两个维度来分类。

一个维度是`阻塞与非阻塞`，所谓阻塞指的是*当队列已满时，入队操作阻塞；当队列已空时，出队操作阻塞*。

另一个维度是`单端与双端`，单端指的是只能队尾入队，队首出队；而双端指的是队首队尾皆可入队出队。

Java 并发包里`阻塞队列都用 Blocking 关键字标识`，`单端队列`使用 `Queue 标识`，`双端队列`使用 `Deque` 标识。这两个维度组合后，可以将 Queue 细分为四大类，分别是：

- **单端阻塞队列**

  - 其实现有 `ArrayBlockingQueue`、`LinkedBlockingQueue`、`SynchronousQueue`、`LinkedTransferQueue`、`PriorityBlockingQueue` 和 `DelayQueue`。
  - 内部一般**会持有一个队列**，这个队列可以是`数组`（其实现是 *有界单端数组阻塞队列*`ArrayBlockingQueue`）
  - 也可以是`链表`（其实现是*有单端界链表阻塞队列* `LinkedBlockingQueue`）；
  - 甚至还可以**不持有队列**（其实现是*单端同步队列* `SynchronousQueue`），此时生产者线程的入队操作必须等待消费者线程的出队操作
  - 而 `LinkedTransferQueue` *融合 LinkedBlockingQueue 和 SynchronousQueue 的功能*，性能比 LinkedBlockingQueue 更好
  - `PriorityBlockingQueue` 支持按照`优先级出队`；
  - `DelayQueue 支持延时出队`。

  <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200920163142.png" alt="image-20200920163130960" style="zoom:50%;" />

- **双端阻塞队列**：其实现是 `LinkedBlockingDeque`。

  <img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200920163256.png" alt="image-20200920163254986" style="zoom:50%;" />

- **单端非阻塞队列**：其实现是 `ConcurrentLinkedQueue`。

- **双端非阻塞队列**：其实现是 `ConcurrentLinkedDeque`。

`注意队列是否支持有界`（所谓**有界指的是内部的队列是否有容量限制**）。

实际工作中，一般都不建议使用无界的队列，因为数据量大了之后很容易导致 OOM。上面我们提到的这些 Queue 中，*只有 ArrayBlockingQueue 和 LinkedBlockingQueue 是支持有界*的，所以在使用其他无界队列时，一定要充分考虑是否存在导致 OOM 的隐患。

#### 课后思考

线上系统 CPU 突然飙升，你怀疑有同学在并发场景里使用了 HashMap，因为在 1.8 之前的版本里并发执行 HashMap.put() 可能会导致 CPU 飙升到 100%，你觉得该如何验证你的猜测呢？

Java7中的HashMap在执行put操作时会涉及到扩容，由于扩容时链表并发操作会造成链表成环，所以可能导致cpu飙升100%。

### 原子类：无锁工具类的典范

`无锁方案：`Java SDK 并发包将这种无锁方案封装提炼之后，实现了一系列的原子类。

#### **累加器**

```java

public class Test {
  AtomicLong count = 
    new AtomicLong(0);
  void add10K() {
    int idx = 0;
    while(idx++ < 10000) {
      count.getAndIncrement();
    }
  }
}
```

long 型变量 count 替换为了原子类 AtomicLong，原来的 count +=1 替换成了 count.getAndIncrement()

#### 无锁方案的实现原理

其实原子类性能高的秘密很简单，`硬件支持`而已。CPU 为了解决并发问题，提供了 `CAS 指令`（CAS，全称是 Compare And Swap，即“比较并交换”）。

CAS 指令包含 3 个参数：共享变量的内存地址 A、用于比较的值 B 和共享变量的新值 C；并且只有当内存中地址 A 处的值等于 B 时，才能将内存中地址 A 处的值更新为新值 C。作为`一条 CPU 指令，CAS 指令本身是能够保证原子性的。`

CAS *来解决并发问题，一般都会伴随着自旋，而所谓自旋，其实就是循环尝试*。

- 实现一个线程安全的count += 1操作，“CAS+ 自旋”的实现方案如下所示，首先计算 newValue = count+1，如果 cas(count,newValue) 返回的值不等于 count，则意味着线程在执行完代码①处之后，执行代码②处之前，count 的值被其他线程更新过。那此时该怎么处理呢？可以采用自旋方案，就像下面代码中展示的，*可以重新读 count 最新的值来计算 newValue 并尝试再次更新，直到成功*。

`CAS 方案`中，有一个问题可能会常被你忽略，那就是 `ABA 的问题`。

CAS 使用的经典范例

```java

do {
  // 获取当前值
  oldV = xxxx；
  // 根据当前值计算新值
  newV = ...oldV...
}while(!compareAndSet(oldV,newV);
```

#### 原子类概览

Java SDK 并发包里提供的原子类内容很丰富，我们可以将它们分为五个类别：**原子化的基本数据类型、原子化的对象引用类型、原子化数组、原子化对象属性更新器和原子化的累加器**。



![image-20200921152648150](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200921152658.png)



##### 原子化的基本数据类型

相关实现有 `AtomicBoolean`、`AtomicInteger` 和 `AtomicLong`，提供的方法主要有

```java

getAndIncrement() //原子化i++
getAndDecrement() //原子化的i--
incrementAndGet() //原子化的++i
decrementAndGet() //原子化的--i
//当前值+=delta，返回+=前的值
getAndAdd(delta) 
//当前值+=delta，返回+=后的值
addAndGet(delta)
//CAS操作，返回是否成功
compareAndSet(expect, update)
//以下四个方法
//新值可以通过传入func函数来计算
getAndUpdate(func)
updateAndGet(func)
getAndAccumulate(x,func)
accumulateAndGet(x,func)
```

##### 原子化的对象引用类型

相关实现有 `AtomicReference`、`AtomicStampedReference` 和 `AtomicMarkableReference`，利用它们可以实现对象引用的原子化更新。AtomicReference 提供的方法和原子化的基本数据类型差不多，这里不再赘述。

对象引用的更新需要重点关注 ABA 问题，A**tomicStampedReference 和 AtomicMarkableReference 这两个原子类可以解决 ABA 问题**。

AtomicStampedReference 实现的 CAS 方法就增`加了版本号参数`，方法签名如下：

```java

boolean compareAndSet(
  V expectedReference,
  V newReference,
  // 版本号
  int expectedStamp,
  int newStamp) 
```

#### 原子化数组

相关实现有 `AtomicIntegerArray`、`AtomicLongArray` 和 `AtomicReferenceArray`，利用这些原子类，我们可以**原子化地更新数组里面的每一个元素**。这些类提供的方法和原子化的基本数据类型的区别仅仅是：每个方法多了一个数组的索引参数，所以这里也不再赘述了。



#### 原子化对象属性更新器

相关实现有 `AtomicIntegerFieldUpdater`、`AtomicLongFieldUpdater` 和 `AtomicReferenceFieldUpdater`，利用它们可以原子化地更新对象的属性，这三个方法都是利用反射机制实现的，创建更新器的方法如下：

```java

public static <U>
AtomicXXXFieldUpdater<U> 
newUpdater(Class<U> tclass, 
  String fieldName)
```

**对象属性必须是 volatile 类型的**，只有这样才能保证可见性；

- 如果对象属性不是 volatile 类型的，newUpdater() 方法会抛出 `IllegalArgumentException` 这个运行时异常。

compareAndSet() 这个原子操作，相比原子化的基本数据类型多了`一个对象引用 obj`。原子化对象属性更新器相关的方法，相比原子化的基本数据类型仅仅是多了对象引用参数

```java

boolean compareAndSet(
  T obj, 
  int expect, 
  int update)
```

#### 原子化的累加器

`DoubleAccumulator`、`DoubleAdder`、`LongAccumulator` 和 `LongAdder`，这四个类仅仅用来执行累加操作，*相比原子化的基本数据类型，速度更快*，但是不支持 compareAndSet() 方法。如果你仅仅需要累加操作，使用原子化的累加器性能会更好。

#### 总结

Java 提供的原子类能够解决一些简单的原子性问题，但你可能会发现，上面我们所有**原子类的方法都是针对一个共享变量的**，如果你需要**解决多个变量的原子性问题，建议还是使用互斥锁方案**。原子类虽好，但使用要慎之又慎。

### Executor与线程池：如何创建正确的线程池？

`创建对象`，仅仅是在 JVM 的堆里分配一块内存而已；而`创建一个线程`，却`需要调用操作系统内核的 API`，然后操作系统要为线程分配一系列的资源，这个成本就很高了，所以**线程是一个重量级的对象，应该避免频繁创建和销毁。**

#### 线程池是一种生产者 - 消费者模式

业界线程池的设计，普遍采用的都是**生产者 - 消费者模式**。线程池的*使用方是生产者，线程池本身是消费者*。

线程池工作原理

```java

//简化的线程池，仅用来说明工作原理
class MyThreadPool{
  //利用阻塞队列实现生产者-消费者模式
  BlockingQueue<Runnable> workQueue;
  //保存内部工作线程
  List<WorkerThread> threads 
    = new ArrayList<>();
  // 构造方法
  MyThreadPool(int poolSize, 
    BlockingQueue<Runnable> workQueue){
    this.workQueue = workQueue;
    // 创建工作线程
    for(int idx=0; idx<poolSize; idx++){
      WorkerThread work = new WorkerThread();
      work.start();
      threads.add(work);
    }
  }
  // 提交任务
  void execute(Runnable command){
    workQueue.put(command);
  }
  // 工作线程负责消费任务，并执行任务
  class WorkerThread extends Thread{
    public void run() {
      //循环取任务并执行
      while(true){ ①
        Runnable task = workQueue.take();
        task.run();
      } 
    }
  }  
}

/** 下面是使用示例 **/
// 创建有界阻塞队列
BlockingQueue<Runnable> workQueue = 
  new LinkedBlockingQueue<>(2);
// 创建线程池  
MyThreadPool pool = new MyThreadPool(
  10, workQueue);
// 提交任务  
pool.execute(()->{
    System.out.println("hello");
});
```

- 在 MyThreadPool 的内部，我们维护了一个`阻塞队列 workQueue 和一组工作线程`，工作线程的个数由构造函数中的 poolSize 来指定。

- 用户通过调用 execute() 方法来`提交 Runnable 任务`，

- execute() 方法的内部实现仅仅是将任务加入到 workQueue 中

- MyThreadPool 内部维护的工作线程会消费 workQueue 中的任务并执行任务，相关的代码就是代码①处的 while 循环。

#### 如Java 中的线程池的参数

Java 提供的线程池相关的工具类中，最核心的是 `ThreadPoolExecutor`

```java

ThreadPoolExecutor(
  int corePoolSize,
  int maximumPoolSize,
  long keepAliveTime,
  TimeUnit unit,
  BlockingQueue<Runnable> workQueue,
  ThreadFactory threadFactory,
  RejectedExecutionHandler handler) 
```

![image-20200910142116416](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200910142118.png)

- **corePoolSize**：表示线程池保有的最小线程数。有些项目很闲，但是也不能把人都撤了，`至少要留 corePoolSize` 个人坚守阵地。

- **maximumPoolSize**：表示线程池创建的最大线程数。当项目很忙时，就需要加人，但是也不能无限制地加，最多就加到 maximumPoolSize 个人。当项目闲下来时，就要撤人了，最多能撤到 corePoolSize 个人。

- **keepAliveTime** & **unit**：上面提到项目根据忙闲来增减人员，那在编程世界里，如何`定义忙和闲`呢？很简单，一个线程如果在一段时间内，都没有执行任务，说明很闲，`keepAliveTime 和 unit 就是用来定义这个“一段时间”的参数`。也就是说，如果一个线程空闲了keepAliveTime & unit这么久，而且线程池的线程数大于 corePoolSize ，那么这个空闲的线程就要被回收了。

- **workQueue**：工作队列，被提交但未执行的任务存放的位置。

- **threadFactory**：通过这个参数你可以`自定义如何创建线程`，例如你可以给线程`指定一个有意义的名字`。

- **handler**：通过这个参数你可以`自己实现 RejectedExecutionHandler 接口`**自定义任务的拒绝策略**。如果线程池中所有的线程都在忙碌，并且工作队列也满了（前提是工作队列是有界队列），那么此时提交任务，线程池就会拒绝接收。至于拒绝的策略，你可以通过 handler 这个参数来指定。

  - 如果是一些不重要任务，可以选择直接丢弃。但是如果为重要任务，可以采用降级处理：例如将任务信息插入数据库或者消息队列，启用一个专门用作补偿的线程池去进行补偿。

  ThreadPoolExecutor 已经提供了以下 4 种策略。

  - `ThreadPoolExecutor.CallerRunsPolicy()`：提交任务的线程自己阻塞执行该任务（不会真的抛弃任务）。
  - `ThreadPoolExecutor.AbortPolicy()`：默认的拒绝策略，会直接抛出运行时异常： throws RejectedExecutionException
  - `ThreadPoolExecutor.DiscardPolicy()`：直接丢弃任务，没有任何异常抛出。
  - `ThreadPoolExecutor.DiscardOldestPolicy()`：丢弃最老的任务，其实就是把最早进入工作队列的任务丢弃，然后把新任务加入到工作队列。

  Java 在 1.6 版本还`增加了 allowCoreThreadTimeOut(boolean value) 方法`，它可以**让所有线程都支持超时**，这意味着如果项目很闲，就会将项目组的成员都撤走。

#### Java线程池的工作流程

*线程池刚被创建时，只是向系统申请个用于执行线程队列和管理线程池的线程资源*。在调用 execute()添加一个任务时，线程池会按照以下流程执行任务:

- 如果正在运行的线程数量`少于 corepoolsize`（用户定义的核心线程数），线程池就会立刻创建线程并执行该线程任务
- 如果正在运行的线程数量`大于等于 corepoolsize`，该任务就将`被放入阻塞队列`中
- 在`阻塞队列已满`且**正在运行的线程数量少于 maximumPoolsize时**，线程池会**创建非核心线程立刻执行该线程任务**。
- 在阻塞队列已满且正在运行的线程数量**大于等于maximumPoolsize时**，线程池将(**执行拒绝策略**)拒绝执行该线程任务并抛出RejectExecutionException异常。
- 在线程任务执行完毕后，该任务将被从线程池队列中移除，线程池将从队列中取下一个线程任务继续执行。
- 在线程**处于空闲状态的时间超过 keepAliveTime时间时**，正在运行的线程数量超过 corepoolsize，该线程将会被认定为空闲线程并停止。因此在线程池中所有线程任务都执行完毕后，**线程池会收缩到corepoo1Size大小**

![image-20200910142404013](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200910142405.png)

#### Jva提供的线程池的5种线程池？

Java 类库提供一个灵活的线程池以及一些有用的默认配置，我们可以通过Executors 的静态方法来创建线程池。

1. ##### 固定长度的线程池

```java
ExecutorService fixedThreadPool = Executors.newFixedThreadPool(int nThreads);


public static ExecutorService newFixedThreadPool(int nThreads) {
    	// 虽然最小最大倒数固定长度
    	// 无超时时间
    	// 默认线程工厂
    	// 虽然LinkedBlockingQueue是有界队列，但是默认构造是Int型最大值，和无界没区别
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
    }
```

- 每当提交一个任务就创建一个线程，直到达到线程池的最大数量，这时线程规模将不再变化，新任务将在阻塞队列中排队。
- 当线程发生未预期的错误而结束时，线程池会补充一个新的线程。

2. ##### 可缓存的线程池

```java
ExecutorService cacheThreadPool = Executors.newCachedThreadPool();

	public static ExecutorService newCachedThreadPool() {
        // 最小值0，最大值Int最大值
        // 超时时间60s，线程被终止
        // 单端无界的不持有队列的SynchronousQueue,此时生产者线程的入队操作必须等待消费者线程的出队操作（这太垃圾了，为了重用而重用？）
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue<Runnable>());
    }
```

- `创建新线程时如果有可重用的线程，则重用它们，否则重新创建一个新的线程并将其添加到线程池中`。
- 在线程池的 keepAliveTime时间`超过默认的60秒后`，该**线程会被终止并从缓存中移除**，因此在没有线程任务运行时， newCachedThreadPool将不会占用系统的线程资源
- 创建新线程复杂，且耗时。在有执行时间很短的大量任务需要执行的情况下， newCachedThreadPool能够很好地`复用运行中的线程（任务已经完成但未关闭的线程）`资源来提高系统的运行效率。

3. ##### 单线程池

```java
ExecutorService singleThreadExecutor=Executors.newSingleThreadExecutor();

	public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            // 最大容量1
            // 永不移除
            // 用的是有界队列LinkedBlockingQueue默认构造，最大容量为int型
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue<Runnable>()));
    }
```

- 它创建单个工作线程来执行任务，如果这个线程异常结束，会创建一个新的来替代它。
- 它的特点是，能确**保依照任务在队列中的顺序来串行执行**。

4. ##### 周期性线程池（支持定时及周期性任务执行）

```java
ExecutorService scheduledThreadPool=Executors.newScheduledThreadPool(int corePoolSize);

	public ScheduledThreadPoolExecutor(int corePoolSize) {
        // 最小输入，最大int
        // 没有超时
        // 演示队列
        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
              new DelayedWorkQueue());
    }
```

方法，创建了一个固定长度的线程池，而且以延迟或定时的方式来执行任务，类似 Timer 。

5. ##### 工作窃取线程

```java
ExecutorService newWorkStealingPool = Executors.newWorkStealingPool();

public static ExecutorService newWorkStealingPool() {
        return new ForkJoinPool
            (Runtime.getRuntime().availableProcessors(),
             ForkJoinPool.defaultForkJoinWorkerThreadFactory,
             null, true);
    }
```

- 创建持有足够线程的抢占式线程池来达到快速运算的目的，在内部通过使用多个队列来减少各个线程调度产生的竞争。
- 足够的线程就是处理器的数量一样多的线程，`Runtime.getRuntime().availableProcessors()`以保障线程的快速执行，并很大程度地使用系统资源，提高并发计算的效率，省去用户根据CPU瓷源估算并行度的过程。
- 如果开发者想自己定义线程的并发数，则也可以将其作为参数传入。



#### 使用线程池注意事项

Java 并发包里提供了一个线程池的静态工厂类 Executors，利用 Executors 你可以快速创建线程池。

- **-不建议使用 Executors 的最重要的原因**是：Executors 提供的很多方法默认使用的都是**无界**的 LinkedBlockingQueue，`高负载情境下，无界队列很容易导致 OOM`，而 OOM 会导致所有请求都无法处理，这是致命问题。所以强烈建议使用有界队列。

- **线程池默认的拒绝策略**会 throw RejectedExecutionException 这是个运行时异常，对于运行时**异常编译器并不强制 catch 它，所以开发人员很容易忽略**。因此默认拒绝策略要慎重使用。如果线程池处理的任务非常重要，建议自定义自己的拒绝策略；并且在实际工作中，自定义的拒绝策略往往和降级策略配合使用。

- **注意异常处理的问题**，例如通过 ThreadPoolExecutor 对象的 execute() 方法提交任务时，如果任务在执行的过程中出现运行时异常，会导致执行任务的线程终止；不过，最致命的是任务虽然异常了，但是你却获取不到任何通知，这会让你误以为任务都执行得很正常。虽然线程池提供了很多用于异常处理的方法，但是最稳妥和简单的方案还是捕获所有异常并按需处理，你可以参考下面的示例代码

  ```java
  
  try {
    //业务逻辑
  } catch (RuntimeException x) {
    //按需处理
  } catch (Throwable x) {
    //按需处理
  } 
  ```

#### 如何给线程赋予一个有意义的名字？

- guava的ThreadFactoryBuilder.setNameFormat可以指定一个前缀，使用%d表示序号；
- 或者自己实现ThreadFactory并制定给线程池，在实现的ThreadFactory中设定计数和调用Thread.setName

### Future：如何用多线程实现最优的“烧水泡茶”程序？

hreadPoolExecutor 的 `void execute(Runnable command) 方法`，利用这个方法虽然可以提交任务，但是却**没有办法获取任务的执行结果**（execute() 方法没有返回值）。

#### 获取任务执行结果

Java 通过 ThreadPoolExecutor 提供的 `3 个 submit() 方法`和 `1 个 FutureTask 工具类`来支持获得任务执行结果的需求。

```java

// 提交Runnable任务，返回的 Future 仅可以用来断言任务已经结束
Future<?> submit(Runnable task);
// 提交Callable任务，可以通过调用其 get() 方法来获取任务的执行结果
<T> Future<T> submit(Callable<T> task);
// 提交Runnable任务及结果引用  
<T> Future<T> submit(Runnable task, T result);
```

- 提交 Runnable 任务 submit(Runnable task) ：这个方法的参数是一个 Runnable 接口，Runnable 接口的 run() 方法是没有返回值的，所以 submit(Runnable task) **这个方法返回的 Future 仅可以用来断言任务已经结束了**，类似于 Thread.join()。

- 提交 Callable 任务 submit(Callable task)：这个方法的参数是一个 Callable 接口，它只有一个 call() 方法，并且这个方法是有返回值的，所以这个方法返回的 Future 对象可以通过调用其 get() 方法来获取任务的执行结果。

- 提交 Runnable 任务及结果引用 submit(Runnable task, T result)：这个方法很有意思，假设这个方法返回的 Future 对象是 f，f.get() 的返回值就是传给 submit() 方法的参数 result。这个方法该怎么用呢？下面这段示例代码展示了它的经典用法。需要你注意的是 *Runnable 接口的实现类 Task 声明了一个有参构造函数 Task(Result r) ，创建 Task 对象的时候传入了 result 对象，这样就能在类 Task 的 run() 方法中对 result 进行各种操作了*。r**esult 相当于主线程和子线程之间的桥梁，通过它主子线程可以共享数据**。

  ```java
  
  ExecutorService executor 
    = Executors.newFixedThreadPool(1);
  // 创建Result对象r
  Result r = new Result();
  r.setAAA(a);
  // 提交任务
  Future<Result> future = 
    executor.submit(new Task(r), r);  
  Result fr = future.get();
  // 下面等式成立
  fr === r;
  fr.getAAA() === a;
  fr.getXXX() === x
  
  class Task implements Runnable{
    Result r;
    //通过构造函数传入result
    Task(Result r){
      this.r = r;
    }
    void run() {
      //可以操作result
      a = r.getAAA();
      r.setXXX(x);
    }
  }
  ```

  

submit() 方法返回的Future接口的5个方法

```java

// 取消任务
boolean cancel(boolean mayInterruptIfRunning);
// 判断任务是否已取消  
boolean isCancelled();
// 判断任务是否已结束
boolean isDone();
// 获得任务执行结果（会阻塞线程）
get();
// 获得任务执行结果，支持超时（会阻塞线程）
get(long timeout, TimeUnit unit);
```

- 注意：这两个 get() 方法都是阻塞式的，如果被调用的时候，任务还没有执行完，那么调用 get() 方法的线程会阻塞，直到任务执行完才会被唤醒。

####  FutureTask 工具类

Future 是一个接口，而 FutureTask 是一个实实在在的工具类，这个工具类有两个构造函数，参数和前面介绍的 submit() 方法类似

```java

FutureTask(Callable<V> callable);
FutureTask(Runnable runnable, V result);
```

FutureTask **实现了 Runnable 和 Future 接口**，由于实现了 Runnable 接口，所以可以将 FutureTask 对象**作为任务**提交给 ThreadPoolExecutor 去执行，也可以直接被 Thread 执行；又因为实现了 Future 接口，所以也能**用来获得任务的执行结果**。下面的示例代码是将 FutureTask 对象提交给 ThreadPoolExecutor 去执行。

```java

// 创建FutureTask
FutureTask<Integer> futureTask
  = new FutureTask<>(()-> 1+2);
// 创建线程池
ExecutorService es = 
  Executors.newCachedThreadPool();
// 提交FutureTask 
es.submit(futureTask);
// 获取计算结果
Integer result = futureTask.get();
```

利用 FutureTask 对象可以很容易获取子线程的执行结果。

```java

// 创建FutureTask
FutureTask<Integer> futureTask
  = new FutureTask<>(()-> 1+2);
// 创建并启动线程
Thread T1 = new Thread(futureTask);
T1.start();
// 获取计算结果
Integer result = futureTask.get();
```

#### 实现最优的“烧水泡茶”程序



<img src="https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200921173132.png" alt="image-20200921173130334" style="zoom:50%;" />

逻辑

可以想出很多种办法，例如 `Thread.join()、CountDownLatch`，甚至`阻塞队列`都可以解决，不过今天我们用 Future 特性来实现。

我们创建了两个 FutureTask——ft1 和 ft2，ft1 完成洗水壶、烧开水、泡茶的任务，ft2 完成洗茶壶、洗茶杯、拿茶叶的任务；这里需要注意的是 ft1 这个任务在执行泡茶任务前，需要等待 ft2 把茶叶拿来，所以 ft1 内部需要引用 ft2，并在执行泡茶之前，调用 ft2 的 get() 方法实现等待。

### (待实践)CompletableFuture：异步编程

用多线程优化性能，其实不过就是将串行操作变成并行操作。

异步化，是并行方案得以实施的基础，更深入地讲其实就是：利用多线程优化性能这个核心方案得以实施的基础。

##### 创建 CompletableFuture 对象

```java

//使用默认线程池
// Runnable 接口的 run() 方法没有返回值
static CompletableFuture<Void> runAsync(Runnable runnable)
// Supplier 接口的 get() 方法是有返回值的
static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier)
//可以指定线程池  
static CompletableFuture<Void> 
  runAsync(Runnable runnable, Executor executor)
static <U> CompletableFuture<U> 
  supplyAsync(Supplier<U> supplier, Executor executor)  
```

默认线程池使用公共的 ForkJoinPool 线程池，这个线程池默认创建的线程数是 CPU 的核数

建议根**据不同的业务类型创建不同的线程池**，以避免互相干扰。

创建完 CompletableFuture 对象之后，*会自动地异步执行 runnable.run() 方法或者 supplier.get() 方法，对于一个异步操作*

需要关注两个问题：一个是异步操作什么时候结束，另一个是如何获取异步操作的执行结果。

因为 CompletableFuture 类实现了 Future 接口，所以这两个问题你都可以通过 Future 接口来解决。另外，CompletableFuture 类还实现了 CompletionStage 接口

#### [CompletionStage接口](https://blog.csdn.net/w605283073/article/details/92418504)

CompletionStage 接口描述串行关系、AND 聚合关系、OR 聚合关系以及异常处理。

##### 描述串行关系

CompletionStage 接口里面描述串行关系，主要是 thenApply、thenAccept、thenRun 和 thenCompose 这四个系列的接口



```java

CompletionStage<R> thenApply(fn);
CompletionStage<R> thenApplyAsync(fn);
CompletionStage<Void> thenAccept(consumer);
CompletionStage<Void> thenAcceptAsync(consumer);
CompletionStage<Void> thenRun(action);
CompletionStage<Void> thenRunAsync(action);
CompletionStage<R> thenCompose(fn);
CompletionStage<R> thenComposeAsync(fn);
```

### CompletionService：批量执行异步任

利用 CompletionService 不但能帮你解决先获取到的报价先保存到数据库的问题，而且还能让代码更简练。

CompletionService 的实现原理也是内部维护了一个阻塞队列，`当任务执行结束就把任务的执行结果加入到阻塞队列中`， CompletionService 是把任务执行结果的 Future 对象加入到阻塞队列中。

##### 创建 CompletionService 

CompletionService 接口的实现类是 ExecutorCompletionService，这个实现类的构造方法有两个，分别是：

```java
ExecutorCompletionService(Executor executor)；
ExecutorCompletionService(Executor executor, BlockingQueue<Future<V>> completionQueue)。
```

这两个构造方法都需要传入一个线程池，如果不指定 completionQueue，那么默认会使用无界的 LinkedBlockingQueue。

通过 CompletionService 接口提供的 submit() 方法提交了三个询价操作，这三个询价操作将会被 CompletionService 异步执行。最后，我们通过 CompletionService 接口提供的 take() 方法获取一个 Future 对象（前面我们提到过，加入到阻塞队列中的是任务执行结果的 Future 对象），调用 Future 对象的 get() 方法就能返回询价操作的执行结果

```java

// 创建线程池
ExecutorService executor = Executors.newFixedThreadPool(3);
// 创建CompletionService
CompletionService<Integer> cs = new ExecutorCompletionService<>(executor);
// 异步向电商S1询价
cs.submit(()->getPriceByS1());
// 异步向电商S2询价
cs.submit(()->getPriceByS2());
// 异步向电商S3询价
cs.submit(()->getPriceByS3());
// 将询价结果异步保存到数据库
for (int i=0; i<3; i++) {
  Integer r = cs.take().get();
  executor.execute(()->save(r));
}
```

#### CompletionService 接口说明

```java
// 添加任务
Future<V> submit(Callable<V> task);
Future<V> submit(Runnable task, V result);

// 都是从阻塞队列中拿元素 

// 没有会阻塞
Future<V> take() throws InterruptedException;
// 没有立即返回null
Future<V> poll();

// 等待一段时间还没有,返回null
Future<V> poll(long timeout, TimeUnit unit) throws InterruptedException;
```



## 熟悉

### 常见的Java线程的4种创建方式

常见的Java线程的4种创建方式分别为：继承 Thread类、实现Runnable接口、通过 ExecutorService和 Callable< Class>实现有返回值的线程、基于线程池。



## 了解

### （新）并发编程和并行编程有什么区别？

并发（Concurrency）和并行（Parallellism）是：

并行编程是指同一时刻没有关系的两个事件执行各自的任务

并发编程是指在一个时间段两个事件相互协作，为了完成一个任务。

所以并发编程的目标是，充分的利用处理器的每一个核，以达到最高的处理性能。

#### 并发和并行的区别？

- 并发：同一时间段，多个任务都在执行（单位时间内不一定同时执行）；
- 并行：单位时间内，多个任务同时执行。

### （新）同步和异步有何异同，在什么情况下分别使用他们？

如果`数据将在线程间共享`。例如正在写的数据以后可能被另一个线程读到，或者正在读的数据可能已经被另一个线程写过了，那么这些数据就是共享数据，必须进行**同步**存取。

当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用**异步**编程，在很多情况下采用异步途径往往更有效率。

### 一个线程运行时发生异常会怎样？

如果异常没有被捕获该线程将会停止执行。

`Thread.UncaughtExceptionHandler` 是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候 JVM 会使用 `Thread#getUncaughtExceptionHandler()` 方法来查询线程的 UncaughtExceptionHandler 并将线程和异常作为参数传递给 handler 的 `#uncaughtException(exception)` 方法进行处理。

具体的使用，可以看看 [《JAVA 多线程之 UncaughtExceptionHandler —— 处理非正常的线程中止》](https://blog.csdn.net/u013256816/article/details/50417822) 。

### notify 和 notifyAll 有什么区别？

当一个线程进入 wait 之后，就必须等其他线程 notify/notifyAll 。

- 使用 `notifyAll,可以唤醒所有处`于 wait 状态的线程，使其重新进入锁的争夺队列中，而 `notify 只能唤醒`一个。
- 如果没把握，建议 notifyAll ，防止 notify 因为信号丢失而造成程序错误（`真正该唤醒的线程就再也没有机会被唤醒`）。

`注：`假设我们有资源 A、B、C、D，线程 1 申请到了 AB，线程 2 申请到了 CD，此时线程 3 申请 AB，会进入等待队列（AB 分配给线程 1，线程 3 要求的条件不满足），线程 4 申请 CD 也会进入等待队列。我们再假设之后线程 1 归还了资源 AB，如果使用 notify() 来通知等待队列中的线程，有可能被通知的是线程 4，但线程 4 申请的是 CD，所以此时线程 4 还是会继续等待，而真正该唤醒的线程 3 就再也没有机会被唤醒了。

关于 notify 的信息丢失，可以看看 [《wait 和 notify 的坑》](https://www.jianshu.com/p/91d95bb5a4bd) 文章。

### 为什么你应该在循环中检查等待条件？

处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。

所以，我们不能写 `if (condition)` 而应该是 `while (condition)` ，特别是 CAS 竞争的时候。示例代码如下：

```
// The standard idiom for using the wait method
synchronized (obj) {
    while (condition does not hold) {
        obj.wait(); // (Releases lock, and reacquires on wakeup)
    }
    ... // Perform action appropriate to condition
}
```

- 另外，也可以看看 [《wait 必须放在 while 循环里面的原因探析》](https://blog.csdn.net/qq_35181209/article/details/77362297)

### 你如何确保 main 方法所在的线程是 Java 程序最后结束的线程？

> 考点，就是 join 方法。

我们可以使用 Thread 类的 `#join()` 方法，来确保所有程序创建的线程在 main 方法退出前结束。

### （新）什么是CPU超线程技术？

超线程技术通俗来讲就是一个人干活慢，于是就又模拟出另一个人一起干活，但实际工作人数未增加。通过特殊硬件指令，将两个逻辑内核模拟为两个物理芯片。让一个物理核心充当两个核心的角色，原本任务只能有一颗核心用单一线程进行处理，但在超线程技术的加持下，单颗核心可以同时对多个任务同时展开工作，利用了CPU的空闲时间，增加了芯片的工作效率，性能得到有效的提升。

### （新）XXX是线程安全的吗？

#### Servlet 是线程安全吗？

Servlet `不是`线程安全的，Servlet 是`单实例多线程`的，当多个线程同时访问同一个方法，是不能保证共享变量的线程安全性的。

#### Struts2 是线程安全吗

Struts2 的 Action 是`多实例多线程`的，`是`线程安全的，每个请求过来都会 `new` 一个新的 Action 分配给这个请求，请求完成后销毁。

#### SpringMVC 是线程安全吗？

`不是`的，和 Servlet 类似的处理流程。

### （新）何在两个线程间共享数据？

在两个线程间**共享变量**，即可实现共享。

一般来说，共享变量要求变量本身是线程安全的，然后在线程内使用的时候，如果有对共享变量的复合操作，那么也得保证复合操作的线程安全性。

### （新）怎么检测一个线程是否拥有锁？

调用 `Thread#holdsLock(Object obj)` **静态**方法，它返回 `true` 如果当且仅当当前线程拥有某个具体对象的锁。代码如下：

```
// Thread.java

public static native boolean holdsLock(Object obj);
```

### （新）如何判断多线程的阻塞导致的问题？

可以用top命令查看Java线程的cpu利用率，用jstack来dump线程。开发环境可以用 java visualvm查看线程执行情况

### （新）10 个线程和 2 个线程的同步代码，哪个更容易写？

从写代码的角度来说，两者的复杂度是相同的，因为同步代码与线程数量是相互独立的。

但是同步策略的选择依赖于线程的数量，`因为越多的线程意味着更大的竞争`，所以你需要利用同步技术，如锁分离，这要求更复杂的代码和专业知识。

### 我们用多核多线程相比单核单线程能提速多少呢？

有个阿姆达尔（Amdahl）定律，代表了处理器并行运算之后效率提升的能力，它正好可以解决这个问题，具体公式如下：

![image-20200915154642053](https://gitee.com//chenchong0817/picture/raw/master/Aaron/20200915154643.png)

公式里的 n 可以理解为 CPU 的核数，p 可以理解为并行百分比，那（1-p）就是串行百分比了，也就是我们假设的 5%。我们再假设 CPU 的核数（也就是 n）无穷大，那加速比 S 的极限就是 20。也就是说，如果我们的串行率是 5%，那么我们无论采用什么技术，最高也就只能提高 20 倍的性能。

串行百分比一般怎么得出来呢？

临界区都是串行的，非临界区都是并行的，用单线程执行临界区的时间/用单线程执行(临界区+非临界区)的时间就是串行百分比

### （待整理）Java 语言提供的 Vector 是一个线程安全的容器，有同学写了下面的代码，你看看是否存在并发问题呢？

```java

void addIfNotExist(Vector v, 
    Object o){
  if(!v.contains(o)) {
    v.add(o);
  }
}
```

Vector实现线程安全是通过给主要的写方法加了synchronized，类似contains这样的读方法并没有synchronized，该题的问题就出在不是线程安全的contains方法，两个线程如果同时执行到if(!v.contains(o)) 是可以都通过的，这时就会执行两次add方法，重复添加。也就是老师说的竞态条件。

vector是线程安全，指的是它方法单独执行的时候没有并发正确性问题，并不代表把它的操作组合在一起问木有，而这个程序显然有老师讲的竞态条件问题。

解决方案：给Vector对象加锁

```java
void addIfNotExist(Vector v,
    Object o){
synchronized(v) {
  if(!v.contains(o)) {
    v.add(o);
  }
}
}
```

为什么给addIfNotExist方法加锁不行。

- 因为addIfNotExist不是Vector方法，可能代码其他地方也在调用Vector::add方法，改变数组内容。

### （待整理）信号量和管程

信号量机制是可以解决同步/互斥的问题的，但是信号量的操作分散在各个进程或线程中，不方便进行管理，因每次需调用PV操作，还可能导致死锁或破坏互斥请求的问题。

管程是定义了一个数据结构和能为并发所执行的一组操作，这组操作能够进行同步和改变管程中的数据。这相当于对临界资源的同步操作都集中进行管理，凡是要访问临界资源的进程或线程，都必须先通过管程，由管程的这套机制来实现多进程或线程对同一个临界资源的互斥访问和使用。管程的同步主要通过condition类型的变量（条件变量），条件变量可执行操作wait()和signal()。管程一般是由语言编译器进行封装，体现出OOP中的封装思想，也如老师所讲的，管程模型和面向对象高度契合的。